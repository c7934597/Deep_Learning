{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image_Classification_Pytorch (Inference)","metadata":{}},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# Table of Contents\n\n1. [套件安裝與載入](#1)\n1. [環境檢測與設定](#2)\n1. [開發參數設定](#3)\n1. [資料處理](#4)\n    -  [載入CSV檔](#4.1)\n    -  [檢查CSV檔缺失值](#4.2)\n1. [定義模型方法](#5)\n1. [製作資料集＆資料擴增＆推論模型](#6)\n1. [待辦事項](#7)","metadata":{}},{"cell_type":"markdown","source":"# 1. 套件安裝與載入<a class=\"anchor\" id=\"1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"!pip3 install git+https://github.com/rwightman/pytorch-image-models.git","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:10.180803Z","iopub.execute_input":"2021-06-06T15:29:10.181148Z","iopub.status.idle":"2021-06-06T15:29:19.585838Z","shell.execute_reply.started":"2021-06-06T15:29:10.181073Z","shell.execute_reply":"2021-06-06T15:29:19.584725Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/rwightman/pytorch-image-models.git\n  Cloning https://github.com/rwightman/pytorch-image-models.git to /tmp/pip-req-build-dujb_g03\n  Running command git clone -q https://github.com/rwightman/pytorch-image-models.git /tmp/pip-req-build-dujb_g03\nRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm==0.4.11) (1.7.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm==0.4.11) (0.8.1)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.11) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.11) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.11) (0.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.11) (1.19.5)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.4.11) (7.2.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# 資料處理套件\nimport os\nimport gc\nimport cv2\nimport sys\nimport time\nimport timm\nimport random\nimport numpy as np\nimport pandas as pd\nimport albumentations as A\n\nfrom tqdm import tqdm\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:19.587776Z","iopub.execute_input":"2021-06-06T15:29:19.588089Z","iopub.status.idle":"2021-06-06T15:29:21.212339Z","shell.execute_reply.started":"2021-06-06T15:29:19.588055Z","shell.execute_reply":"2021-06-06T15:29:21.210998Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# pytorch深度學習模組套件\nimport torch\nimport torch.nn as nn\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:21.214438Z","iopub.execute_input":"2021-06-06T15:29:21.214817Z","iopub.status.idle":"2021-06-06T15:29:21.219497Z","shell.execute_reply.started":"2021-06-06T15:29:21.214782Z","shell.execute_reply":"2021-06-06T15:29:21.218361Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# 2. 環境檢測與設定<a class=\"anchor\" id=\"2\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nDEVICE","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:21.220997Z","iopub.execute_input":"2021-06-06T15:29:21.221326Z","iopub.status.idle":"2021-06-06T15:29:21.239150Z","shell.execute_reply.started":"2021-06-06T15:29:21.221295Z","shell.execute_reply":"2021-06-06T15:29:21.237980Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}]},{"cell_type":"code","source":"# 查看pytorch版本\nprint(torch.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:21.240845Z","iopub.execute_input":"2021-06-06T15:29:21.241456Z","iopub.status.idle":"2021-06-06T15:29:21.250148Z","shell.execute_reply.started":"2021-06-06T15:29:21.241408Z","shell.execute_reply":"2021-06-06T15:29:21.249103Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"1.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"'''執行環境參數設定'''\n\n# (Boolean)是否為本機\nLOCAL = False\n\n# (Boolean)是否為 Colab\nCOLAB = False\n\n\n'''檔案路徑參數設定'''\n\n# (String)Root路徑\nif LOCAL:\n    PATH = r'../'\nelif COLAB:\n    PATH = r'/content/drive/My Drive/Colab Notebooks/'\nelse:\n    PATH = r'../input/'\n    \n# (String)資料根路徑\nDATA_ROOT_PATH = PATH+r'resized-2015-2019-diabetic-retinopathy-detection/' \n\n# (String)CSV根路徑\nCSV_ROOT_PATH = PATH+r'aptos2019-blindness-detection/' \n\n# (String)測試資料路徑\nTEST_DATA_PATH = DATA_ROOT_PATH+r'resized_test19/'\n\n# (String)測試CSV路徑\nTEST_CSV_PATH = CSV_ROOT_PATH+r'sample_submission.csv'\n\n# (Boolean)是否要匯入Library\nIMPORT_PYTORCH_LIBRARY = False\n\n# (String)Library的路徑\nPYTORCH_LIBRARY_PATH = PATH + \"PyTorch_Library/\"\n\n# (String)讀取預訓練模型/權重的名稱，當fold model時，後面會自動加_NUMBER\nLOAD_MODEL_NAME = ['efficientnet_v2_b0', 'efficientnet_v2_b0', 'efficientnet_v2_b0']\n\n# (String)讀取預訓練模型/權重的儲存路徑\nLOAD_MODEL_PATH = [PATH + r'test1111/', \n                   PATH + r'test1111/', \n                   PATH + r'test1111/']","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-06-06T15:29:21.251720Z","iopub.execute_input":"2021-06-06T15:29:21.252019Z","iopub.status.idle":"2021-06-06T15:29:21.262191Z","shell.execute_reply.started":"2021-06-06T15:29:21.251991Z","shell.execute_reply":"2021-06-06T15:29:21.261248Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"if DEVICE != torch.device(\"cpu\"):\n    !nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:21.263419Z","iopub.execute_input":"2021-06-06T15:29:21.263975Z","iopub.status.idle":"2021-06-06T15:29:21.273092Z","shell.execute_reply.started":"2021-06-06T15:29:21.263936Z","shell.execute_reply":"2021-06-06T15:29:21.271696Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"if not LOCAL and COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    \nif IMPORT_PYTORCH_LIBRARY:\n    sys.path.append(PYTORCH_LIBRARY_PATH + \"Custom_Loss.py\")\n    sys.path.append(PYTORCH_LIBRARY_PATH + \"Custom_Model.py\")","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:21.276051Z","iopub.execute_input":"2021-06-06T15:29:21.276381Z","iopub.status.idle":"2021-06-06T15:29:21.283999Z","shell.execute_reply.started":"2021-06-06T15:29:21.276350Z","shell.execute_reply":"2021-06-06T15:29:21.283092Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# 3. 開發參數設定<a class=\"anchor\" id=\"3\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"'''客製參數設定'''\n\n\n'''資料參數設定'''\n\n# (Int)分類數量\nCLASSES = 5\n\n# (Int)集成模型數量\nENSEMBLE_MODEL_COUNT = 3\n\n# (Int List)有CSV檔該參數才有用，1則為不做交叉驗證\nFOLD = [1]*ENSEMBLE_MODEL_COUNT\n\n# (Int List)圖片尺寸\nIMAGE_SIZE = [224]*ENSEMBLE_MODEL_COUNT\n\n# (String)圖片副檔名\nIMAGE_NAME_EXTENSION = '.jpg'\n\n# (String)CSV圖片檔名欄位\nIMAGE_NAME = 'id_code'\n\n# (Boolean)CSV圖片檔名欄位是否包含副檔名\nIMAGE_NAME_HAVE_EXTENSION = False\n\n#  (Boolean)圖像轉為RGB\nCOLOR_CONVERT_RGB = True\n\n# (Int)不同的種子會產生不同的Random或分層K-FOLD分裂, 42則是預設固定種子\nSEED = 42\n\n# (Boolean)是否資料轉Tensor時啟動鎖頁內存(GPU內存)，而不鎖頁內存就是會使用到硬碟虛擬內存\nPIN_MEMORY = False\n\n# (Int)要用於數據加載的子進程數。0表示將在主進程中加載數據。（默認值：0）\nNUM_WORKERS = 0\n    \n# (Boolean)如為True每次返回的卷積算法將是確定的，即默認算法\nCUDNN_DETERMINISTIC = True\n\n# (Boolean)PyTorch 中對模型裡的卷積層進行預先的優化，也就是在每一個卷積層中測試 cuDNN 提供的所有卷積實現算法，\n# 然後選擇最快的那個。這樣在模型啟動的時候，只要額外多花一點點預處理時間，就可以較大幅度地減少訓練時間\nCUDNN_BENCHMARK = True\n\n\n'''資料擴增參數設定\n\n資料擴增教學\nhttps://zhuanlan.zhihu.com/p/107399127\n\n資料擴增Doc\nhttps://vfdev-5-albumentations.readthedocs.io/en/docs_pytorch_fix/api/augmentations.html\n'''\n\n# (Float)訓練集資料擴增的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_TRAIN_TRANSFORMS = 1.0\n\n# (Float)驗證集資料擴增的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_VAL_TRANSFORMS = 1.0\n\n# 以下資料擴增為訓練集使用=============================================\n\n# (Float)模糊的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_BLUR = 0\n\n# (Int)模糊的上限\nBLUR_LIMIT = 3\n\n# (Float)水平翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_HORIZONTALFLIP = 0\n\n# (Float)垂直翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_VERTICALFLIP = 0\n\n# (Float)水平和垂直翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_FLIP = 0\n\n# (Float)隨機旋轉90度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RANDOMROTATE90 = 0\n\n# (Float)平移縮放旋轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_SHIFTSCALEROTATE = 0\n\n# (Float)平移縮放旋轉的平移上限\nSHIFTSCALEROTATE_SHIFT_LIMIT = 0.0625\n\n# (Float)平移縮放旋轉的縮放上限\nSHIFTSCALEROTATE_SCALE_LIMIT = 0.1\n\n# (Float)平移縮放旋轉的旋轉上限\nSHIFTSCALEROTATE_ROTATE_LIMIT = 45\n\n# (Float)彈性變換的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_ELATICTRANSFORM = 0\n\n# (Float)彈性變換的alpha高斯過濾參數\nELATICTRANSFORM_ALPHA = 1\n\n# (Float)彈性變換的sigma高斯過濾參數\nELATICTRANSFORM_SIGMA = 50\n\n# (Float)彈性變換的alpha_affine，範圍為（-alpha_affine，alpha_affine）\nELATICTRANSFORM_ALPHA_AFFINE = 50\n\n# (Float)網格失真的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_GRIDDISTORTION = 0\n\n# (Int)網格失真的每一條邊上網格單元數量\nGRIDDISTORTION_NUM_STEPS = 5\n\n# (Float)隨機亮度對比度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RANDOMBRIGHTNESSCONTRAST_CONTRAST = 0\n\n# (Float)隨機亮度的上限\nRANDOMBRIGHTNESSCONTRAST_BRIGHTNESS_LIMIT = 0.2\n\n# (Float)隨機對比度的上限\nRANDOMBRIGHTNESSCONTRAST_CONTRAST_LIMIT = 0.2\n\n# (Float)隨機色調飽和度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_HUESATURATIONVALUE = 0\n\n# (Float)隨機色調飽和度的色調上限\nHUESATURATIONVALUE_HUE_SHIFT_LIMIT = 20\n\n# (Float)隨機色調飽和度的飽和度上限\nHUESATURATIONVALUE_SAT_SHIFT_LIMIT = 30\n\n# (Float)隨機色調飽和度的值上限\nHUESATURATIONVALUE_VAL_SHIFT_LIMIT = 20\n\n# (Float)對比度受限自適應直方圖均衡的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_CLAHE = 0\n\n# (Float)對比度受限自適應直方圖均衡的對比度上限\nCLAHE_CLIP_LIMIT = 4.0\n\n# (Float)隨機在圖像上生成黑色矩形的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_COARSEDROPOUT = 0\n\n# (Int)隨機在圖像上生成黑色矩形的數量\nCOARSEDROPOUT_NUM_HOLES = 8\n\n# (Int)隨機在圖像上生成黑色矩形的最大高度\nCOARSEDROPOUT_MAX_H_SIZE = 8\n\n# (Int)隨機在圖像上生成黑色矩形的最大寬度\nCOARSEDROPOUT_MAX_W_SIZE = 8\n\n# (Float)隨機縮放剪裁的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RANDOMRESIZEDCROP = 0\n\n# (Float Tuple)隨機縮放剪裁之前的圖像比例縮放\nRANDOMRESIZEDCROP_SCALE = (0.08, 1.0)\n\n# (Int)隨機縮放剪裁之前的圖像高度\nRANDOMRESIZEDCROP_HEIGHT = IMAGE_SIZE\n\n# (Int)隨機縮放剪裁之前的圖像寬度\nRANDOMRESIZEDCROP_WIDTH = IMAGE_SIZE\n\n# 以上資料擴增為訓練集使用=============================================\n\n# 以下資料擴增為訓練集和驗證集共用======================================\n\n# (Float)縮放的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RESIZE = 1.0\n\n# (Int)縮放後的圖片高度\nRESIZE_HEIGHT = IMAGE_SIZE\n\n# (Int)縮放後的圖片寬度\nRESIZE_WIDTH = IMAGE_SIZE\n\n# (Float)正規化的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_NORMALIZE = 1.0\n\n# (Float List)正規化的平均值([0,1]的參考平均值:[0.485, 0.456, 0.406], [-1,1]的參考平均值:[0.5, 0.5, 0.5])\nNORMALIZE_MEAN = [0.485, 0.456, 0.406]\n\n# (Float List)正規化的標準差([0,1]的參考標準差[0.229, 0.224, 0.225], [-1,1]的參考標準差[0.5, 0.5, 0.5])\nNORMALIZE_STD = [0.229, 0.224, 0.225]\n\n# (Float)正規化的PIXEL最大值(參考PIXEL最大值255.0)\nNORMALIZE_MAX_PIXEL_VALUE = 255.0\n\n# (Float)歸一化的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n# ToTensorV2()將[0, 255]的PIL.Image或[H, W, C]的numpy.ndarray數據，\n# 轉換為形狀[C, H, W]的torch.FloadTensor，並歸一化。\nP_TOTENSORV2 = 1.0\n\n# 以上資料擴增為訓練集和驗證集共用======================================\n\n\n''''模型參數設定'''\n\n# (String List)模型載入方式(MODEL、WEIGHT_OF_CUSTOM_MODEL、WEIGHT_OF_TIMM_MODEL、WEIGHT_OF_BASE_MODEL）\nMODEL_LIST = [\"WEIGHT_OF_TIMM_MODEL\"]*ENSEMBLE_MODEL_COUNT\n\nif \"WEIGHT_OF_CUSTOM_MODEL\" in MODEL_LIST:\n    # (Model List)模型載入方式有CUSTOM_MODEL，依照出現次數順序列出\n    CUSTOM_MODEL = [None]*ENSEMBLE_MODEL_COUNT\n\nif \"WEIGHT_OF_TIMM_MODEL\" in MODEL_LIST:\n    # (Model List)模型載入方式有TIMM_MODEL，依照出現次數順序列出\n    TIMM_MODEL = [\"tf_efficientnet_b0\"]*ENSEMBLE_MODEL_COUNT\n\nif \"WEIGHT_OF_BASE_MODEL\" in MODEL_LIST:\n    # (Model List)模型載入方式有BASE_MODEL，依照出現次數順序列出\n    BASE_MODEL = [models.resnet18]*ENSEMBLE_MODEL_COUNT\n\n# (Boolean)模型是否使用分類層輸出，否則為全連接層\nCLASSIFIER_OUTPUT = [True]*ENSEMBLE_MODEL_COUNT\n\n# (Float)Dropout比率\nDROPOUT = [1]*ENSEMBLE_MODEL_COUNT\n\n# (Boolean)Bias偏移量\nBIAS = [True]*ENSEMBLE_MODEL_COUNT\n\n# (Boolean)是否印出完整模型\nMODEL_PRINT = [False]*ENSEMBLE_MODEL_COUNT\n\n\n''''訓練參數設定'''\n\n# (Int List)每批推論的尺寸\nBATCH_SIZE = [256]*ENSEMBLE_MODEL_COUNT","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:21.285700Z","iopub.execute_input":"2021-06-06T15:29:21.286132Z","iopub.status.idle":"2021-06-06T15:29:21.304362Z","shell.execute_reply.started":"2021-06-06T15:29:21.286100Z","shell.execute_reply":"2021-06-06T15:29:21.303480Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = CUDNN_DETERMINISTIC\n    torch.backends.cudnn.benchmark = CUDNN_BENCHMARK\n\nseed_everything(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:21.305575Z","iopub.execute_input":"2021-06-06T15:29:21.306022Z","iopub.status.idle":"2021-06-06T15:29:21.321692Z","shell.execute_reply.started":"2021-06-06T15:29:21.305981Z","shell.execute_reply":"2021-06-06T15:29:21.320857Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# 4. 資料處理<a class=\"anchor\" id=\"4\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"markdown","source":"## 4.1 載入CSV檔 <a class=\"anchor\" id=\"4.1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"print('Reading data...')\n\n# 讀取訓練資料集CSV檔\ntest_csv = pd.read_csv(TEST_CSV_PATH,encoding=\"utf8\")\n\nprint('Reading data completed')","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:21.322845Z","iopub.execute_input":"2021-06-06T15:29:21.323294Z","iopub.status.idle":"2021-06-06T15:29:21.341605Z","shell.execute_reply.started":"2021-06-06T15:29:21.323252Z","shell.execute_reply":"2021-06-06T15:29:21.340498Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Reading data...\nReading data completed\n","output_type":"stream"}]},{"cell_type":"code","source":"# 顯示訓練資料集CSV檔\ntest_csv.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:21.343320Z","iopub.execute_input":"2021-06-06T15:29:21.343961Z","iopub.status.idle":"2021-06-06T15:29:21.358586Z","shell.execute_reply.started":"2021-06-06T15:29:21.343915Z","shell.execute_reply":"2021-06-06T15:29:21.357454Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"        id_code  diagnosis\n0  0005cfc8afb6          0\n1  003f0afdcd15          0\n2  006efc72b638          0\n3  00836aaacf06          0\n4  009245722fa4          0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_code</th>\n      <th>diagnosis</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0005cfc8afb6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>003f0afdcd15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>006efc72b638</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00836aaacf06</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>009245722fa4</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Shape of train_data :\", test_csv.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:21.360403Z","iopub.execute_input":"2021-06-06T15:29:21.360858Z","iopub.status.idle":"2021-06-06T15:29:21.371402Z","shell.execute_reply.started":"2021-06-06T15:29:21.360826Z","shell.execute_reply":"2021-06-06T15:29:21.370074Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Shape of train_data : (1928, 2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 5. 定義模型方法<a class=\"anchor\" id=\"5\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"class build_model(nn.Module):\n\n    def __init__(self, count, custom_model_count, timm_model_count, base_model_count):\n        super().__init__()\n        \n        if MODEL_LIST[count] == \"MODEL\":\n            # 載入預訓練模型\n            self.model = torch.load(LOAD_MODEL_PATH[count])\n        elif MODEL_LIST[count] == \"WEIGHT_OF_CUSTOM_MODEL\":\n            # 載入模型架構\n            self.model = CUSTOM_MODEL[custom_model_count]\n        elif MODEL_LIST[count] == \"WEIGHT_OF_TIMM_MODEL\":\n            self.model = timm.create_model(BASE_MODEL[timm_model_count], pretrained = None)\n        else:\n            self.model = BASE_MODEL[base_model_count](pretrained = None)\n\n        if MODEL_LIST[count] != \"MODEL\":\n            # 載入預訓練權重\n            model.load_state_dict(LOAD_MODEL_PATH[count])\n\n        if CLASSIFIER_OUTPUT[count]:\n            n_features = self.model.classifier.in_features\n            self.model.classifier = nn.Sequential(nn.Dropout(DROPOUT[count]), nn.Linear(n_features, CLASSES, bias = BIAS[count]))\n        else:\n            n_features = self.model.fc.in_features\n            self.model.fc = nn.Sequential(nn.Dropout(DROPOUT[count]), nn.Linear(n_features, CLASSES, bias = BIAS[count]))\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:21.373185Z","iopub.execute_input":"2021-06-06T15:29:21.373603Z","iopub.status.idle":"2021-06-06T15:29:21.384453Z","shell.execute_reply.started":"2021-06-06T15:29:21.373560Z","shell.execute_reply":"2021-06-06T15:29:21.383627Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# 6. 製作資料集＆資料擴增＆推論模型<a class=\"anchor\" id=\"6\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, df, transforms = None):\n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms = transforms\n        \n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, index: int):\n        image_name = self.df[IMAGE_NAME].values[index]\n\n        if IMAGE_NAME_HAVE_EXTENSION:\n            image_path = TEST_DATA_PATH + image_name\n        else:\n            image_path = TEST_DATA_PATH + image_name + IMAGE_NAME_EXTENSION\n            \n        image = cv2.imread(image_path)\n        \n        if COLOR_CONVERT_RGB:\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transforms is not None:\n            image = self.transforms(image = image)['image']\n            \n        return image","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:21.385867Z","iopub.execute_input":"2021-06-06T15:29:21.386374Z","iopub.status.idle":"2021-06-06T15:29:21.395643Z","shell.execute_reply.started":"2021-06-06T15:29:21.386341Z","shell.execute_reply":"2021-06-06T15:29:21.394758Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# 確定是否將應用此增強。機率為 p = 1.0 意味著我們總是從上面應用轉換。\n# p = 0 將意味著將忽略轉換塊。\n# 0 < p < 1.0 等於每個擴增都具有以一定概率應用的選項。\n# OneOf 隨機選取一種增強擴增\n\ndef get_test_transforms(fold):\n    return A.Compose([\n        A.Blur(blur_limit = BLUR_LIMIT, \n               p = P_BLUR), # 模糊\n        A.HorizontalFlip(p = P_HORIZONTALFLIP), # 水平翻轉\n        A.VerticalFlip(p = P_VERTICALFLIP), # 垂直翻轉\n        A.Flip(p = P_FLIP), # 水平和垂直翻轉\n        A.Resize(height = RESIZE_HEIGHT[fold], \n                 width = RESIZE_WIDTH[fold], \n                 p = P_RESIZE), # 縮放\n        A.RandomResizedCrop(height = RANDOMRESIZEDCROP_HEIGHT[fold], \n                            width = RANDOMRESIZEDCROP_WIDTH[fold], \n                            scale = RANDOMRESIZEDCROP_SCALE, \n                            p = P_RANDOMRESIZEDCROP), #隨機縮放剪裁\n        A.RandomRotate90(p = P_RANDOMROTATE90), # 隨機旋轉90度\n        A.ShiftScaleRotate(shift_limit = SHIFTSCALEROTATE_SHIFT_LIMIT, \n                           scale_limit = SHIFTSCALEROTATE_SCALE_LIMIT, \n                           rotate_limit = SHIFTSCALEROTATE_ROTATE_LIMIT, \n                           p = P_SHIFTSCALEROTATE), # 平移縮放旋轉\n        A.ElasticTransform(alpha = ELATICTRANSFORM_ALPHA, \n                           sigma = ELATICTRANSFORM_SIGMA, \n                           alpha_affine = ELATICTRANSFORM_ALPHA_AFFINE, \n                           p = P_ELATICTRANSFORM), # 彈性變換\n        A.GridDistortion(num_steps = GRIDDISTORTION_NUM_STEPS, \n                         p = P_GRIDDISTORTION), # 網格失真\n        A.RandomBrightnessContrast(brightness_limit = RANDOMBRIGHTNESSCONTRAST_BRIGHTNESS_LIMIT, \n                                   contrast_limit = RANDOMBRIGHTNESSCONTRAST_CONTRAST_LIMIT, \n                                   p = P_RANDOMBRIGHTNESSCONTRAST_CONTRAST), # 隨機亮度對比度\n        A.HueSaturationValue(hue_shift_limit = HUESATURATIONVALUE_HUE_SHIFT_LIMIT, \n                             sat_shift_limit = HUESATURATIONVALUE_SAT_SHIFT_LIMIT, \n                             val_shift_limit = HUESATURATIONVALUE_VAL_SHIFT_LIMIT, \n                             p = P_HUESATURATIONVALUE), # 隨機色調飽和度值\n        A.CLAHE(clip_limit = CLAHE_CLIP_LIMIT, \n                p = P_CLAHE), # 將對比度受限的自適應直方圖均衡化應用於輸入圖像\n        A.Cutout(num_holes = COARSEDROPOUT_NUM_HOLES, \n                        max_h_size = COARSEDROPOUT_MAX_H_SIZE, \n                        max_w_size = COARSEDROPOUT_MAX_W_SIZE, \n                        p = P_COARSEDROPOUT), # 隨機在圖像上生成黑色矩形\n        A.Normalize(\n             mean = NORMALIZE_MEAN, \n             std = NORMALIZE_STD, \n            max_pixel_value = NORMALIZE_MAX_PIXEL_VALUE, \n            p = P_NORMALIZE), # 正規化。\n        ToTensorV2(p = P_TOTENSORV2) # 歸一化\n    ], p = P_TRAIN_TRANSFORMS)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:21.396912Z","iopub.execute_input":"2021-06-06T15:29:21.397314Z","iopub.status.idle":"2021-06-06T15:29:21.409961Z","shell.execute_reply.started":"2021-06-06T15:29:21.397275Z","shell.execute_reply":"2021-06-06T15:29:21.408880Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def prepare_dataloader(fold, count):\n    test_dataset = MyDataset(test_csv, transforms = get_test_transforms(fold))\n    test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE[count], pin_memory = PIN_MEMORY, \n                                               shuffle = False, num_workers = NUM_WORKERS)\n    return test_loader","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:21.411244Z","iopub.execute_input":"2021-06-06T15:29:21.411603Z","iopub.status.idle":"2021-06-06T15:29:21.426985Z","shell.execute_reply.started":"2021-06-06T15:29:21.411573Z","shell.execute_reply":"2021-06-06T15:29:21.425301Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# def inference_one_epoch(model, data_loader, device):\n#     model.eval()\n#     image_preds_all = []\n#     # pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n#     with torch.no_grad():\n#         for step, (imgs) in enumerate(data_loader):\n#             imgs = imgs.to(device).float()\n\n#             image_preds = model(imgs)   #output = model(input)\n#             image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n        \n    \n#     image_preds_all = np.concatenate(image_preds_all, axis=0)\n#     return image_preds_all","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:21.428498Z","iopub.execute_input":"2021-06-06T15:29:21.428887Z","iopub.status.idle":"2021-06-06T15:29:21.439754Z","shell.execute_reply.started":"2021-06-06T15:29:21.428851Z","shell.execute_reply":"2021-06-06T15:29:21.438429Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def inference_process(count, fold, kf):\n    if kf:\n        print('Fold %i - image size %i with %s and batch size %i'%(fold+1,IMAGE_SIZE[count],LOAD_MODEL_NAME[count].upper(),BATCH_SIZE[count]))\n    else:\n        print('Image size %i with %s and batch_size %i'%(IMAGE_SIZE[count],LOAD_MODEL_NAME[count].upper(),BATCH_SIZE[count]))\n    \n\n#     build_model(count, custom_model_count, timm_model_count, base_model_count)\n#     model = model.to(DEVICE)\n#     model.eval()\n    \n    \n#         if FOLD[0] >1:\n#             count = 0\n#             for x in LOAD_MODEL_PATH:\n#                 LOAD_MODEL_PATH[count] = x + LOAD_MODEL_NAME[count]\n#                 print(LOAD_MODEL_PATH[count])\n#         else:\n#             count = 0\n#             for x in LOAD_MODEL_PATH:\n#                 LOAD_MODEL_PATH[count] = x + LOAD_MODEL_NAME[count]\n#                 print(LOAD_MODEL_PATH[count])\n    \n    \n#     test_loader = prepare_dataloader(fold, count)\n\n#     del test_loader\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:21.441415Z","iopub.execute_input":"2021-06-06T15:29:21.441866Z","iopub.status.idle":"2021-06-06T15:29:21.452013Z","shell.execute_reply.started":"2021-06-06T15:29:21.441814Z","shell.execute_reply":"2021-06-06T15:29:21.450824Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def main():\n    try:\n        print('Inference start')\n        since = time.time()    \n        for count in range(len(LOAD_MODEL_NAME)):\n            if FOLD[count] > 1:\n                for fold in enumerate(KF.split(np.arange(train_csv.shape[0]))):\n                    inference_process(count, fold = fold, kf = True)\n            else:\n                inference_process(count, fold = 0, kf = False)\n        time_elapsed = time.time() - since\n        print('Inference complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    except Exception as exception:\n        print(exception)\n        raise","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:21.453753Z","iopub.execute_input":"2021-06-06T15:29:21.454190Z","iopub.status.idle":"2021-06-06T15:29:21.462712Z","shell.execute_reply.started":"2021-06-06T15:29:21.454145Z","shell.execute_reply":"2021-06-06T15:29:21.461839Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    main()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:29:21.463832Z","iopub.execute_input":"2021-06-06T15:29:21.464323Z","iopub.status.idle":"2021-06-06T15:29:22.052480Z","shell.execute_reply.started":"2021-06-06T15:29:21.464287Z","shell.execute_reply":"2021-06-06T15:29:22.051393Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Inference start\nImage size 224 with EFFICIENTNET_V2_B0 and batch_size 256\nImage size 224 with EFFICIENTNET_V2_B0 and batch_size 256\nImage size 224 with EFFICIENTNET_V2_B0 and batch_size 256\nInference complete in 0m 1s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 7. 待辦事項<a class=\"anchor\" id=\"7\"></a>\n[Back to Table of Contents](#0)\n1. FOLD\n1. TTA\n1. ENSEMBLE","metadata":{}}]}