{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image_Classification_Pytorch (Inference)","metadata":{}},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# Table of Contents\n\n1. [套件安裝與載入](#1)\n1. [環境檢測與設定](#2)\n1. [開發參數設定](#3)\n1. [資料處理](#4)\n    -  [載入CSV檔](#4.1)\n    -  [檢查CSV檔缺失值](#4.2)\n1. [定義模型方法](#5)\n1. [製作資料集＆資料擴增＆推論模型](#6)\n1. [待辦事項](#7)","metadata":{}},{"cell_type":"markdown","source":"# 1. 套件安裝與載入<a class=\"anchor\" id=\"1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"!pip3 install git+https://github.com/rwightman/pytorch-image-models.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 資料處理套件\nimport os\nimport gc\nimport cv2\nimport sys\nimport time\nimport timm\nimport random\nimport numpy as np\nimport pandas as pd\nimport albumentations as A\n\nfrom tqdm import tqdm\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pytorch深度學習模組套件\nimport torch\nimport torch.nn as nn\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. 環境檢測與設定<a class=\"anchor\" id=\"2\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nDEVICE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 查看pytorch版本\nprint(torch.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''執行環境參數設定'''\n\n# (Boolean)是否為本機\nLOCAL = False\n\n# (Boolean)是否為 Colab\nCOLAB = False\n\n\n'''檔案路徑參數設定'''\n\n# (String)Root路徑\nif LOCAL:\n    PATH = r'../'\nelif COLAB:\n    PATH = r'/content/drive/My Drive/Colab Notebooks/'\nelse:\n    PATH = r'../input/'\n    \n# (String)資料根路徑\nDATA_ROOT_PATH = PATH+r'resized-2015-2019-blindness-detection-images/' \n\n# (String)CSV根路徑\nCSV_ROOT_PATH = PATH+r'aptos2019-blindness-detection/' \n\n# (String)測試資料路徑\nTEST_DATA_PATH = DATA_ROOT_PATH+r'resized test 19/'\n\n# (String)測試CSV路徑\nTEST_CSV_PATH = CSV_ROOT_PATH+r'sample_submission.csv'\n\n# (Boolean)是否要匯入Library\nIMPORT_PYTORCH_LIBRARY = False\n\n# (String)Library的路徑\nPYTORCH_LIBRARY_PATH = PATH + \"PyTorch_Library/\"\n\n# (String)模型/權重名稱\nMODEL_NAME = ['efficientnet_v2_b0', 'efficientnet_v2_b0', 'efficientnet_v2_b0']\n\n# (String)讀取預訓練模型/權重的儲存路徑\nLOAD_MODEL_PATH = [PATH + r'test1111/', \n                   PATH + r'test1111/', \n                   PATH + r'test1111/']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DEVICE != torch.device(\"cpu\"):\n    !nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not LOCAL and COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    \nif IMPORT_PYTORCH_LIBRARY:\n    sys.path.append(PYTORCH_LIBRARY_PATH + \"Custom_Loss.py\")\n    sys.path.append(PYTORCH_LIBRARY_PATH + \"Custom_Model.py\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. 開發參數設定<a class=\"anchor\" id=\"3\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"'''客製參數設定'''\n\n\n'''資料參數設定'''\n\n# (Int)分類數量\nCLASSES = 5\n\n# (Int)集成模型數量\nENSEMBLE_MODEL_COUNT = 3\n\n# (Int)有CSV檔該參數才有用，1則為不做交叉驗證\nFOLD = [1]*ENSEMBLE_MODEL_COUNT\n\n# (Int)圖片尺寸\nIMAGE_SIZE = [224]*ENSEMBLE_MODEL_COUNT\n\n# (String)圖片副檔名\nIMAGE_NAME_EXTENSION = '.jpg'\n\n# (String)CSV圖片檔名欄位\nIMAGE_NAME = 'id_code'\n\n# (String)CSV標籤欄位\nLABEL_NAME = 'diagnosis'\n\n# (String)CSV標籤欄位類型\nLABEL_NAME_TYPE = 'string'\n\n# (Boolean)CSV圖片檔名欄位是否包含副檔名\nIMAGE_NAME_HAVE_EXTENSION = False\n\n#  (Boolean)圖像轉為RGB\nCOLOR_CONVERT_RGB = True\n\n# (Int)不同的種子會產生不同的Random或分層K-FOLD分裂, 42則是預設固定種子\nSEED = 42\n\n# (Boolean)是否資料轉Tensor時啟動鎖頁內存(GPU內存)，而不鎖頁內存就是會使用到硬碟虛擬內存\nPIN_MEMORY = False\n\n# (Int)要用於數據加載的子進程數。0表示將在主進程中加載數據。（默認值：0）\nNUM_WORKERS = 0\n    \n# (Boolean)如為True每次返回的卷積算法將是確定的，即默認算法\nCUDNN_DETERMINISTIC = True\n\n# (Boolean)PyTorch 中對模型裡的卷積層進行預先的優化，也就是在每一個卷積層中測試 cuDNN 提供的所有卷積實現算法，\n# 然後選擇最快的那個。這樣在模型啟動的時候，只要額外多花一點點預處理時間，就可以較大幅度地減少訓練時間\nCUDNN_BENCHMARK = True\n\n\n'''資料擴增參數設定\n\n資料擴增教學\nhttps://zhuanlan.zhihu.com/p/107399127\n\n資料擴增Doc\nhttps://vfdev-5-albumentations.readthedocs.io/en/docs_pytorch_fix/api/augmentations.html\n'''\n\n# (Float)訓練集資料擴增的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_TRAIN_TRANSFORMS = 1.0\n\n# (Float)驗證集資料擴增的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_VAL_TRANSFORMS = 1.0\n\n# 以下資料擴增為訓練集使用=============================================\n\n# (Float)模糊的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_BLUR = 0\n\n# (Int)模糊的上限\nBLUR_LIMIT = 3\n\n# (Float)水平翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_HORIZONTALFLIP = 0\n\n# (Float)垂直翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_VERTICALFLIP = 0\n\n# (Float)水平和垂直翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_FLIP = 0\n\n# (Float)隨機旋轉90度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RANDOMROTATE90 = 0\n\n# (Float)平移縮放旋轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_SHIFTSCALEROTATE = 0\n\n# (Float)平移縮放旋轉的平移上限\nSHIFTSCALEROTATE_SHIFT_LIMIT = 0.0625\n\n# (Float)平移縮放旋轉的縮放上限\nSHIFTSCALEROTATE_SCALE_LIMIT = 0.1\n\n# (Float)平移縮放旋轉的旋轉上限\nSHIFTSCALEROTATE_ROTATE_LIMIT = 45\n\n# (Float)彈性變換的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_ELATICTRANSFORM = 0\n\n# (Float)彈性變換的alpha高斯過濾參數\nELATICTRANSFORM_ALPHA = 1\n\n# (Float)彈性變換的sigma高斯過濾參數\nELATICTRANSFORM_SIGMA = 50\n\n# (Float)彈性變換的alpha_affine，範圍為（-alpha_affine，alpha_affine）\nELATICTRANSFORM_ALPHA_AFFINE = 50\n\n# (Float)網格失真的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_GRIDDISTORTION = 0\n\n# (Int)網格失真的每一條邊上網格單元數量\nGRIDDISTORTION_NUM_STEPS = 5\n\n# (Float)隨機亮度對比度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RANDOMBRIGHTNESSCONTRAST_CONTRAST = 0\n\n# (Float)隨機亮度的上限\nRANDOMBRIGHTNESSCONTRAST_BRIGHTNESS_LIMIT = 0.2\n\n# (Float)隨機對比度的上限\nRANDOMBRIGHTNESSCONTRAST_CONTRAST_LIMIT = 0.2\n\n# (Float)隨機色調飽和度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_HUESATURATIONVALUE = 0\n\n# (Float)隨機色調飽和度的色調上限\nHUESATURATIONVALUE_HUE_SHIFT_LIMIT = 20\n\n# (Float)隨機色調飽和度的飽和度上限\nHUESATURATIONVALUE_SAT_SHIFT_LIMIT = 30\n\n# (Float)隨機色調飽和度的值上限\nHUESATURATIONVALUE_VAL_SHIFT_LIMIT = 20\n\n# (Float)對比度受限自適應直方圖均衡的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_CLAHE = 0\n\n# (Float)對比度受限自適應直方圖均衡的對比度上限\nCLAHE_CLIP_LIMIT = 4.0\n\n# (Float)隨機在圖像上生成黑色矩形的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_COARSEDROPOUT = 0\n\n# (Int)隨機在圖像上生成黑色矩形的數量\nCOARSEDROPOUT_NUM_HOLES = 8\n\n# (Int)隨機在圖像上生成黑色矩形的最大高度\nCOARSEDROPOUT_MAX_H_SIZE = 8\n\n# (Int)隨機在圖像上生成黑色矩形的最大寬度\nCOARSEDROPOUT_MAX_W_SIZE = 8\n\n# (Float)隨機縮放剪裁的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RANDOMRESIZEDCROP = 0\n\n# (Float Tuple)隨機縮放剪裁之前的圖像比例縮放\nRANDOMRESIZEDCROP_SCALE = (0.08, 1.0)\n\n# (Int)隨機縮放剪裁之前的圖像高度\nRANDOMRESIZEDCROP_HEIGHT = IMAGE_SIZE\n\n# (Int)隨機縮放剪裁之前的圖像寬度\nRANDOMRESIZEDCROP_WIDTH = IMAGE_SIZE\n\n# 以上資料擴增為訓練集使用=============================================\n\n# 以下資料擴增為訓練集和驗證集共用======================================\n\n# (Float)縮放的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RESIZE = 1.0\n\n# (Int)縮放後的圖片高度\nRESIZE_HEIGHT = IMAGE_SIZE\n\n# (Int)縮放後的圖片寬度\nRESIZE_WIDTH = IMAGE_SIZE\n\n# (Float)正規化的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_NORMALIZE = 1.0\n\n# (List)正規化的平均值([0,1]的參考平均值:[0.485, 0.456, 0.406], [-1,1]的參考平均值:[0.5, 0.5, 0.5])\nNORMALIZE_MEAN = [0.485, 0.456, 0.406]\n\n# (List)正規化的標準差([0,1]的參考標準差[0.229, 0.224, 0.225], [-1,1]的參考標準差[0.5, 0.5, 0.5])\nNORMALIZE_STD = [0.229, 0.224, 0.225]\n\n# (Float)正規化的PIXEL最大值(參考PIXEL最大值255.0)\nNORMALIZE_MAX_PIXEL_VALUE = 255.0\n\n# (Float)歸一化的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n# ToTensorV2()將[0, 255]的PIL.Image或[H, W, C]的numpy.ndarray數據，\n# 轉換為形狀[C, H, W]的torch.FloadTensor，並歸一化。\nP_TOTENSORV2 = 1.0\n\n# 以上資料擴增為訓練集和驗證集共用======================================\n\n\n''''模型參數設定'''\n\n# (Boolean)是否依照設定路徑，載入完整客製(模型+權重)\nLOAD_MODEL = [False]*ENSEMBLE_MODEL_COUNT\n\n# (Boolean)使用客制模型，None則使用基本模型\nCUSTOM_MODEL = [None]*ENSEMBLE_MODEL_COUNT\n\nif CUSTOM_MODEL is None and not LOAD_MODEL:\n    # (Boolean)使用基礎timm模型，如為False則使用基礎Pytorch模型\n    USE_BASE_TIMM_MODEL = True\n    if USE_BASE_TIMM_MODEL:\n        # https://github.com/rwightman/pytorch-image-models#getting-started-documentation\n        # (Model)建立timm模型\n        BASE_MODEL = [\"tf_efficientnetv2_b0\"]*ENSEMBLE_MODEL_COUNT\n    else:\n        # (Model)建立Pytorch模型\n        BASE_MODEL = [models.resnet18]*ENSEMBLE_MODEL_COUNT\n    \n    # (Boolean)基礎模型是否使用分類層輸出，否則為全連接層\n    CLASSIFIER_OUTPUT = [True]*ENSEMBLE_MODEL_COUNT\n\n    # (Float)Dropout比率\n    DROPOUT = [1]*ENSEMBLE_MODEL_COUNT\n\n    # (Boolean)Bias偏移量\n    BIAS = [True]*ENSEMBLE_MODEL_COUNT\n    \n\n''''訓練參數設定'''\n\n# (Int List)每批推論的尺寸\nBATCH_SIZE = 256","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = CUDNN_DETERMINISTIC\n    torch.backends.cudnn.benchmark = CUDNN_BENCHMARK\n\nseed_everything(SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. 資料處理<a class=\"anchor\" id=\"4\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"markdown","source":"## 4.1 載入CSV檔 <a class=\"anchor\" id=\"4.1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"print('Reading data...')\n\n# 讀取訓練資料集CSV檔\ntest_csv = pd.read_csv(TEST_CSV_PATH,encoding=\"utf8\")\n\nprint('Reading data completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 顯示訓練資料集CSV檔\ntest_csv.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of train_data :\", test_csv.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. 定義模型方法<a class=\"anchor\" id=\"5\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"class build_model(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        if USE_BASE_TIMM_MODEL:\n            self.model = timm.create_model(BASE_MODEL, pretrained = None)\n        else:\n            self.model = BASE_MODEL(pretrained = None)\n\n        for param in self.model.parameters():\n            param.requires_grad = False\n\n        if CLASSIFIER_OUTPUT:\n            n_features = self.model.classifier.in_features\n            self.model.classifier = nn.Sequential(nn.Dropout(DROPOUT), nn.Linear(n_features, CLASSES, bias = BIAS))\n        else:\n            n_features = self.model.fc.in_features\n            self.model.fc = nn.Sequential(nn.Dropout(DROPOUT), nn.Linear(n_features, CLASSES, bias = BIAS))\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_MODEL:\n    # 載入預訓練模型\n    model = torch.load(LOAD_MODEL_PATH) \nelif CUSTOM_MODEL is not None:    \n    # ==== INIT CUSTIOM MODEL\n    model = CUSTOM_MODEL\n    # 載入預訓練權重\n    model.load_state_dict(LOAD_WEIGHTS_PATH)\nelse:\n    # 創建model\n    model = build_model()\n    # 載入預訓練權重\n    model.load_state_dict(torch.load(LOAD_WEIGHTS_PATH))\n        \nmodel = model.to(DEVICE)\nmodel.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. 製作資料集＆資料擴增＆推論模型<a class=\"anchor\" id=\"6\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, df, transforms = None):\n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms = transforms\n        \n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, index: int):\n        image_name = self.df[IMAGE_NAME].values[index]\n\n        if IMAGE_NAME_HAVE_EXTENSION:\n            image_path = TEST_DATA_PATH + image_name\n        else:\n            image_path = TEST_DATA_PATH + image_name + IMAGE_NAME_EXTENSION\n            \n        image = cv2.imread(image_path)\n        \n        if COLOR_CONVERT_RGB:\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transforms is not None:\n            image = self.transforms(image = image)['image']\n            \n        return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 確定是否將應用此增強。機率為 p = 1.0 意味著我們總是從上面應用轉換。\n# p = 0 將意味著將忽略轉換塊。\n# 0 < p < 1.0 等於每個擴增都具有以一定概率應用的選項。\n# OneOf 隨機選取一種增強擴增\n\ndef get_test_transforms():\n    return A.Compose([\n        A.Blur(blur_limit = BLUR_LIMIT, \n               p = P_BLUR), # 模糊\n        A.HorizontalFlip(p = P_HORIZONTALFLIP), # 水平翻轉\n        A.VerticalFlip(p = P_VERTICALFLIP), # 垂直翻轉\n        A.Flip(p = P_FLIP), # 水平和垂直翻轉\n        A.Resize(height = RESIZE_HEIGHT, \n                 width = RESIZE_WIDTH, \n                 p = P_RESIZE), # 縮放\n        A.RandomResizedCrop(height = RANDOMRESIZEDCROP_HEIGHT, \n                            width = RANDOMRESIZEDCROP_WIDTH, \n                            scale = RANDOMRESIZEDCROP_SCALE, \n                            p = P_RANDOMRESIZEDCROP), #隨機縮放剪裁\n        A.RandomRotate90(p = P_RANDOMROTATE90), # 隨機旋轉90度\n        A.ShiftScaleRotate(shift_limit = SHIFTSCALEROTATE_SHIFT_LIMIT, \n                           scale_limit = SHIFTSCALEROTATE_SCALE_LIMIT, \n                           rotate_limit = SHIFTSCALEROTATE_ROTATE_LIMIT, \n                           p = P_SHIFTSCALEROTATE), # 平移縮放旋轉\n        A.ElasticTransform(alpha = ELATICTRANSFORM_ALPHA, \n                           sigma = ELATICTRANSFORM_SIGMA, \n                           alpha_affine = ELATICTRANSFORM_ALPHA_AFFINE, \n                           p = P_ELATICTRANSFORM), # 彈性變換\n        A.GridDistortion(num_steps = GRIDDISTORTION_NUM_STEPS, \n                         p = P_GRIDDISTORTION), # 網格失真\n        A.RandomBrightnessContrast(brightness_limit = RANDOMBRIGHTNESSCONTRAST_BRIGHTNESS_LIMIT, \n                                   contrast_limit = RANDOMBRIGHTNESSCONTRAST_CONTRAST_LIMIT, \n                                   p = P_RANDOMBRIGHTNESSCONTRAST_CONTRAST), # 隨機亮度對比度\n        A.HueSaturationValue(hue_shift_limit = HUESATURATIONVALUE_HUE_SHIFT_LIMIT, \n                             sat_shift_limit = HUESATURATIONVALUE_SAT_SHIFT_LIMIT, \n                             val_shift_limit = HUESATURATIONVALUE_VAL_SHIFT_LIMIT, \n                             p = P_HUESATURATIONVALUE), # 隨機色調飽和度值\n        A.CLAHE(clip_limit = CLAHE_CLIP_LIMIT, \n                p = P_CLAHE), # 將對比度受限的自適應直方圖均衡化應用於輸入圖像\n        A.Cutout(num_holes = COARSEDROPOUT_NUM_HOLES, \n                        max_h_size = COARSEDROPOUT_MAX_H_SIZE, \n                        max_w_size = COARSEDROPOUT_MAX_W_SIZE, \n                        p = P_COARSEDROPOUT), # 隨機在圖像上生成黑色矩形\n        A.Normalize(\n             mean = NORMALIZE_MEAN, \n             std = NORMALIZE_STD, \n            max_pixel_value = NORMALIZE_MAX_PIXEL_VALUE, \n            p = P_NORMALIZE), # 正規化。\n        ToTensorV2(p = P_TOTENSORV2) # 歸一化\n    ], p = P_TRAIN_TRANSFORMS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_dataloader():\n    test_dataset = MyDataset(test_csv, transforms = get_test_transforms())\n    test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, pin_memory = PIN_MEMORY, \n                                               shuffle = False, num_workers = NUM_WORKERS)\n    return test_loader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def inference_one_epoch(model, data_loader, device):\n#     model.eval()\n#     image_preds_all = []\n#     # pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n#     with torch.no_grad():\n#         for step, (imgs) in enumerate(data_loader):\n#             imgs = imgs.to(device).float()\n\n#             image_preds = model(imgs)   #output = model(input)\n#             image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n        \n    \n#     image_preds_all = np.concatenate(image_preds_all, axis=0)\n#     return image_preds_all","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def inference_process():\n#     test_loader = prepare_dataloader()\n\n#     del test_loader\n#     gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n    try:\n        print('Inference start')\n        since = time.time()\n        \n        \n        \n#         if FOLD[0] >1:\n#             count = 0\n#             for x in LOAD_MODEL_PATH:\n#                 LOAD_MODEL_PATH[count] = x + MODEL_NAMEp[count]\n#                 print(LOAD_MODEL_PATH[count])\n#         else:\n#             count = 0\n#             for x in LOAD_MODEL_PATH:\n#                 LOAD_MODEL_PATH[count] = x + MODEL_NAMEp[count]\n#                 print(LOAD_MODEL_PATH[count])\n        \n        \n        \n        \n        if FOLD > 1:\n            for fold,(train_index, valid_index) in enumerate(KF.split(np.arange(train_csv.shape[0]), train_csv[LABEL_NAME])):\n#                 inference_process(fold = fold, kf = True, train_index = train_index, valid_index = valid_index)\n        else:\n#             inference_process(fold = 0, kf = False, train_index = None, valid_index = None)\n\n        time_elapsed = time.time() - since\n        print('Inference complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    except Exception as exception:\n        print(exception)\n        raise","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    main()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. 待辦事項<a class=\"anchor\" id=\"7\"></a>\n[Back to Table of Contents](#0)\n1. FOLD\n1. TTA\n1. ENSEMBLE","metadata":{}}]}