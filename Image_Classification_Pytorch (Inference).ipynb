{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image_Classification_Pytorch (Inference)","metadata":{}},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# Table of Contents\n\n1. [套件安裝與載入](#1)\n1. [環境檢測與設定](#2)\n1. [開發參數設定](#3)\n1. [資料處理](#4)\n    -  [載入CSV檔](#4.1)\n    -  [檢查CSV檔缺失值](#4.2)\n1. [定義模型方法](#5)\n1. [製作資料集＆資料擴增＆推論模型](#6)\n1. [待辦事項](#7)","metadata":{}},{"cell_type":"markdown","source":"# 1. 套件安裝與載入<a class=\"anchor\" id=\"1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"!pip3 install git+https://github.com/rwightman/pytorch-image-models.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 資料處理套件\nimport os\nimport gc\nimport cv2\nimport sys\nimport time\nimport timm\nimport random\nimport numpy as np\nimport pandas as pd\nimport albumentations as A\n\nfrom tqdm import tqdm\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pytorch深度學習模組套件\nimport torch\nimport torch.nn as nn\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. 環境檢測與設定<a class=\"anchor\" id=\"2\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nDEVICE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 查看pytorch版本\nprint(torch.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''執行環境參數設定'''\n\n# (Boolean)是否為本機\nLOCAL = False\n\n# (Boolean)是否為 Colab\nCOLAB = False\n\n\n'''檔案路徑參數設定'''\n\n# (String)Root路徑\nif LOCAL:\n    PATH = r'../'\nelif COLAB:\n    PATH = r'/content/drive/My Drive/Colab Notebooks/'\nelse:\n    PATH = r'../input/'\n    \n# (String)資料根路徑\nDATA_ROOT_PATH = PATH+r'resized-2015-2019-diabetic-retinopathy-detection/' \n\n# (String)CSV根路徑\nCSV_ROOT_PATH = PATH+r'aptos2019-blindness-detection/' \n\n# (String)測試資料路徑\nTEST_DATA_PATH = DATA_ROOT_PATH+r'resized_test19/'\n\n# (String)測試CSV路徑\nTEST_CSV_PATH = CSV_ROOT_PATH+r'sample_submission.csv'\n\n# (Boolean)是否要匯入Library\nIMPORT_PYTORCH_LIBRARY = False\n\n# (String)Library的路徑\nPYTORCH_LIBRARY_PATH = PATH + \"PyTorch_Library/\"\n\n# (String)讀取預訓練模型/權重的名稱，當fold model時，後面會自動加_NUMBER\nLOAD_MODEL_NAME = ['tf_efficientnet_b3_ns', 'tf_efficientnet_b3_ns', 'tf_efficientnet_b3_ns']\n\n# (String)讀取預訓練模型/權重的儲存路徑\nLOAD_MODEL_PATH = [PATH + r'test123/', \n                   PATH + r'test123/', \n                   PATH + r'test123/']","metadata":{"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DEVICE != torch.device(\"cpu\"):\n    !nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not LOCAL and COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    \nif IMPORT_PYTORCH_LIBRARY:\n    sys.path.append(PYTORCH_LIBRARY_PATH + \"Custom_Loss.py\")\n    sys.path.append(PYTORCH_LIBRARY_PATH + \"Custom_Model.py\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. 開發參數設定<a class=\"anchor\" id=\"3\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"'''客製參數設定'''\n\n\n'''資料參數設定'''\n\n# (Int)分類數量\nCLASSES = 5\n\n# (Int)集成模型數量\nENSEMBLE_MODEL_COUNT = 3\n\n# (Int List)有CSV檔該參數才有用，1則為不做交叉驗證\nFOLD = [1]*ENSEMBLE_MODEL_COUNT\n\n# (Int List)圖片尺寸\nIMAGE_SIZE = [300]*ENSEMBLE_MODEL_COUNT\n\n# (String)圖片副檔名\nIMAGE_NAME_EXTENSION = '.jpg'\n\n# (String)CSV圖片檔名欄位\nIMAGE_NAME = 'id_code'\n\n# (Boolean)CSV圖片檔名欄位是否包含副檔名\nIMAGE_NAME_HAVE_EXTENSION = False\n\n#  (Boolean)圖像轉為RGB\nCOLOR_CONVERT_RGB = True\n\n# (Int)不同的種子會產生不同的Random或分層K-FOLD分裂, 42則是預設固定種子\nSEED = 42\n    \n# (Boolean)如為True每次返回的卷積算法將是確定的，即默認算法\nCUDNN_DETERMINISTIC = True\n\n# (Boolean)PyTorch 中對模型裡的卷積層進行預先的優化，也就是在每一個卷積層中測試 cuDNN 提供的所有卷積實現算法，\n# 然後選擇最快的那個。這樣在模型啟動的時候，只要額外多花一點點預處理時間，就可以較大幅度地減少訓練時間\nCUDNN_BENCHMARK = True\n\n\n'''資料擴增參數設定\n\n資料擴增教學\nhttps://zhuanlan.zhihu.com/p/107399127\n\n資料擴增Doc\nhttps://vfdev-5-albumentations.readthedocs.io/en/docs_pytorch_fix/api/augmentations.html\n'''\n\n# (Float List)訓練集資料擴增的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_TEST_TRANSFORMS = [1.0]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)模糊的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_BLUR = [0]*ENSEMBLE_MODEL_COUNT\n\n# (Int List)模糊的上限\nBLUR_LIMIT = [3]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)水平翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_HORIZONTALFLIP = [0]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)垂直翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_VERTICALFLIP = [0]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)水平和垂直翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_FLIP = [0]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)隨機旋轉90度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RANDOMROTATE90 = [0]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)平移縮放旋轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_SHIFTSCALEROTATE = [0]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)平移縮放旋轉的平移上限\nSHIFTSCALEROTATE_SHIFT_LIMIT = [0.0625]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)平移縮放旋轉的縮放上限\nSHIFTSCALEROTATE_SCALE_LIMIT = [0.1]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)平移縮放旋轉的旋轉上限\nSHIFTSCALEROTATE_ROTATE_LIMIT = [45]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)彈性變換的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_ELATICTRANSFORM = [0]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)彈性變換的alpha高斯過濾參數\nELATICTRANSFORM_ALPHA = [1]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)彈性變換的sigma高斯過濾參數\nELATICTRANSFORM_SIGMA = [50]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)彈性變換的alpha_affine，範圍為（-alpha_affine，alpha_affine）\nELATICTRANSFORM_ALPHA_AFFINE = [50]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)網格失真的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_GRIDDISTORTION = [0]*ENSEMBLE_MODEL_COUNT\n\n# (Int List)網格失真的每一條邊上網格單元數量\nGRIDDISTORTION_NUM_STEPS = [5]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)隨機亮度對比度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RANDOMBRIGHTNESSCONTRAST_CONTRAST = [0]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)隨機亮度的上限\nRANDOMBRIGHTNESSCONTRAST_BRIGHTNESS_LIMIT = [0.2]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)隨機對比度的上限\nRANDOMBRIGHTNESSCONTRAST_CONTRAST_LIMIT = [0.2]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)隨機色調飽和度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_HUESATURATIONVALUE = [0]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)隨機色調飽和度的色調上限\nHUESATURATIONVALUE_HUE_SHIFT_LIMIT = [20]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)隨機色調飽和度的飽和度上限\nHUESATURATIONVALUE_SAT_SHIFT_LIMIT = [30]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)隨機色調飽和度的值上限\nHUESATURATIONVALUE_VAL_SHIFT_LIMIT = [20]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)對比度受限自適應直方圖均衡的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_CLAHE = [0]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)對比度受限自適應直方圖均衡的對比度上限\nCLAHE_CLIP_LIMIT = [4.0]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)隨機在圖像上生成黑色矩形的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_COARSEDROPOUT = [0]*ENSEMBLE_MODEL_COUNT\n\n# (Int List)隨機在圖像上生成黑色矩形的數量\nCOARSEDROPOUT_NUM_HOLES = [8]*ENSEMBLE_MODEL_COUNT\n\n# (Int List)隨機在圖像上生成黑色矩形的最大高度\nCOARSEDROPOUT_MAX_H_SIZE = [8]*ENSEMBLE_MODEL_COUNT\n\n# (Int List)隨機在圖像上生成黑色矩形的最大寬度\nCOARSEDROPOUT_MAX_W_SIZE = [8]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)隨機縮放剪裁的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RANDOMRESIZEDCROP = [0]*ENSEMBLE_MODEL_COUNT\n\n# (Float Tuple of List)隨機縮放剪裁之前的圖像比例縮放\nRANDOMRESIZEDCROP_SCALE = [(0.08, 1.0)]*ENSEMBLE_MODEL_COUNT\n\n# (Int List)隨機縮放剪裁之前的圖像高度\nRANDOMRESIZEDCROP_HEIGHT = IMAGE_SIZE\n\n# (Int List)隨機縮放剪裁之前的圖像寬度\nRANDOMRESIZEDCROP_WIDTH = IMAGE_SIZE\n\n# (Float List)縮放的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RESIZE = [1.0]*ENSEMBLE_MODEL_COUNT\n\n# (Int List)縮放後的圖片高度\nRESIZE_HEIGHT = IMAGE_SIZE\n\n# (Int List)縮放後的圖片寬度\nRESIZE_WIDTH = IMAGE_SIZE\n\n# (Float List)正規化的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_NORMALIZE = [1.0]*ENSEMBLE_MODEL_COUNT\n\n# (Float List of List)正規化的平均值([0,1]的參考平均值:[0.485, 0.456, 0.406], [-1,1]的參考平均值:[0.5, 0.5, 0.5])\nNORMALIZE_MEAN = [[0.485, 0.456, 0.406]]*ENSEMBLE_MODEL_COUNT\n\n# (Float List of List)正規化的標準差([0,1]的參考標準差[0.229, 0.224, 0.225], [-1,1]的參考標準差[0.5, 0.5, 0.5])\nNORMALIZE_STD = [[0.229, 0.224, 0.225]]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)正規化的PIXEL最大值(參考PIXEL最大值255.0)\nNORMALIZE_MAX_PIXEL_VALUE = [255.0]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)歸一化的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n# ToTensorV2()將[0, 255]的PIL.Image或[H, W, C]的numpy.ndarray數據，\n# 轉換為形狀[C, H, W]的torch.FloadTensor，並歸一化。\nP_TOTENSORV2 = [1.0]*ENSEMBLE_MODEL_COUNT\n\n\n''''模型參數設定'''\n\n# (String List)模型載入方式 - 1 MODEL;2 WEIGHT_OF_CUSTOM_MODEL;\n# 3 WEIGHT_OF_TIMM_MODEL;4 WEIGHT_OF_BASE_MODEL\nMODEL_LIST = [3]*ENSEMBLE_MODEL_COUNT\n\nif 2 in MODEL_LIST:\n    # (Model List)模型載入方式有CUSTOM_MODEL，依照index位置填入\n    CUSTOM_MODEL = [None]*ENSEMBLE_MODEL_COUNT\n\nif 3 in MODEL_LIST:\n    # (Model List)模型載入方式有TIMM_MODEL，依照index位置填入\n    TIMM_MODEL = [\"tf_efficientnet_b3_ns\"]*ENSEMBLE_MODEL_COUNT\n\nif 4 in MODEL_LIST:\n    # (Model List)模型載入方式有BASE_MODEL，依照index位置填入\n    BASE_MODEL = [None]*ENSEMBLE_MODEL_COUNT\n\n# (Boolean List)模型是否增加TOP層\nINCULDE_TOP = [True]*ENSEMBLE_MODEL_COUNT\n\n# (Boolean List)模型是否使用分類層輸出，否則為全連接層\nCLASSIFIER_OUTPUT = [True]*ENSEMBLE_MODEL_COUNT\n\n# (Float List)Dropout比率\nDROPOUT = [0.5]*ENSEMBLE_MODEL_COUNT\n\n# (Boolean List)Bias偏移量\nBIAS = [True]*ENSEMBLE_MODEL_COUNT\n\n# (Boolean List)是否印出完整模型\nMODEL_PRINT = [False]*ENSEMBLE_MODEL_COUNT\n\n\n''''推論參數設定'''\n\n# (Int List)每批推論的尺寸\nBATCH_SIZE = [256]*ENSEMBLE_MODEL_COUNT\n\n# (Int List)每個模型推論的次數\nINFERENCE_COUNT = [1]*ENSEMBLE_MODEL_COUNT\n\n# (Int)指定列印進度條的位置（從0開始）\nTQDM_POSITION = 0\n\n# (Boolean)保留迭代結束時進度條的所有痕跡。如果是None，只會在position是0時離開\nTQDM_LEAVE = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = CUDNN_DETERMINISTIC\n    torch.backends.cudnn.benchmark = CUDNN_BENCHMARK\n\nseed_everything(SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. 資料處理<a class=\"anchor\" id=\"4\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"markdown","source":"## 4.1 載入CSV檔 <a class=\"anchor\" id=\"4.1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"print('Reading data...')\n\n# 讀取訓練資料集CSV檔\ntest_csv = pd.read_csv(TEST_CSV_PATH,encoding=\"utf8\")\n\nprint('Reading data completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 顯示訓練資料集CSV檔\ntest_csv.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of train_data :\", test_csv.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. 定義模型方法<a class=\"anchor\" id=\"5\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"class build_model(nn.Module):\n\n    def __init__(self, count, model_path):\n        super().__init__()\n        \n        if MODEL_LIST[count] == 1:\n            # 載入預訓練模型\n            self.model = torch.load(model_path)\n        elif MODEL_LIST[count] == 2:\n            # 載入模型架構\n            self.model = CUSTOM_MODEL[count]\n        elif MODEL_LIST[count] == 3:\n            self.model = timm.create_model(TIMM_MODEL[count], pretrained = None)\n        elif MODEL_LIST[count] == 4:\n            self.model = BASE_MODEL[count](pretrained = None)\n\n        if INCULDE_TOP[count]:\n            if CLASSIFIER_OUTPUT[count]:\n                n_features = self.model.classifier.in_features\n                self.model.classifier = nn.Sequential(\n                    nn.Dropout(DROPOUT[count]), \n                    nn.Linear(n_features, CLASSES, bias = BIAS[count])\n                )\n            else:\n                n_features = self.model.fc.in_features\n                self.model.fc = nn.Sequential(\n                    nn.Dropout(DROPOUT[count]), \n                    nn.Linear(n_features, CLASSES, bias = BIAS[count])\n                )\n            \n    def forward(self, x):\n        x = self.model(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. 製作資料集＆資料擴增＆推論模型<a class=\"anchor\" id=\"6\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, df, transforms = None):\n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms = transforms\n        \n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, index: int):\n        image_name = self.df[IMAGE_NAME].values[index]\n\n        if IMAGE_NAME_HAVE_EXTENSION:\n            image_path = TEST_DATA_PATH + image_name\n        else:\n            image_path = TEST_DATA_PATH + image_name + IMAGE_NAME_EXTENSION\n            \n        image = cv2.imread(image_path)\n        \n        if COLOR_CONVERT_RGB:\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transforms is not None:\n            image = self.transforms(image = image)['image']\n            \n        return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 確定是否將應用此增強。機率為 p = 1.0 意味著我們總是從上面應用轉換。\n# p = 0 將意味著將忽略轉換塊。\n# 0 < p < 1.0 等於每個擴增都具有以一定概率應用的選項。\n# OneOf 隨機選取一種增強擴增\n\ndef get_test_transforms(count):\n    return A.Compose([\n        A.Blur(blur_limit = BLUR_LIMIT[count], \n               p = P_BLUR[count]), # 模糊\n        A.HorizontalFlip(p = P_HORIZONTALFLIP[count]), # 水平翻轉\n        A.VerticalFlip(p = P_VERTICALFLIP[count]), # 垂直翻轉\n        A.Flip(p = P_FLIP[count]), # 水平和垂直翻轉\n        A.Resize(height = RESIZE_HEIGHT[count], \n                 width = RESIZE_WIDTH[count], \n                 p = P_RESIZE[count]), # 縮放\n        A.RandomResizedCrop(height = RANDOMRESIZEDCROP_HEIGHT[count], \n                            width = RANDOMRESIZEDCROP_WIDTH[count], \n                            scale = RANDOMRESIZEDCROP_SCALE[count], \n                            p = P_RANDOMRESIZEDCROP[count]), #隨機縮放剪裁\n        A.RandomRotate90(p = P_RANDOMROTATE90[count]), # 隨機旋轉90度\n        A.ShiftScaleRotate(shift_limit = SHIFTSCALEROTATE_SHIFT_LIMIT[count], \n                           scale_limit = SHIFTSCALEROTATE_SCALE_LIMIT[count], \n                           rotate_limit = SHIFTSCALEROTATE_ROTATE_LIMIT[count], \n                           p = P_SHIFTSCALEROTATE[count]), # 平移縮放旋轉\n        A.ElasticTransform(alpha = ELATICTRANSFORM_ALPHA[count], \n                           sigma = ELATICTRANSFORM_SIGMA[count], \n                           alpha_affine = ELATICTRANSFORM_ALPHA_AFFINE[count], \n                           p = P_ELATICTRANSFORM[count]), # 彈性變換\n        A.GridDistortion(num_steps = GRIDDISTORTION_NUM_STEPS[count], \n                         p = P_GRIDDISTORTION[count]), # 網格失真\n        A.RandomBrightnessContrast(brightness_limit = RANDOMBRIGHTNESSCONTRAST_BRIGHTNESS_LIMIT[count], \n                                   contrast_limit = RANDOMBRIGHTNESSCONTRAST_CONTRAST_LIMIT[count], \n                                   p = P_RANDOMBRIGHTNESSCONTRAST_CONTRAST[count]), # 隨機亮度對比度\n        A.HueSaturationValue(hue_shift_limit = HUESATURATIONVALUE_HUE_SHIFT_LIMIT[count], \n                             sat_shift_limit = HUESATURATIONVALUE_SAT_SHIFT_LIMIT[count], \n                             val_shift_limit = HUESATURATIONVALUE_VAL_SHIFT_LIMIT[count], \n                             p = P_HUESATURATIONVALUE[count]), # 隨機色調飽和度值\n        A.CLAHE(clip_limit = CLAHE_CLIP_LIMIT[count], \n                p = P_CLAHE[count]), # 將對比度受限的自適應直方圖均衡化應用於輸入圖像\n        A.Cutout(num_holes = COARSEDROPOUT_NUM_HOLES[count], \n                        max_h_size = COARSEDROPOUT_MAX_H_SIZE[count], \n                        max_w_size = COARSEDROPOUT_MAX_W_SIZE[count], \n                        p = P_COARSEDROPOUT[count]), # 隨機在圖像上生成黑色矩形\n        A.Normalize(\n             mean = NORMALIZE_MEAN[count], \n             std = NORMALIZE_STD[count], \n            max_pixel_value = NORMALIZE_MAX_PIXEL_VALUE[count], \n            p = P_NORMALIZE[count]), # 正規化。\n        ToTensorV2(p = P_TOTENSORV2[count]) # 歸一化\n    ], p = P_TEST_TRANSFORMS[count])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_dataloader(count):\n    \n    test_dataset = MyDataset(test_csv, transforms = get_test_transforms(count))\n    \n    test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE[count], pin_memory = False, \n                                               shuffle = False)\n    return test_loader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_one_epoch(model, data_loader):\n    model.eval()\n    outputs_all = []\n    pbar = tqdm(enumerate(data_loader), total=len(data_loader), \n                position = TQDM_POSITION, leave = TQDM_LEAVE)\n    with torch.no_grad():\n        for batch_idx, (inputs) in pbar:\n            inputs = inputs.to(DEVICE).float()\n\n            outputs = model(inputs)\n            outputs_all += [torch.softmax(outputs, 1).detach().cpu().numpy()]\n        \n    outputs_all = np.concatenate(outputs_all, axis=0)\n    return outputs_all","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_process(count, fold, kf):\n    if kf:\n        print('Fold %i - image size %i with %s and batch size %i'%(fold+1,IMAGE_SIZE[count],LOAD_MODEL_NAME[count].upper(),BATCH_SIZE[count]))\n    else:\n        print('Image size %i with %s and batch_size %i'%(IMAGE_SIZE[count],LOAD_MODEL_NAME[count].upper(),BATCH_SIZE[count]))\n    \n    test_loader = prepare_dataloader(count)\n\n    if kf:\n        model_path = LOAD_MODEL_PATH[count] + LOAD_MODEL_NAME[count] + '_' + str(fold+1) + '.pth'\n    else:\n        model_path = LOAD_MODEL_PATH[count] + LOAD_MODEL_NAME[count] + '.pth'\n    \n    model = build_model(count, model_path)\n    if MODEL_LIST[count] != 1:\n        # 載入預訓練權重\n        model.load_state_dict(torch.load(model_path))\n    model = model.to(DEVICE)\n    \n    test_preds = []\n    for inf in range(INFERENCE_COUNT[count]):\n        test_preds += [inference_one_epoch(model, test_loader)]\n        \n#     sub1 += [np.mean(test_preds, axis=0)]\n    \n    del test_loader, model\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n    try:\n        print('Inference start')\n        since = time.time()\n        for count in range(len(LOAD_MODEL_NAME)):\n            print('Model {:d}'.format(count+1))\n            if FOLD[count] > 1:\n                for fold in enumerate(KF.split(np.arange(train_csv.shape[0]))):\n                    inference_process(count, fold = fold, kf = True)\n            else:\n                inference_process(count, fold = 0, kf = False)\n        time_elapsed = time.time() - since\n        print('Inference complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    except Exception as exception:\n        print(exception)\n        raise","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    main()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. 待辦事項<a class=\"anchor\" id=\"7\"></a>\n[Back to Table of Contents](#0)\n1. FOLD\n1. TTA\n1. ENSEMBLE","metadata":{}}]}