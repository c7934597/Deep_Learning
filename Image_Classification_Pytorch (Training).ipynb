{"metadata":{"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image_Classification_Pytorch (Training)\nhttps://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n\nhttps://www.kaggle.com/zzy990106/pytorch-5-fold-efficientnet-baseline","metadata":{}},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# Table of Contents\n\n1. [套件安裝與載入](#1)\n1. [環境檢測與設定](#2)\n1. [開發參數設定](#3)\n1. [資料處理](#4)\n    -  [載入CSV檔](#4.1)\n    -  [檢查CSV檔缺失值](#4.2)\n1. [定義模型方法](#5)\n1. [定義回調函數方法](#6)\n1. [製作資料集＆資料擴增&訓練模型](#7)\n1. [混淆矩陣](#8)\n1. [待辦事項](#9)","metadata":{}},{"cell_type":"markdown","source":"# 1. 套件安裝與載入<a class=\"anchor\" id=\"1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"# 資料處理套件\nimport os\nimport gc\nimport sys\nimport random\nimport datetime\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport albumentations as A\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom sklearn.model_selection import StratifiedKFold\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 設定顯示中文字體\nfrom matplotlib.font_manager import FontProperties\nplt.rcParams['font.sans-serif'] = ['Microsoft JhengHei'] # 用來正常顯示中文標籤\nplt.rcParams['font.family'] = 'AR PL UMing CN'\nplt.rcParams['axes.unicode_minus'] = False # 用來正常顯示負號","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pytorch深度學習模組套件\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torch.nn.functional as F\n\nimport torchvision\n\nfrom torch.utils.data import DataLoader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. 環境檢測與設定<a class=\"anchor\" id=\"2\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nDEVICE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''執行環境參數設定'''\n\n# (Boolean)是否為本機\nLOCAL = False\n\n# (Boolean)是否為 Colab\nCOLAB = False\n\n\n'''檔案路徑參數設定'''\n\n# (String)Root路徑\nif LOCAL:\n    PATH = r'../'\nelif COLAB:\n    PATH = r'/content/drive/My Drive/Colab Notebooks/'\nelse:\n    PATH = r'../input/'\n    OUTPUT_PATH = r'/kaggle/working/'\n    \n# (String)資料根路徑\nDATA_ROOT_PATH = PATH+r'datasets/AI_CUP_2020_AIMango_Defective_Classification/' \n\n# (String)訓練資料路徑\nTRAIN_DATA_PATH = DATA_ROOT_PATH+r'C1-P2_Train Dev/Train'\n\n# (String)訓練CSV路徑，如為None則不讀CSV檔\nTRAIN_CSV_PATH = DATA_ROOT_PATH+r'C1-P2_Train Dev/train.csv'\n\n# (String)專案名稱\nPROJECT_NAME = 'AI_CUP_2020_AIMango_Defective_Classification'\n\n# (String)專案檔案儲存路徑\nif LOCAL or COLAB:\n    OUTPUT_PATH = PATH\nPROJECT_PATH = OUTPUT_PATH+PROJECT_NAME+'/'+PROJECT_NAME+' '+datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n\n# (String)權重名稱(使用哪個權重)\nWEIGHTS_NAME = 'efficientnetb7'\n\n# (String)模型名稱(使用哪個模型)\nMODEL_NAME = 'efficientnetb7'\n\n# (String)讀取預訓練權重的儲存路徑 \nLOAD_WEIGHTS_PATH = PROJECT_PATH+r'/models/backup/'+WEIGHTS_NAME+'.pth'\n\n# (String)讀取預訓練模型的儲存路徑 \nLOAD_MODEL_PATH = PROJECT_PATH+r'/models/backup/'+MODEL_NAME+'.pth'\n\n# (String)訓練模型的儲存路徑\nTRAIN_MODEL_PATH = PROJECT_PATH+r'/models/'+MODEL_NAME+'.pth'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not LOCAL and COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DEVICE != \"CPU\":\n    !nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if os.path.isfile(TRAIN_CSV_PATH):\n    LOAD_CSV = True\nelse:\n    LOAD_CSV = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.isdir(PROJECT_PATH+r'/models/'):\n    os.makedirs(PROJECT_PATH+r'/models/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. 開發參數設定<a class=\"anchor\" id=\"3\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"'''客製參數設定'''\n\n\n'''資料參數設定'''\n\n# (Int)分類數量\nCLASSES = 3\n\n# (Int)有CSV檔該參數才有用，1則為不做交叉驗證\nFOLD = 1\n\n# (Int)沒CSV檔，FOLD該參數固定為1\nif not LOAD_CSV:\n    FOLD = 1\n    \n# (Int)圖片尺寸\nIMAGE_SIZE = [224]*FOLD\n\n# (String)圖片副檔名\nIMAGE_NAME_EXTENSION = '.jpg'\n\n# (String)CSV圖片檔名欄位(不包含路徑)\nIMAGE_NAME = 'image_id'\n\n# (String)CSV圖片檔名欄位(包含路徑)\nIMAGE_NAME_ROOT = 'image'\n\n# (String)CSV標籤欄位\nLABEL_NAME = 'grade'\n\n# (String)CSV標籤欄位類型\nLABEL_NAME_TYPE = 'string'\n\n# (Boolean)CSV圖片檔名欄位是否包含副檔名\nIMAGE_NAME_HAVE_EXTENSION = True\n\n# (Int)不包含副檔名的圖片檔名長度，因為CSV檔名欄位有副檔名時需要移除\nIMAGE_NAME_LENGTH = 5\n\n# (Int)不同的種子會產生不同的Random或分層K-FOLD分裂, 42則是預設固定種子\nSEED = 42\n\nif FOLD == 1:\n    # (Float)驗證集佔訓練集的比率，FOLD>1則不啟用\n    DATA_SPLIT = 0.2\nelse:\n    # (String)切分訓練集跟驗證集方式\n    SKF = StratifiedKFold(n_splits=FOLD,shuffle=True,random_state=SEED)\n\n# (Boolean)如為True每次返回的卷積算法將是確定的，即默認算法\nCUDNN_DETERMINISTIC = True\n\n# (Boolean)PyTorch 中對模型裡的卷積層進行預先的優化，也就是在每一個卷積層中測試 cuDNN 提供的所有卷積實現算法，\n# 然後選擇最快的那個。這樣在模型啟動的時候，只要額外多花一點點預處理時間，就可以較大幅度地減少訓練時間\nCUDNN_BENCHMARK = True\n\n\n'''資料擴增參數設定\n\n資料擴增範例\nhttps://zh-hant.hotbak.net/key/albumentation%E6%95%B8%E6%93%9A%E5%A2%9E%E5%BC%B7CSDN.html\n\n資料擴增教學\nhttps://zhuanlan.zhihu.com/p/107399127\n\n資料擴增Doc\nhttps://vfdev-5-albumentations.readthedocs.io/en/docs_pytorch_fix/api/augmentations.html\n'''\n\n# (Float)訓練集資料擴增的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_TRAIN_TRANSFORMS = 1.0\n\n# (Float)驗證集資料擴增的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_VALID_TRANSFORMS = 1.0\n\n# 以下資料擴增為訓練集使用=============================================\n\n# (Float)模糊的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_BLUR = 0\n\n# (Int)模糊的上限\nBLUR_LIMIT = 3\n\n# (Float)水平翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_HORIZONTALFLIP = 0.5\n\n# (Float)垂直翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_VERTICALFLIP = 0\n\n# (Float)水平和垂直翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_FLIP = 0\n\n# (Float)隨機旋轉90度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RANDOMROTATE90 = 0\n\n# (Float)平移縮放旋轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_SHIFTSCALEROTATE = 0\n\n# (Float)平移縮放旋轉的平移上限\nSHIFTSCALEROTATE_SHIFT_LIMIT = 0.0625\n\n# (Float)平移縮放旋轉的縮放上限\nSHIFTSCALEROTATE_SCALE_LIMIT = 0.1\n\n# (Float)平移縮放旋轉的旋轉上限\nSHIFTSCALEROTATE_SHIFT_LIMIT = 45\n\n# (Float)彈性變換的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_ELATICTRANSFORM = 0\n\n# (Float)彈性變換的alpha高斯過濾參數\nELATICTRANSFORM_ALPHA = 1\n\n# (Float)彈性變換的sigma高斯過濾參數\nELATICTRANSFORM_SIGMA = 50\n\n# (Float)彈性變換的alpha_affine，範圍為（-alpha_affine，alpha_affine）\nELATICTRANSFORM_ALPHA_AFFINE = 50\n\n# (Float)網格失真的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_GRIDDISTORTION = 0\n\n# (Int)網格失真的每一條邊上網格單元數量\nGRIDDISTORTION_NUM_STEPS = 5\n\n# (Float)隨機亮度對比度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RANDOMBRIGHTNESSCONTRAST_CONTRAST = 0\n\n# (Float)隨機亮度的上限\nRANDOMBRIGHTNESSCONTRAST_BRIGHTNESS_LIMIT = 0.2\n\n# (Float)隨機對比度的上限\nRANDOMBRIGHTNESSCONTRAST_CONTRAST_LIMIT = 0.2\n\n# (Float)隨機色調飽和度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_HUESATURATIONVALUE = 0\n\n# (Float)隨機色調飽和度的色調上限\nHUESATURATIONVALUE_HUE_SHIFT_LIMIT = 20\n\n# (Float)隨機色調飽和度的飽和度上限\nHUESATURATIONVALUE_SAT_SHIFT_LIMIT = 30\n\n# (Float)隨機色調飽和度的值上限\nHUESATURATIONVALUE_VAL_SHIFT_LIMIT = 20\n\n# (Float)對比度受限自適應直方圖均衡的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_CLAHE = 0\n\n# (Float)對比度受限自適應直方圖均衡的對比度上限\nCLAHE_CLIP_LIMIT = 4.0\n\n# (Float)隨機在圖像上生成黑色矩形的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_COARSEDROPOUT = 0\n\n# (Int)隨機在圖像上生成黑色矩形的數量\nCOARSEDROPOUT_NUM_HOLES = 0\n\n# (Int)隨機在圖像上生成黑色矩形的最大高度\nCOARSEDROPOUT_MAX_H_SIZE = 8\n\n# (Int)隨機在圖像上生成黑色矩形的最大寬度\nCOARSEDROPOUT_MAX_W_SIZE = 8\n\n# (Float)隨機縮放剪裁的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RANDOMRESIZEDCROP = 0\n\n# (Float Tuple)隨機縮放剪裁之前的圖像比例縮放\nRANDOMRESIZEDCROP_SCALE = (0.08, 1.0)\n\n# (Int)隨機縮放剪裁之前的圖像高度\nRANDOMRESIZEDCROP_HEIGHT = IMAGE_SIZE[0]\n\n# (Int)隨機縮放剪裁之前的圖像寬度\nRANDOMRESIZEDCROP_WIDTH = IMAGE_SIZE[0]\n\n# 以上資料擴增為訓練集使用=============================================\n\n# 以下資料擴增為訓練集和驗證集共用======================================\n\n# (Float)縮放的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RESIZE = 1.0\n\n# (Int)縮放後的圖片高度\nRESIZE_HEIGHT = IMAGE_SIZE[0]\n\n# (Int)縮放後的圖片寬度\nRESIZE_WIDTH = IMAGE_SIZE[0]\n\n# (Float)正規化的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_NORMALIZE = 1.0\n\n# (List)正規化的平均值(Imagenet的參考平均值[0.485, 0.456, 0.406])\nNORMALIZE_MEAN = [0.485, 0.456, 0.406]\n\n# (List)正規化的標準差(Imagenet的參考標準差[0.229, 0.224, 0.225])\nNORMALIZE_STD = [0.229, 0.224, 0.225]\n\n# (Float)正規化的PIXEL最大值(Imagenet的參考PIXEL最大值255.0)\nNORMALIZE_MAX_PIXEL_VALUE = 255.0\n\n# (Float)歸一化的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n# ToTensorV2()將[0, 255]的PIL.Image或[H, W, C]的numpy.ndarray數據，\n# 轉換為形狀[C, H, W]的torch.FloadTensor，並歸一化到[0, 1.0]。\nP_TOTENSORV2 = 1.0\n\n# 以上資料擴增為訓練集和驗證集共用======================================\n\n\n''''模型參數設定'''\n\n# (Boolean)是否印出完整模型\nMODEL_PRINT = True\n\n\n''''回調函數參數設定\n\n學習率遞減\nhttps://zhuanlan.zhihu.com/p/69411064\n\n模型儲存\nhttps://pytorch.org/tutorials/beginner/saving_loading_models.html\nhttps://discuss.pytorch.org/t/how-to-save-the-best-model/84608\n\n'''\n\n\n''''編譯參數設定'''\n\n# (Boolean)是否印出完整編譯器\nOPTIMIZER_PRINT = True\n\n# (Float)優化器學習率 1e-3/1e-1\nLEARNING_RATE = 1e-3\n\n# (Float)優化器權重衰減 5e-5/5e-4\nWEIGHT_DECAY = 5e-5\n\n# (String)優化器指定，None為客制，須另外撰寫\nBASE_OPTIMIZERS = optim.Adam\n\n# (String)損失函數，None為客制，須另外撰寫\nBASE_LOSSES = nn.CrossEntropyLoss\n\n# (String)指定還原成適用於輸出，預設mean\nREDUCTION = \"mean\"\n\n\n''''訓練參數設定'''\n\n# (Int List)每批訓練的尺寸\nBATCH_SIZE = [16]*FOLD\n\n# (Int)訓練做幾次時代\nEPOCHS = [2]*FOLD\n\n# (Int)要用於數據加載的子進程數。0表示將在主進程中加載數據。（默認值：0）\nNUM_WORKERS = 0\n\n# (Boolean)批次處理在大小不合適的情況下，是否刪除最後一個不完整的批次\nDROP_LAST = False\n\n# (Int)指定列印進度條的位置（從0開始）。\nTQDM_POSITION = 0\n\n# (Boolean)保留迭代結束時進度條的所有痕跡。如果是None，只會在position是0時離開\nTQDM_LEAVE = True\n\n\n''''圖表參數設定'''\n\n# (Float)全部SNS圖表的字形縮放\nALL_SNS_FONT_SCALE = 1.0\n\n# (Int)CSV缺失值圖表寬度\nCSV_COUNTPLOT_FIGSIZE_W = 10\n\n# (Int)CSV缺失值圖表高度\nCSV_COUNTPLOT_FIGSIZE_H = 10\n\n# (Int)CSV缺失值圖表標題字型大小\nCSV_COUNTPLOT_TITLE_FONTSIZE = 20\n\n# (Int)CSV缺失值圖表X軸標題字型大小\nCSV_COUNTPLOT_XLABEL_FONTSIZE = 15\n\n# (Int)CSV缺失值圖表Y軸標題字型大小\nCSV_COUNTPLOT_YLABEL_FONTSIZE = 15","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = CUDNN_DETERMINISTIC\n    torch.backends.cudnn.benchmark = CUDNN_BENCHMARK\n\nseed_everything(SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 設置sns圖表縮放係數\nsns.set(font_scale = ALL_SNS_FONT_SCALE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. 資料處理<a class=\"anchor\" id=\"4\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"markdown","source":"## 4.1 載入CSV檔 <a class=\"anchor\" id=\"4.1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"if LOAD_CSV:\n    print('Reading data...')\n\n    # 讀取訓練資料集CSV檔\n    train_csv = pd.read_csv(TRAIN_CSV_PATH,encoding=\"utf8\")\n\n    print('Reading data completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_CSV:\n    # CSV檔名欄位包括副檔名時，需要移除副檔名\n    if IMAGE_NAME_HAVE_EXTENSION:\n        train_csv[IMAGE_NAME] = train_csv[IMAGE_NAME].str.slice(stop = IMAGE_NAME_LENGTH)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_CSV:\n    # 顯示訓練資料集CSV檔\n    print(train_csv.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_CSV:\n    print(\"Shape of train_data :\", train_csv.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 檢查CSV檔缺失值 <a class=\"anchor\" id=\"4.2\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"if LOAD_CSV:\n    total = train_csv.isnull().sum().sort_values(ascending = False)\n    percent = (train_csv.isnull().sum()/train_csv.isnull().count()*100).sort_values(ascending = False)\n    missing_train_csv  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    print(missing_train_csv.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_CSV:\n    print(train_csv[LABEL_NAME].value_counts())\n    f,ax = plt.subplots(figsize=(CSV_COUNTPLOT_FIGSIZE_W, CSV_COUNTPLOT_FIGSIZE_H))\n    sns.countplot(train_csv[LABEL_NAME], hue = train_csv[LABEL_NAME],ax = ax)\n    plt.title(\"LABEL COUNT\", fontsize=CSV_COUNTPLOT_TITLE_FONTSIZE)\n    plt.xlabel(LABEL_NAME.upper(), fontsize=CSV_COUNTPLOT_XLABEL_FONTSIZE)\n    plt.ylabel(\"COUNT\", fontsize=CSV_COUNTPLOT_YLABEL_FONTSIZE)\n    plt.legend()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. 定義模型方法<a class=\"anchor\" id=\"5\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"def build_optimizers():\n    if BASE_OPTIMIZERS == None:\n        print(\"Custiom OPTIMIZERS\")\n    else:\n        RETURN_OPTIMIZERS = BASE_OPTIMIZERS\n    return RETURN_OPTIMIZERS\n\noptimizer = build_optimizers()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_losses():\n    if BASE_LOSSES == None:\n        print(\"Custiom LOSSES\")\n    else:\n        RETURN_LOSSES = BASE_LOSSES\n    return RETURN_LOSSES\n\nloss = build_losses()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class build_model(nn.Module):\n\n    def __init__(self):\n        super(build_model, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ==== INIT MODEL    \nmodel = build_model()\nmodel.to(DEVICE)\noptimizer = optimizer(model.parameters(), lr = LEARNING_RATE, weight_decay = WEIGHT_DECAY)\n\n# Later we have to filter the invalid steps.\ncriterion = loss(reduction = REDUCTION)\n\nif MODEL_PRINT:\n    # Print model's state_dict\n    print(\"Model's state_dict:\")\n    for param_tensor in model.state_dict():\n        print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n\nif OPTIMIZER_PRINT:\n    # Print optimizer's state_dict\n    print(\"Optimizer's state_dict:\")\n    for var_name in optimizer.state_dict():\n        print(var_name, \"\\t\", optimizer.state_dict()[var_name])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. 定義回調函數方法<a class=\"anchor\" id=\"6\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. 製作資料集＆資料擴增&訓練模型 <a class=\"anchor\" id=\"7\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, df, transform = None):\n        self.df = df\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx: int):\n        label = self.df.target.values[idx]\n        image_name = self.df.image_name.values[idx]\n        image_path = TRAIN_DATA_PATH + image_name + IMAGE_NAME_EXTENSION\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        return image, label","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 確定是否將應用此增強。機率為 p = 1.0 意味著我們總是從上面應用轉換。\n# p = 0 將意味著將忽略轉換塊。\n# 0 < p < 1.0 等於每個擴增都具有以一定概率應用的選項。\n# OneOf 隨機選取一種增強擴增\n\ndef get_train_transforms():\n    return A.Compose([\n        A.Blur(blur_limit = BLUR_LIMIT, \n               p = P_BLUR), # 模糊\n        A.HorizontalFlip(p = P_HORIZONTALFLIP), # 水平翻轉\n        A.VerticalFlip(p = P_VERTICALFLIP), # 垂直翻轉\n        A.Flip(p = P_FLIP), # 水平和垂直翻轉\n        A.Resize(height = RESIZE_HEIGHT, \n                 width = RESIZE_WIDTH, \n                 p = P_RESIZE), # 縮放\n        A.RandomResizedCrop(height = RANDOMRESIZEDCROP_HEIGHT, \n                            width = RANDOMRESIZEDCROP_WIDTH, \n                            scale = RANDOMRESIZEDCROP_SCALE, \n                            p = P_RANDOMRESIZEDCROP), #隨機縮放剪裁\n        A.RandomRotate90(p = P_RANDOMROTATE90), # 隨機旋轉90度\n        A.ShiftScaleRotate(shift_limit = SHIFTSCALEROTATE_SHIFT_LIMIT, \n                           scale_limit = SHIFTSCALEROTATE_SCALE_LIMIT, \n                           rotate_limit = SHIFTSCALEROTATE_ROTATE_LIMIT, \n                           p = P_SHIFTSCALEROTATE), # 平移縮放旋轉\n        A.ElasticTransform(alpha = ELATICTRANSFORM_ALPHA, \n                           sigma = ELATICTRANSFORM_SIGMA, \n                           alpha_affine = ELATICTRANSFORM_ALPHA_AFFINE, \n                           p = P_ELATICTRANSFORM), # 彈性變換\n        A.GridDistortion(num_steps = GRIDDISTORTION_NUM_STEPS, \n                         p = P_GRIDDISTORTION), # 網格失真\n        A.RandomBrightnessContrast(brightness_limit = RANDOMBRIGHTNESSCONTRAST_BRIGHTNESS_LIMIT, \n                                   contrast_limit = RANDOMBRIGHTNESSCONTRAST_CONTRAST_LIMIT, \n                                   p = P_RANDOMBRIGHTNESSCONTRAST_CONTRAST), # 隨機亮度對比度\n        A.HueSaturationValue(hue_shift_limit = HUESATURATIONVALUE_HUE_SHIFT_LIMIT, \n                             sat_shift_limit = HUESATURATIONVALUE_SAT_SHIFT_LIMIT, \n                             val_shift_limit = HUESATURATIONVALUE_VAL_SHIFT_LIMIT, \n                             p = P_HUESATURATIONVALUE), # 隨機色調飽和度值\n        A.CLAHE(clip_limit = CLAHE_CLIP_LIMIT, \n                p = P_CLAHE), # 將對比度受限的自適應直方圖均衡化應用於輸入圖像\n        A.CoarseDropout(num_holes = COARSEDROPOUT_NUM_HOLES, \n                        max_h_size = COARSEDROPOUT_MAX_H_SIZE, \n                        max_w_size = COARSEDROPOUT_MAX_W_SIZE, \n                        p = P_COARSEDROPOUT), # 隨機在圖像上生成黑色矩形\n        A.Normalize(\n             mean = NORMALIZE_MEAN, \n             std = NORMALIZE_STD, \n            max_pixel_value = NORMALIZE_MAX_PIXEL_VALUE, \n            p = P_NORMALIZE), # 正規化。\n        ToTensorV2(p = P_TOTENSORV2) # 歸一化\n    ], p = P_TRAIN_TRANSFORMS)\n\ndef get_valid_transforms():\n    return A.Compose([\n        A.Resize(height = RESIZE_HEIGHT, \n                 width = RESIZE_WIDTH, \n                 p = P_RESIZE), # 縮放\n        A.Normalize(\n             mean = NORMALIZE_MEAN,\n             std = NORMALIZE_STD, \n            max_pixel_value = NORMALIZE_MAX_PIXEL_VALUE, \n            p = P_NORMALIZE), # 正規化。\n        ToTensorV2(p = P_TOTENSORV2) # 歸一化\n    ], p = P_VALID_TRANSFORMS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AverageMeter:\n    \"\"\"\n    Computes and stores the average and current value\n    \"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, epoch):\n    model.train() \n    \n    losses = AverageMeter()\n    avg_loss = 0.\n\n    optimizer.zero_grad()\n    \n    tq = tqdm(train_loader, total = len(train_loader), position = TQDM_POSITION, leave = TQDM_LEAVE)\n    for idx, data in enumerate(tq):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n        \n        # zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # forward + backward + optimize\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step() \n        \n        avg_loss += loss.item() / len(train_loader)\n        \n        losses.update(loss.item(), inputs.size(0))\n        tq.set_postfix(loss = losses.avg)\n        \n    return avg_loss\n\ndef valid_model(model):    \n    model.eval()\n    \n    losses = AverageMeter()\n    avg_valid_loss = 0.\n    \n#     valid_preds, valid_targets = [], []\n    \n    with torch.no_grad():\n        tq = tqdm(valid_loader, total = len(valid_loader), position = TQDM_POSITION, leave = TQDM_LEAVE)\n        for idx, data in enumerate(tq):\n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n            \n            # forward\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            \n            avg_valid_loss += loss.item() / len(valid_loader)\n\n            losses.update(loss.item(), imgs_valid.size(0))\n            tq.set_postfix(loss = losses.avg)\n            \n#             valid_preds.append(torch.softmax(output_valid,1)[:,1].detach().cpu().numpy())\n#             valid_targets.append(labels_valid.detach().cpu().numpy())\n            \n#         valid_preds = np.concatenate(valid_preds)\n#         valid_targets = np.concatenate(valid_targets)\n#         auc =  roc_auc_score(valid_targets, valid_preds) \n            \n#     return avg_val_loss, auc\n    return avg_valid_loss","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_process(fold, skf, x_train, x_val, y_train, y_val):\n    if skf:\n        print('FOLD %i - IMAGE SIZE %i WITH %s AND BATCH_SIZE %i'%(fold+1,IMAGE_SIZE[fold],MODEL_NAME.upper(),BATCH_SIZE[fold]))\n    else:\n        print('IMAGE SIZE %i WITH %s AND BATCH_SIZE %i'%(IMAGE_SIZE[fold],MODEL_NAME.upper(),BATCH_SIZE[fold]))\n        \n    if LOAD_CSV:\n        train_data = pd.DataFrame(x_train)\n        train_data.columns = [IMAGE_NAME_ROOT]\n        train_data[LABEL_NAME] = y_train\n\n        validation_data = pd.DataFrame(x_val)\n        validation_data.columns = [IMAGE_NAME_ROOT]\n        validation_data[LABEL_NAME] = y_val\n\n        train_data[LABEL_NAME] = train_data[LABEL_NAME].astype(LABEL_NAME_TYPE)\n        validation_data[LABEL_NAME] = validation_data[LABEL_NAME].astype(LABEL_NAME_TYPE)\n        \n    train_set = MyDataset(train_data, transform = get_train_transforms())\n    train_loader = torch.utils.data.DataLoader(train_set, batch_size = BATCH_SIZE[fold], shuffle = True, num_workers = NUM_WORKERS, drop_last=DROP_LAST)\n   \n    valid_set = MyDataset(validation_data, transform = get_valid_transforms())\n    valid_loader = torch.utils.data.DataLoader(valid_set, batch_size = BATCH_SIZE[fold], shuffle = False, num_workers = NUM_WORKERS, drop_last=DROP_LAST)\n    \n    early_stopping = 0\n    best_loss = 0\n\n    for epoch in range(EPOCHS):\n        avg_loss = train_model(model, epoch)\n        avg_valid_loss = valid_model(model)\n\n        if avg_valid_loss < best_loss:\n            best_loss = avg_valid_loss\n            torch.save(model.state_dict(), str(fold) + 'weight.pt')\n        else:\n            early_stopping += 1\n            if early_stopping >= 10:\n                break\n        print('current_valid_loss:', avg_valid_loss, 'best_valid_loss:', best_loss)\n        \n        scheduler.step()\n    \n#     best_auc = 0\n\n#     for epoch in range(n_epochs):\n#         avg_loss = train_model(model, epoch)\n#         avg_valid_loss, auc = valid_model(model)\n\n#         if auc > best_auc:\n#             best_auc = auc\n#             torch.save(model.state_dict(), str(fold) + 'weight.pt')\n#         else:\n#             es += 1\n#             if es > 1:\n#                 break\n#         print('current_valid_auc:', auc, 'best_valid_auc:', best_auc)\n        \n#         scheduler.step()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_CSV:\n    label_list = []\n    train_list = []\n    for i in range(train_csv.shape[0]):\n        train_list.append(TRAIN_DATA_PATH + '/' + train_csv[IMAGE_NAME].iloc[i] + IMAGE_NAME_EXTENSION)\n        label_list.append(train_csv[LABEL_NAME].iloc[i])\n    df_train = pd.DataFrame(train_list)\n    df_train.columns = [IMAGE_NAME_ROOT]\n    df_train[LABEL_NAME] = label_list","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nif LOAD_CSV and FOLD == 1:\n    X_train, X_val, Y_train, Y_val = train_test_split(df_train[IMAGE_NAME_ROOT],df_train[LABEL_NAME], test_size = DATA_SPLIT, random_state = SEED)\n    train_process(fold = 0, skf = False, x_train = X_train, x_val = X_val, y_train = Y_train, y_val = Y_val)\n    del X_train, X_val, Y_train, Y_val\n    gc.collect()\nelif LOAD_CSV and FOLD > 1:\n    for fold,(train_index, val_index) in enumerate(SKF.split(df_train[IMAGE_NAME_ROOT], df_train[LABEL_NAME])):\n        X_train, X_val = df_train[IMAGE_NAME_ROOT].iloc[train_index], df_train[IMAGE_NAME_ROOT].iloc[val_index]\n        Y_train, Y_val = df_train[LABEL_NAME].iloc[train_index], df_train[LABEL_NAME].iloc[val_index]\n        train_process(fold = fold, skf = True, x_train = X_train, x_val = X_val, y_train = Y_train, y_val = Y_val)\n        del X_train, X_val, Y_train, Y_val\n        gc.collect()\nelse:\n    train_process(fold = 0, skf = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. 混淆矩陣<a class=\"anchor\" id=\"8\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"markdown","source":"# 9. 待辦事項<a class=\"anchor\" id=\"9\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"markdown","source":"1. 製作資料集(無csv訓練)\n2. 訓練(無csv訓練)\n3. 回調函數(模型儲存整個或權重，學習率遞減，tensroboard)\n4. 列印訓練過程\n5. 混淆矩陣","metadata":{}}]}