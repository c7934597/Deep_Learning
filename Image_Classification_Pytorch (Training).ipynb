{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image_Classification_Pytorch (Training)\nhttps://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n\nhttps://www.kaggle.com/zzy990106/pytorch-5-fold-efficientnet-baseline","metadata":{}},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# Table of Contents\n\n1. [套件安裝與載入](#1)\n1. [環境檢測與設定](#2)\n1. [開發參數設定](#3)\n1. [資料處理](#4)\n    -  [載入CSV檔](#4.1)\n    -  [檢查CSV檔缺失值](#4.2)\n1. [定義模型方法](#5)\n1. [製作資料集＆資料擴增&回調函數&訓練模型](#6)\n1. [混淆矩陣](#7)\n1. [待辦事項](#8)","metadata":{}},{"cell_type":"markdown","source":"# 1. 套件安裝與載入<a class=\"anchor\" id=\"1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"# 資料處理套件\nimport os\nimport gc\nimport sys\nimport time\nimport copy\nimport random\nimport datetime\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport albumentations as A\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 設定顯示中文字體\nfrom matplotlib.font_manager import FontProperties\nplt.rcParams['font.sans-serif'] = ['Microsoft JhengHei'] # 用來正常顯示中文標籤\nplt.rcParams['font.family'] = 'AR PL UMing CN'\nplt.rcParams['axes.unicode_minus'] = False # 用來正常顯示負號","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pytorch深度學習模組套件\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torch.nn.functional as F\nimport torchvision\n\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader\nfrom torchvision import models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. 環境檢測與設定<a class=\"anchor\" id=\"2\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nDEVICE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''執行環境參數設定'''\n\n# (Boolean)是否為本機\nLOCAL = False\n\n# (Boolean)是否為 Colab\nCOLAB = False\n\n\n'''檔案路徑參數設定'''\n\n# (String)Root路徑\nif LOCAL:\n    PATH = r'../'\nelif COLAB:\n    PATH = r'/content/drive/My Drive/Colab Notebooks/'\nelse:\n    PATH = r'../input/'\n    OUTPUT_PATH = r'/kaggle/working/'\n    \n# (String)資料根路徑\nDATA_ROOT_PATH = PATH+r'datasets/AI_CUP_2020_AIMango_Defective_Classification/' \n\n# (String)訓練資料路徑\nTRAIN_DATA_PATH = DATA_ROOT_PATH+r'C1-P2_Train Dev/Train'\n\n# (String)訓練CSV路徑，如為None則不讀CSV檔\nTRAIN_CSV_PATH = DATA_ROOT_PATH+r'C1-P2_Train Dev/train.csv'\n\n# (String)專案名稱\nPROJECT_NAME = 'AI_CUP_2020_AIMango_Defective_Classification'\n\n# (String)專案檔案儲存路徑\nif LOCAL or COLAB:\n    OUTPUT_PATH = PATH\nPROJECT_PATH = OUTPUT_PATH+PROJECT_NAME+'/'+PROJECT_NAME+' '+datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n\n# (String)權重名稱(使用哪個權重)\nWEIGHTS_NAME = 'efficientnetb7'\n\n# (String)模型名稱(使用哪個模型)\nMODEL_NAME = 'efficientnetb7'\n\n# (String)讀取預訓練權重的儲存路徑 \nLOAD_WEIGHTS_PATH = PROJECT_PATH+r'/models/backup/'+WEIGHTS_NAME+'.pth'\n\n# (String)讀取預訓練模型的儲存路徑 \nLOAD_MODEL_PATH = PROJECT_PATH+r'/models/backup/'+MODEL_NAME+'.pth'\n\n# (String)訓練模型的儲存路徑\nTRAIN_MODEL_PATH = PROJECT_PATH+r'/models/'+MODEL_NAME+'.pth'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not LOCAL and COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DEVICE != \"CPU\":\n    !nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if os.path.isfile(TRAIN_CSV_PATH):\n    LOAD_CSV = True\nelse:\n    LOAD_CSV = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.isdir(PROJECT_PATH+r'/models/'):\n    os.makedirs(PROJECT_PATH+r'/models/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. 開發參數設定<a class=\"anchor\" id=\"3\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"'''客製參數設定'''\n\n\n'''資料參數設定'''\n\n# (Int)分類數量\nCLASSES = 2\n\n# (Int)有CSV檔該參數才有用，1則為不做交叉驗證\nFOLD = 1\n\n# (Int)沒CSV檔，FOLD該參數固定為1\nif not LOAD_CSV:\n    FOLD = 1\n    \n# (Int)圖片尺寸\nIMAGE_SIZE = [224]*FOLD\n\n# (String)圖片副檔名\nIMAGE_NAME_EXTENSION = '.jpg'\n\n# (String)CSV圖片檔名欄位(不包含路徑)\nIMAGE_NAME = 'image_id'\n\n# (String)CSV圖片檔名欄位(包含路徑)\nIMAGE_NAME_ROOT = 'image'\n\n# (String)CSV標籤欄位\nLABEL_NAME = 'grade'\n\n# (String)CSV標籤欄位類型\nLABEL_NAME_TYPE = 'string'\n\n# (Boolean)CSV圖片檔名欄位是否包含副檔名\nIMAGE_NAME_HAVE_EXTENSION = True\n\n# (Int)不包含副檔名的圖片檔名長度，因為CSV檔名欄位有副檔名時需要移除\nIMAGE_NAME_LENGTH = 5\n\n# (Int)不同的種子會產生不同的Random或分層K-FOLD分裂, 42則是預設固定種子\nSEED = 42\n\nif FOLD == 1:\n    # (Float)驗證集佔訓練集的比率，FOLD>1則不啟用\n    DATA_SPLIT = 0.2\nelse:\n    # (String)切分訓練集跟驗證集方式\n    SKF = StratifiedKFold(n_splits=FOLD,shuffle=True,random_state=SEED)\n\n# (Boolean)如為True每次返回的卷積算法將是確定的，即默認算法\nCUDNN_DETERMINISTIC = True\n\n# (Boolean)PyTorch 中對模型裡的卷積層進行預先的優化，也就是在每一個卷積層中測試 cuDNN 提供的所有卷積實現算法，\n# 然後選擇最快的那個。這樣在模型啟動的時候，只要額外多花一點點預處理時間，就可以較大幅度地減少訓練時間\nCUDNN_BENCHMARK = True\n\n\n'''資料擴增參數設定\n\n資料擴增範例\nhttps://zh-hant.hotbak.net/key/albumentation%E6%95%B8%E6%93%9A%E5%A2%9E%E5%BC%B7CSDN.html\n\n資料擴增教學\nhttps://zhuanlan.zhihu.com/p/107399127\n\n資料擴增Doc\nhttps://vfdev-5-albumentations.readthedocs.io/en/docs_pytorch_fix/api/augmentations.html\n'''\n\n# (Float)訓練集資料擴增的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_TRAIN_TRANSFORMS = 1.0\n\n# (Float)驗證集資料擴增的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_VAL_TRANSFORMS = 1.0\n\n# 以下資料擴增為訓練集使用=============================================\n\n# (Float)模糊的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_BLUR = 0\n\n# (Int)模糊的上限\nBLUR_LIMIT = 3\n\n# (Float)水平翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_HORIZONTALFLIP = 0.5\n\n# (Float)垂直翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_VERTICALFLIP = 0\n\n# (Float)水平和垂直翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_FLIP = 0\n\n# (Float)隨機旋轉90度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RANDOMROTATE90 = 0\n\n# (Float)平移縮放旋轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_SHIFTSCALEROTATE = 0\n\n# (Float)平移縮放旋轉的平移上限\nSHIFTSCALEROTATE_SHIFT_LIMIT = 0.0625\n\n# (Float)平移縮放旋轉的縮放上限\nSHIFTSCALEROTATE_SCALE_LIMIT = 0.1\n\n# (Float)平移縮放旋轉的旋轉上限\nSHIFTSCALEROTATE_SHIFT_LIMIT = 45\n\n# (Float)彈性變換的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_ELATICTRANSFORM = 0\n\n# (Float)彈性變換的alpha高斯過濾參數\nELATICTRANSFORM_ALPHA = 1\n\n# (Float)彈性變換的sigma高斯過濾參數\nELATICTRANSFORM_SIGMA = 50\n\n# (Float)彈性變換的alpha_affine，範圍為（-alpha_affine，alpha_affine）\nELATICTRANSFORM_ALPHA_AFFINE = 50\n\n# (Float)網格失真的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_GRIDDISTORTION = 0\n\n# (Int)網格失真的每一條邊上網格單元數量\nGRIDDISTORTION_NUM_STEPS = 5\n\n# (Float)隨機亮度對比度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RANDOMBRIGHTNESSCONTRAST_CONTRAST = 0\n\n# (Float)隨機亮度的上限\nRANDOMBRIGHTNESSCONTRAST_BRIGHTNESS_LIMIT = 0.2\n\n# (Float)隨機對比度的上限\nRANDOMBRIGHTNESSCONTRAST_CONTRAST_LIMIT = 0.2\n\n# (Float)隨機色調飽和度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_HUESATURATIONVALUE = 0\n\n# (Float)隨機色調飽和度的色調上限\nHUESATURATIONVALUE_HUE_SHIFT_LIMIT = 20\n\n# (Float)隨機色調飽和度的飽和度上限\nHUESATURATIONVALUE_SAT_SHIFT_LIMIT = 30\n\n# (Float)隨機色調飽和度的值上限\nHUESATURATIONVALUE_VAL_SHIFT_LIMIT = 20\n\n# (Float)對比度受限自適應直方圖均衡的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_CLAHE = 0\n\n# (Float)對比度受限自適應直方圖均衡的對比度上限\nCLAHE_CLIP_LIMIT = 4.0\n\n# (Float)隨機在圖像上生成黑色矩形的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_COARSEDROPOUT = 0\n\n# (Int)隨機在圖像上生成黑色矩形的數量\nCOARSEDROPOUT_NUM_HOLES = 0\n\n# (Int)隨機在圖像上生成黑色矩形的最大高度\nCOARSEDROPOUT_MAX_H_SIZE = 8\n\n# (Int)隨機在圖像上生成黑色矩形的最大寬度\nCOARSEDROPOUT_MAX_W_SIZE = 8\n\n# (Float)隨機縮放剪裁的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RANDOMRESIZEDCROP = 0\n\n# (Float Tuple)隨機縮放剪裁之前的圖像比例縮放\nRANDOMRESIZEDCROP_SCALE = (0.08, 1.0)\n\n# (Int)隨機縮放剪裁之前的圖像高度\nRANDOMRESIZEDCROP_HEIGHT = IMAGE_SIZE[0]\n\n# (Int)隨機縮放剪裁之前的圖像寬度\nRANDOMRESIZEDCROP_WIDTH = IMAGE_SIZE[0]\n\n# 以上資料擴增為訓練集使用=============================================\n\n# 以下資料擴增為訓練集和驗證集共用======================================\n\n# (Float)縮放的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RESIZE = 1.0\n\n# (Int)縮放後的圖片高度\nRESIZE_HEIGHT = IMAGE_SIZE[0]\n\n# (Int)縮放後的圖片寬度\nRESIZE_WIDTH = IMAGE_SIZE[0]\n\n# (Float)正規化的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_NORMALIZE = 1.0\n\n# (List)正規化的平均值(Imagenet的參考平均值[0.485, 0.456, 0.406])\nNORMALIZE_MEAN = [0.485, 0.456, 0.406]\n\n# (List)正規化的標準差(Imagenet的參考標準差[0.229, 0.224, 0.225])\nNORMALIZE_STD = [0.229, 0.224, 0.225]\n\n# (Float)正規化的PIXEL最大值(Imagenet的參考PIXEL最大值255.0)\nNORMALIZE_MAX_PIXEL_VALUE = 255.0\n\n# (Float)歸一化的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n# ToTensorV2()將[0, 255]的PIL.Image或[H, W, C]的numpy.ndarray數據，\n# 轉換為形狀[C, H, W]的torch.FloadTensor，並歸一化到[0, 1.0]。\nP_TOTENSORV2 = 1.0\n\n# 以上資料擴增為訓練集和驗證集共用======================================\n\n\n''''模型參數設定'''\n\n# (Boolean)使用Pytorch模型，如為False則須客制另外撰寫\nUSE_BASE_MODEL = False\n\nif USE_BASE_MODEL:\n    # (Model)建立Pytorch模型\n    BASE_MODEL = models.resnet18\n    \n# (Boolean)是否使用Pytorch權重\nLOAD_PYTORCH_WEIGHTS = True\n\n# (Boolean)Pytorch模型是否包含完全連接網路頂部的網路層\nINCLUDE_TOP = True\n\n# (Boolean)Pytorch模型是否可訓練權重(不包括頂部網路層)\nBASE_MODEL_TRAINABLE = True\n\n# (Boolean)是否已有客製模型，僅載入權重\nLOAD_WEIGHTS = False\n\n# (Boolean)是否載入完整客製(模型+權重)\nLOAD_MODEL = False\n\n# (Boolean)是否印出完整模型\nMODEL_PRINT = True\n\n\n''''回調函數參數設定\n\n學習率遞減\nhttps://zhuanlan.zhihu.com/p/69411064\n\n模型儲存\nhttps://pytorch.org/tutorials/beginner/saving_loading_models.html\n\n'''\n\n# (Boolean)回調函數 ModelCheckpoint 是否啟用\nCALLBACKS_CHECK_POINTER = True\n\n# (String)回調函數監控數值(val_auc 僅限雙分類) val_acc/val_loss/val_auc\nMONITOR = 'val_loss'\n\n# (Boolean)回調函數 ModelCheckpoint 是否只儲存最佳模型 False\nSAVE_BEST_ONLY = True\n\n# (Boolean)回調函數 ModelCheckpoint 是否只儲存權重 True\nSAVE_WEIGHTS_ONLY = True\n\n\n''''編譯參數設定'''\n\n# (Boolean)是否印出完整編譯器\nOPTIMIZER_PRINT = True\n\n# (Float)優化器學習率 1e-3/1e-1\nLEARNING_RATE = 1e-3\n\n# (Float)優化器權重衰減 5e-5/5e-4\nWEIGHT_DECAY = 5e-5\n\n# (Float)加速優化器在相關方向上前進，並抑制震盪 0.9\nMOMENTUM = None\n\n# (String)優化器指定，None為客制，須另外撰寫\nBASE_OPTIMIZERS = optim.Adam\n\n# (String)損失函數，None為客制，須另外撰寫\nBASE_LOSSES = nn.CrossEntropyLoss\n\n# (String)指定還原成適用於輸出，預設mean\nREDUCTION = \"mean\"\n\n\n''''訓練參數設定'''\n\n# (Int List)每批訓練的尺寸\nBATCH_SIZE = [16]*FOLD\n\n# (Int)訓練做幾次時代\nEPOCHS = [2]*FOLD\n\n# (Int)要用於數據加載的子進程數。0表示將在主進程中加載數據。（默認值：0）\nNUM_WORKERS = 0\n\n# (Boolean)批次處理在大小不合適的情況下，是否刪除最後一個不完整的批次\nDROP_LAST = False\n\n# (Int)指定列印進度條的位置（從0開始）。\nTQDM_POSITION = 0\n\n# (Boolean)保留迭代結束時進度條的所有痕跡。如果是None，只會在position是0時離開\nTQDM_LEAVE = True\n\n\n''''圖表參數設定'''\n\n# (Float)全部SNS圖表的字形縮放\nALL_SNS_FONT_SCALE = 1.0\n\n# (Int)CSV缺失值圖表寬度\nCSV_COUNTPLOT_FIGSIZE_W = 10\n\n# (Int)CSV缺失值圖表高度\nCSV_COUNTPLOT_FIGSIZE_H = 10\n\n# (Int)CSV缺失值圖表標題字型大小\nCSV_COUNTPLOT_TITLE_FONTSIZE = 20\n\n# (Int)CSV缺失值圖表X軸標題字型大小\nCSV_COUNTPLOT_XLABEL_FONTSIZE = 15\n\n# (Int)CSV缺失值圖表Y軸標題字型大小\nCSV_COUNTPLOT_YLABEL_FONTSIZE = 15","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = CUDNN_DETERMINISTIC\n    torch.backends.cudnn.benchmark = CUDNN_BENCHMARK\n\nseed_everything(SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 設置sns圖表縮放係數\nsns.set(font_scale = ALL_SNS_FONT_SCALE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. 資料處理<a class=\"anchor\" id=\"4\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"markdown","source":"## 4.1 載入CSV檔 <a class=\"anchor\" id=\"4.1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"if LOAD_CSV:\n    print('Reading data...')\n\n    # 讀取訓練資料集CSV檔\n    train_csv = pd.read_csv(TRAIN_CSV_PATH,encoding=\"utf8\")\n\n    print('Reading data completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_CSV:\n    # CSV檔名欄位包括副檔名時，需要移除副檔名\n    if IMAGE_NAME_HAVE_EXTENSION:\n        train_csv[IMAGE_NAME] = train_csv[IMAGE_NAME].str.slice(stop = IMAGE_NAME_LENGTH)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_CSV:\n    # 顯示訓練資料集CSV檔\n    print(train_csv.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_CSV:\n    print(\"Shape of train_data :\", train_csv.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 檢查CSV檔缺失值 <a class=\"anchor\" id=\"4.2\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"if LOAD_CSV:\n    total = train_csv.isnull().sum().sort_values(ascending = False)\n    percent = (train_csv.isnull().sum()/train_csv.isnull().count()*100).sort_values(ascending = False)\n    missing_train_csv  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    print(missing_train_csv.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_CSV:\n    print(train_csv[LABEL_NAME].value_counts())\n    f,ax = plt.subplots(figsize=(CSV_COUNTPLOT_FIGSIZE_W, CSV_COUNTPLOT_FIGSIZE_H))\n    sns.countplot(train_csv[LABEL_NAME], hue = train_csv[LABEL_NAME],ax = ax)\n    plt.title(\"LABEL COUNT\", fontsize=CSV_COUNTPLOT_TITLE_FONTSIZE)\n    plt.xlabel(LABEL_NAME.upper(), fontsize=CSV_COUNTPLOT_XLABEL_FONTSIZE)\n    plt.ylabel(\"COUNT\", fontsize=CSV_COUNTPLOT_YLABEL_FONTSIZE)\n    plt.legend()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. 定義模型方法<a class=\"anchor\" id=\"5\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"def build_optimizers():\n    if BASE_OPTIMIZERS == None:\n        print(\"Custiom OPTIMIZERS\")\n    else:\n        RETURN_OPTIMIZERS = BASE_OPTIMIZERS\n    return RETURN_OPTIMIZERS\n\noptimizer = build_optimizers()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_losses():\n    if BASE_LOSSES == None:\n        print(\"Custiom LOSSES\")\n    else:\n        RETURN_LOSSES = BASE_LOSSES\n    return RETURN_LOSSES\n\nloss = build_losses()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class build_model(nn.Module):\n\n    def __init__(self):\n        super(build_model, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_MODEL:\n    # load model\n    model = torch.load(LOAD_MODEL_PATH)\nelif USE_BASE_MODEL:\n    model = BASE_MODEL(pretrained = LOAD_PYTORCH_WEIGHTS)\n    \n    if BASE_MODEL_TRAINABLE:\n        for param in model.parameters():\n            param.requires_grad = False\n    \n    if INCLUDE_TOP:\n        # Here the size of each output sample is set to 2.\n        # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names))\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, CLASSES) \n        \n    # 載入完整模型架構與參數\n    model = copy.deepcopy(model.state_dict())\nelse:\n    # ==== INIT MODEL    \n    model = build_model()\n\n    if LOAD_WEIGHTS:\n        # load model weights\n        model.load_state_dict(LOAD_WEIGHTS_PATH)\n\nmodel.to(DEVICE)\noptimizer = optimizer(model.parameters(), lr = LEARNING_RATE, weight_decay = WEIGHT_DECAY)\n\n# Later we have to filter the invalid steps.\ncriterion = loss(reduction = REDUCTION)\n\nif MODEL_PRINT:\n    # Print model's state_dict\n    print(\"Model's state_dict:\")\n    for param_tensor in model.state_dict():\n        print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n\nif OPTIMIZER_PRINT:\n    # Print optimizer's state_dict\n    print(\"Optimizer's state_dict:\")\n    for var_name in optimizer.state_dict():\n        print(var_name, \"\\t\", optimizer.state_dict()[var_name])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. 製作資料集＆資料擴增&回調函數&訓練模型 <a class=\"anchor\" id=\"6\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, df, transform = None):\n        self.df = df\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx: int):\n        label = self.df.target.values[idx]\n        image_name = self.df.image_name.values[idx]\n        image_path = TRAIN_DATA_PATH + image_name + IMAGE_NAME_EXTENSION\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        return image, label","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 確定是否將應用此增強。機率為 p = 1.0 意味著我們總是從上面應用轉換。\n# p = 0 將意味著將忽略轉換塊。\n# 0 < p < 1.0 等於每個擴增都具有以一定概率應用的選項。\n# OneOf 隨機選取一種增強擴增\n\ndef get_train_transforms():\n    return A.Compose([\n        A.Blur(blur_limit = BLUR_LIMIT, \n               p = P_BLUR), # 模糊\n        A.HorizontalFlip(p = P_HORIZONTALFLIP), # 水平翻轉\n        A.VerticalFlip(p = P_VERTICALFLIP), # 垂直翻轉\n        A.Flip(p = P_FLIP), # 水平和垂直翻轉\n        A.Resize(height = RESIZE_HEIGHT, \n                 width = RESIZE_WIDTH, \n                 p = P_RESIZE), # 縮放\n        A.RandomResizedCrop(height = RANDOMRESIZEDCROP_HEIGHT, \n                            width = RANDOMRESIZEDCROP_WIDTH, \n                            scale = RANDOMRESIZEDCROP_SCALE, \n                            p = P_RANDOMRESIZEDCROP), #隨機縮放剪裁\n        A.RandomRotate90(p = P_RANDOMROTATE90), # 隨機旋轉90度\n        A.ShiftScaleRotate(shift_limit = SHIFTSCALEROTATE_SHIFT_LIMIT, \n                           scale_limit = SHIFTSCALEROTATE_SCALE_LIMIT, \n                           rotate_limit = SHIFTSCALEROTATE_ROTATE_LIMIT, \n                           p = P_SHIFTSCALEROTATE), # 平移縮放旋轉\n        A.ElasticTransform(alpha = ELATICTRANSFORM_ALPHA, \n                           sigma = ELATICTRANSFORM_SIGMA, \n                           alpha_affine = ELATICTRANSFORM_ALPHA_AFFINE, \n                           p = P_ELATICTRANSFORM), # 彈性變換\n        A.GridDistortion(num_steps = GRIDDISTORTION_NUM_STEPS, \n                         p = P_GRIDDISTORTION), # 網格失真\n        A.RandomBrightnessContrast(brightness_limit = RANDOMBRIGHTNESSCONTRAST_BRIGHTNESS_LIMIT, \n                                   contrast_limit = RANDOMBRIGHTNESSCONTRAST_CONTRAST_LIMIT, \n                                   p = P_RANDOMBRIGHTNESSCONTRAST_CONTRAST), # 隨機亮度對比度\n        A.HueSaturationValue(hue_shift_limit = HUESATURATIONVALUE_HUE_SHIFT_LIMIT, \n                             sat_shift_limit = HUESATURATIONVALUE_SAT_SHIFT_LIMIT, \n                             val_shift_limit = HUESATURATIONVALUE_VAL_SHIFT_LIMIT, \n                             p = P_HUESATURATIONVALUE), # 隨機色調飽和度值\n        A.CLAHE(clip_limit = CLAHE_CLIP_LIMIT, \n                p = P_CLAHE), # 將對比度受限的自適應直方圖均衡化應用於輸入圖像\n        A.CoarseDropout(num_holes = COARSEDROPOUT_NUM_HOLES, \n                        max_h_size = COARSEDROPOUT_MAX_H_SIZE, \n                        max_w_size = COARSEDROPOUT_MAX_W_SIZE, \n                        p = P_COARSEDROPOUT), # 隨機在圖像上生成黑色矩形\n        A.Normalize(\n             mean = NORMALIZE_MEAN, \n             std = NORMALIZE_STD, \n            max_pixel_value = NORMALIZE_MAX_PIXEL_VALUE, \n            p = P_NORMALIZE), # 正規化。\n        ToTensorV2(p = P_TOTENSORV2) # 歸一化\n    ], p = P_TRAIN_TRANSFORMS)\n\ndef get_val_transforms():\n    return A.Compose([\n        A.Resize(height = RESIZE_HEIGHT, \n                 width = RESIZE_WIDTH, \n                 p = P_RESIZE), # 縮放\n        A.Normalize(\n             mean = NORMALIZE_MEAN,\n             std = NORMALIZE_STD, \n            max_pixel_value = NORMALIZE_MAX_PIXEL_VALUE, \n            p = P_NORMALIZE), # 正規化。\n        ToTensorV2(p = P_TOTENSORV2) # 歸一化\n    ], p = P_VAL_TRANSFORMS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save the losses for further visualization\nlosses = {'train':[], 'val':[]}\naccuracies = {'train':[], 'val':[]}\n\n# Decay LR\nscheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.3)\n\n# 宣告為訓練後預測用\nall_labels = []; all_pred = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_process(fold, skf, x_train, x_val, y_train, y_val):\n    if skf:\n        print('FOLD %i - IMAGE SIZE %i WITH %s AND BATCH_SIZE %i'%(fold+1,IMAGE_SIZE[fold],MODEL_NAME.upper(),BATCH_SIZE[fold]))\n    else:\n        print('IMAGE SIZE %i WITH %s AND BATCH_SIZE %i'%(IMAGE_SIZE[fold],MODEL_NAME.upper(),BATCH_SIZE[fold]))\n        \n    if LOAD_CSV:\n        train_data = pd.DataFrame(x_train)\n        train_data.columns = [IMAGE_NAME_ROOT]\n        train_data[LABEL_NAME] = y_train\n\n        validation_data = pd.DataFrame(x_val)\n        validation_data.columns = [IMAGE_NAME_ROOT]\n        validation_data[LABEL_NAME] = y_val\n\n        train_data[LABEL_NAME] = train_data[LABEL_NAME].astype(LABEL_NAME_TYPE)\n        validation_data[LABEL_NAME] = validation_data[LABEL_NAME].astype(LABEL_NAME_TYPE)\n        \n    train_set = MyDataset(train_data, transform = get_train_transforms())\n    val_set = MyDataset(validation_data, transform = get_val_transforms())\n    \n    #for metrics\n    dataset_sizes = { 'train': len(train_set), 'val': len(val_set)}\n    print(dataset_sizes)\n    \n    loaders = {\n        'train': DataLoader(train_set, batch_size = BATCH_SIZE[fold], \n                                               shuffle = True, num_workers = NUM_WORKERS, drop_last = DROP_LAST),\n        'val': DataLoader(val_set, batch_size = BATCH_SIZE[fold], \n                                               shuffle = False, num_workers = NUM_WORKERS, drop_last = DROP_LAST)\n    }\n    \n    val_acc = 0.0\n    val_loss = 0.0\n    val_auc = 0.0\n    early_stopping = 0\n    \n    if LOAD_CSV and skf:\n        # (String)訓練模型FOLD>1的儲存路徑\n        SAVE_MODEL_PATH = PROJECT_PATH+r'/models/'+MODEL_NAME+'_fold_%i.pt'%(fold+1)\n    else:\n        SAVE_MODEL_PATH = TRAIN_MODEL_PATH\n    \n    since = time.time()\n    for epoch in range(EPOCHS):  \n        print('Epoch: {}/{}'.format(epoch, EPOCHS - 1))\n        print('-' * 10)\n        \n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train() # Set model to training mode\n            else:\n                model.eval() # Set model to evaluate mode\n                \n            running_loss = 0.0\n            running_corrects = 0.0\n            \n            # 宣告為計算每次迭代auc\n            valid_preds, valid_targets = [], []\n                \n            # Iterate over data.\n            tq = tqdm(loaders[phase], total = len(loaders[phase]), position = TQDM_POSITION, leave = TQDM_LEAVE)\n            for idx, data in enumerate(tq):\n                # get the inputs; data is a list of [inputs, labels]\n                inputs, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n                \n                # zero the parameter gradients\n                optimizer.zero_grad()\n                \n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase=='train'):\n                    outputs = model(inputs)\n                    _, pred = torch.max(outp, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                    else:\n                        valid_preds.append(torch.softmax(outputs,1)[:,1].detach().cpu().numpy())\n                        valid_targets.append(labels.detach().cpu().numpy())\n                   \n                # statistics\n                running_loss += loss.item()*inputs.size(0)\n                running_corrects += torch.sum(pred == labels.data)\n            \n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double()/dataset_sizes[phase]\n            losses[phase].append(epoch_loss)\n            accuracies[phase].append(epoch_acc)\n            \n            # 為了計算每次迭代auc\n            valid_preds = np.concatenate(valid_preds)\n            valid_targets = np.concatenate(valid_targets)\n            epoch_auc =  roc_auc_score(valid_targets, valid_preds)\n            \n            # 為了計算全部迭代混淆矩陣\n            all_pred = np.concatenate(valid_preds)\n            all_labels = np.concatenate(valid_targets)\n            \n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n            \n            if phase == 'val':\n                print('Time: {}m {}s'.format((time.time()- since)//60, (time.time()- since)%60))\n                \n                if CALLBACKS_CHECK_POINTER:\n                    save_model = False\n                    if SAVE_BEST_ONLY:\n                        if epoch_acc > val_acc and MONITOR == \"val_acc\":\n                            val_acc = epoch_acc\n                            save_model = True\n                        elif epoch_loss < val_loss and MONITOR == \"val_loss\":\n                            val_loss = epoch_loss\n                            save_model = True\n                        elif epoch_auc > val_auc and MONITOR == \"val_auc\":\n                            val_auc = epoch_auc\n                            save_model = True\n                    else:\n                        if MONITOR == \"val_acc\":\n                            val_acc = epoch_acc\n                        elif MONITOR == \"val_loss\":\n                            val_loss = epoch_loss\n                        elif MONITOR == \"val_auc\":\n                            val_auc = epoch_auc\n                        save_model = True\n                        \n                    if SAVE_WEIGHTS_ONLY and save_model:\n                        torch.save(model.state_dict(), SAVE_MODEL_PATH)\n                    elif not SAVE_WEIGHTS_ONLY and save_model:\n                        torch.save(model, SAVE_MODEL_PATH)\n                \n#         scheduler.step()\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    \n    if SAVE_BEST_ONLY:\n        if MONITOR == \"val_acc\":\n            print('Best val Acc: {:4f}'.format(val_acc))\n        elif MONITOR == \"val_loss\":\n            print('Best val Loss: {:4f}'.format(val_loss))\n        elif MONITOR == \"val_auc\":\n            print('Best val AUC: {:4f}'.format(val_auc))\n            \n    if LOAD_CSV:\n        del x_train, x_val, y_train, y_val\n    del train_data, validation_data\n    del loaders\n    if LOAD_CSV and skf:\n        del model\n    gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# csv檔名加上副檔名，為了讀圖\nif LOAD_CSV:\n    label_list = []\n    train_list = []\n    for i in range(train_csv.shape[0]):\n        train_list.append(TRAIN_DATA_PATH + '/' + train_csv[IMAGE_NAME].iloc[i] + IMAGE_NAME_EXTENSION)\n        label_list.append(train_csv[LABEL_NAME].iloc[i])\n    df_train = pd.DataFrame(train_list)\n    df_train.columns = [IMAGE_NAME_ROOT]\n    df_train[LABEL_NAME] = label_list","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LOAD_CSV and FOLD == 1:\n    X_train, X_val, Y_train, Y_val = train_test_split(df_train[IMAGE_NAME_ROOT],df_train[LABEL_NAME], test_size = DATA_SPLIT, random_state = SEED)\n    train_process(fold = 0, skf = False, x_train = X_train, x_val = X_val, y_train = Y_train, y_val = Y_val)\n    del X_train, X_val, Y_train, Y_val\n    gc.collect()\nelif LOAD_CSV and FOLD > 1:\n    for fold,(train_index, val_index) in enumerate(SKF.split(df_train[IMAGE_NAME_ROOT], df_train[LABEL_NAME])):\n        X_train, X_val = df_train[IMAGE_NAME_ROOT].iloc[train_index], df_train[IMAGE_NAME_ROOT].iloc[val_index]\n        Y_train, Y_val = df_train[LABEL_NAME].iloc[train_index], df_train[LABEL_NAME].iloc[val_index]\n        train_process(fold = fold, skf = True, x_train = X_train, x_val = X_val, y_train = Y_train, y_val = Y_val)\n        del X_train, X_val, Y_train, Y_val\n        gc.collect()\nelse:\n    train_process(fold = 0, skf = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. 混淆矩陣<a class=\"anchor\" id=\"8\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"markdown","source":"# 8. 待辦事項<a class=\"anchor\" id=\"9\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"markdown","source":"1. 製作資料集(無csv訓練)\n2. 訓練(無csv訓練)\n3. 回調函數(提早減少，學習率遞減，tensroboard)\n4. 列印訓練過程\n5. 混淆矩陣","metadata":{}}]}