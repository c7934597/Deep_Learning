{"metadata":{"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image_Classification_Pytorch (Training)\nhttps://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html","metadata":{}},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# Table of Contents\n\n1. [套件安裝與載入](#1)\n1. [環境檢測與設定](#2)\n1. [開發參數設定](#3)\n1. [資料處理](#4)\n    -  [載入CSV檔](#4.1)\n    -  [檢查CSV檔缺失值](#4.2)\n1. [定義模型方法](#5)\n1. [定義回調函數方法](#6)\n1. [製作資料集＆資料擴增&回調函數&訓練模型](#7)\n1. [混淆矩陣](#8)\n1. [待辦事項](#9)","metadata":{}},{"cell_type":"markdown","source":"# 1. 套件安裝與載入<a class=\"anchor\" id=\"1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"!pip3 install git+https://github.com/rwightman/pytorch-image-models.git","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/rwightman/pytorch-image-models.git\n  Cloning https://github.com/rwightman/pytorch-image-models.git to /tmp/pip-req-build-bur_hkd_\n  Running command git clone -q https://github.com/rwightman/pytorch-image-models.git /tmp/pip-req-build-bur_hkd_\nRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm==0.4.8) (1.7.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm==0.4.8) (0.8.1)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.8) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.8) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.8) (0.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.8) (1.19.5)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.4.8) (7.2.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# 資料處理套件\nimport os\nimport cv2\nimport sys\nimport time\nimport timm\nimport copy\nimport random\nimport datetime\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport albumentations as A\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# 設定顯示中文字體\nfrom matplotlib.font_manager import FontProperties\nplt.rcParams['font.sans-serif'] = ['Microsoft JhengHei'] # 用來正常顯示中文標籤\nplt.rcParams['font.family'] = 'AR PL UMing CN'\nplt.rcParams['axes.unicode_minus'] = False # 用來正常顯示負號","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# pytorch深度學習模組套件\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torch.nn.functional as F\nimport torchvision\n\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.nn.modules.loss import _WeightedLoss\nfrom torchvision import models","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# 2. 環境檢測與設定<a class=\"anchor\" id=\"2\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nDEVICE","metadata":{"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"'''執行環境參數設定'''\n\n# (Boolean)是否為本機\nLOCAL = False\n\n# (Boolean)是否為 Colab\nCOLAB = False\n\n\n'''檔案路徑參數設定'''\n\n# (String)Root路徑\nif LOCAL:\n    PATH = r'../'\nelif COLAB:\n    PATH = r'/content/drive/My Drive/Colab Notebooks/'\nelse:\n    PATH = r'../input/'\n    OUTPUT_PATH = r'/kaggle/working/'\n    \n# (String)資料根路徑\nDATA_ROOT_PATH = PATH+r'aptos2019-blindness-detection/' \n\n# (String)訓練資料路徑\nTRAIN_DATA_PATH = DATA_ROOT_PATH+r'train_images/'\n\n# (String)訓練CSV路徑，如為None則不讀CSV檔\nTRAIN_CSV_PATH = DATA_ROOT_PATH+r'train.csv'\n\n# (String)專案名稱\nPROJECT_NAME = 'Blindness Detection'\n\n# (String)專案檔案儲存路徑\nif LOCAL or COLAB:\n    OUTPUT_PATH = PATH\nPROJECT_PATH = OUTPUT_PATH+PROJECT_NAME+'/'+PROJECT_NAME+' '+datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n\n# (String)權重名稱(使用哪個權重)\nWEIGHTS_NAME = 'efficientnetb7'\n\n# (String)模型名稱(使用哪個模型)\nMODEL_NAME = 'efficientnetb7'\n\n# (String)讀取預訓練權重的儲存路徑 \nLOAD_WEIGHTS_PATH = PROJECT_PATH+r'/models/backup/'+WEIGHTS_NAME+'.pth'\n\n# (String)讀取預訓練模型的儲存路徑 \nLOAD_MODEL_PATH = PROJECT_PATH+r'/models/backup/'+MODEL_NAME+'.pth'\n\n# (String)訓練模型的儲存路徑\nTRAIN_MODEL_PATH = PROJECT_PATH+r'/models/'+MODEL_NAME+'.pth'","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"if not LOCAL and COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"if DEVICE != \"CPU\":\n    !nvidia-smi","metadata":{"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Thu Apr 29 09:26:50 2021       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   36C    P0    34W / 250W |      2MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"if os.path.isfile(TRAIN_CSV_PATH):\n    LOAD_CSV = True\nelse:\n    LOAD_CSV = False","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"if not os.path.isdir(PROJECT_PATH+r'/models/'):\n    os.makedirs(PROJECT_PATH+r'/models/')","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# 3. 開發參數設定<a class=\"anchor\" id=\"3\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"'''客製參數設定'''\n\n\n'''資料參數設定'''\n\n# (Int)分類數量\nCLASSES = 5\n\n# (Int)有CSV檔該參數才有用，1則為不做交叉驗證\nFOLD = 1\n\n# (Int)沒CSV檔，FOLD該參數固定為1\nif not LOAD_CSV:\n    FOLD = 1\n    \n# (Int)圖片尺寸\nIMAGE_SIZE = [224]*FOLD\n\n# (String)圖片副檔名\nIMAGE_NAME_EXTENSION = '.png'\n\n# (String)CSV圖片檔名欄位\nIMAGE_NAME = 'id_code'\n\n# (String)CSV標籤欄位\nLABEL_NAME = 'diagnosis'\n\n# (String)CSV標籤欄位類型\nLABEL_NAME_TYPE = 'string'\n\n# (Boolean)CSV圖片檔名欄位是否包含副檔名\nIMAGE_NAME_HAVE_EXTENSION = False\n\n#  (Boolean)圖像轉為RGB\nCOLOR_CONVERT_RGB = True\n\n# (Int)不同的種子會產生不同的Random或分層K-FOLD分裂, 42則是預設固定種子\nSEED = 42\n\nif FOLD == 1:\n    # (Float)驗證集佔訓練集的比率，FOLD>1則不啟用\n    DATA_SPLIT = 0.2\nelse:\n    # (String)切分訓練集跟驗證集方式\n    SKF = StratifiedKFold(n_splits=FOLD,shuffle=True,random_state=SEED)\n\n# (Boolean)是否資料轉Tensor時啟動鎖頁內存(GPU內存)，而不鎖頁內存就是會使用到硬碟虛擬內存\nPIN_MEMORY = False\n\n# (Int)要用於數據加載的子進程數。0表示將在主進程中加載數據。（默認值：0）\nNUM_WORKERS = 0\n\n# (Boolean)批次處理在大小不合適的情況下，是否刪除最後一個不完整的批次\nDROP_LAST = False\n    \n# (Boolean)如為True每次返回的卷積算法將是確定的，即默認算法\nCUDNN_DETERMINISTIC = True\n\n# (Boolean)PyTorch 中對模型裡的卷積層進行預先的優化，也就是在每一個卷積層中測試 cuDNN 提供的所有卷積實現算法，\n# 然後選擇最快的那個。這樣在模型啟動的時候，只要額外多花一點點預處理時間，就可以較大幅度地減少訓練時間\nCUDNN_BENCHMARK = True\n\n\n'''資料擴增參數設定\n\n資料擴增範例\nhttps://zh-hant.hotbak.net/key/albumentation%E6%95%B8%E6%93%9A%E5%A2%9E%E5%BC%B7CSDN.html\n\n資料擴增教學\nhttps://zhuanlan.zhihu.com/p/107399127\n\n資料擴增Doc\nhttps://vfdev-5-albumentations.readthedocs.io/en/docs_pytorch_fix/api/augmentations.html\n'''\n\n# (Float)訓練集資料擴增的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_TRAIN_TRANSFORMS = 1.0\n\n# (Float)驗證集資料擴增的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_VAL_TRANSFORMS = 1.0\n\n# 以下資料擴增為訓練集使用=============================================\n\n# (Float)模糊的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_BLUR = 0\n\n# (Int)模糊的上限\nBLUR_LIMIT = 3\n\n# (Float)水平翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_HORIZONTALFLIP = 0.5\n\n# (Float)垂直翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_VERTICALFLIP = 0\n\n# (Float)水平和垂直翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_FLIP = 0\n\n# (Float)隨機旋轉90度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RANDOMROTATE90 = 0\n\n# (Float)平移縮放旋轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_SHIFTSCALEROTATE = 0\n\n# (Float)平移縮放旋轉的平移上限\nSHIFTSCALEROTATE_SHIFT_LIMIT = 0.0625\n\n# (Float)平移縮放旋轉的縮放上限\nSHIFTSCALEROTATE_SCALE_LIMIT = 0.1\n\n# (Float)平移縮放旋轉的旋轉上限\nSHIFTSCALEROTATE_ROTATE_LIMIT = 45\n\n# (Float)彈性變換的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_ELATICTRANSFORM = 0\n\n# (Float)彈性變換的alpha高斯過濾參數\nELATICTRANSFORM_ALPHA = 1\n\n# (Float)彈性變換的sigma高斯過濾參數\nELATICTRANSFORM_SIGMA = 50\n\n# (Float)彈性變換的alpha_affine，範圍為（-alpha_affine，alpha_affine）\nELATICTRANSFORM_ALPHA_AFFINE = 50\n\n# (Float)網格失真的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_GRIDDISTORTION = 0\n\n# (Int)網格失真的每一條邊上網格單元數量\nGRIDDISTORTION_NUM_STEPS = 5\n\n# (Float)隨機亮度對比度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RANDOMBRIGHTNESSCONTRAST_CONTRAST = 0\n\n# (Float)隨機亮度的上限\nRANDOMBRIGHTNESSCONTRAST_BRIGHTNESS_LIMIT = 0.2\n\n# (Float)隨機對比度的上限\nRANDOMBRIGHTNESSCONTRAST_CONTRAST_LIMIT = 0.2\n\n# (Float)隨機色調飽和度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_HUESATURATIONVALUE = 0\n\n# (Float)隨機色調飽和度的色調上限\nHUESATURATIONVALUE_HUE_SHIFT_LIMIT = 20\n\n# (Float)隨機色調飽和度的飽和度上限\nHUESATURATIONVALUE_SAT_SHIFT_LIMIT = 30\n\n# (Float)隨機色調飽和度的值上限\nHUESATURATIONVALUE_VAL_SHIFT_LIMIT = 20\n\n# (Float)對比度受限自適應直方圖均衡的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_CLAHE = 0\n\n# (Float)對比度受限自適應直方圖均衡的對比度上限\nCLAHE_CLIP_LIMIT = 4.0\n\n# (Float)隨機在圖像上生成黑色矩形的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_COARSEDROPOUT = 0\n\n# (Int)隨機在圖像上生成黑色矩形的數量\nCOARSEDROPOUT_NUM_HOLES = 8\n\n# (Int)隨機在圖像上生成黑色矩形的最大高度\nCOARSEDROPOUT_MAX_H_SIZE = 8\n\n# (Int)隨機在圖像上生成黑色矩形的最大寬度\nCOARSEDROPOUT_MAX_W_SIZE = 8\n\n# (Float)隨機縮放剪裁的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RANDOMRESIZEDCROP = 0\n\n# (Float Tuple)隨機縮放剪裁之前的圖像比例縮放\nRANDOMRESIZEDCROP_SCALE = (0.08, 1.0)\n\n# (Int)隨機縮放剪裁之前的圖像高度\nRANDOMRESIZEDCROP_HEIGHT = IMAGE_SIZE[0]\n\n# (Int)隨機縮放剪裁之前的圖像寬度\nRANDOMRESIZEDCROP_WIDTH = IMAGE_SIZE[0]\n\n# 以上資料擴增為訓練集使用=============================================\n\n# 以下資料擴增為訓練集和驗證集共用======================================\n\n# (Float)縮放的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_RESIZE = 1.0\n\n# (Int)縮放後的圖片高度\nRESIZE_HEIGHT = IMAGE_SIZE[0]\n\n# (Int)縮放後的圖片寬度\nRESIZE_WIDTH = IMAGE_SIZE[0]\n\n# (Float)正規化的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_NORMALIZE = 1.0\n\n# (List)正規化的平均值(Imagenet的參考平均值[0.485, 0.456, 0.406])\nNORMALIZE_MEAN = [0.485, 0.456, 0.406]\n\n# (List)正規化的標準差(Imagenet的參考標準差[0.229, 0.224, 0.225])\nNORMALIZE_STD = [0.229, 0.224, 0.225]\n\n# (Float)正規化的PIXEL最大值(Imagenet的參考PIXEL最大值255.0)\nNORMALIZE_MAX_PIXEL_VALUE = 255.0\n\n# (Float)歸一化的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n# ToTensorV2()將[0, 255]的PIL.Image或[H, W, C]的numpy.ndarray數據，\n# 轉換為形狀[C, H, W]的torch.FloadTensor，並歸一化到[0, 1.0]。\nP_TOTENSORV2 = 1.0\n\n# 以上資料擴增為訓練集和驗證集共用======================================\n\n\n''''模型參數設定'''\n\n# (Boolean)使用基礎模型，如為False則須客制另外撰寫\nUSE_BASE_MODEL = True\n\nif USE_BASE_MODEL:\n    # (Boolean)使用基礎timm模型，如為False則使用基礎Pytorch模型\n    USE_BASE_TIMM_MODEL = False\n    if USE_BASE_TIMM_MODEL:\n        # (Model)建立timm模型\n        BASE_MODEL = \"tf_efficientnet_b4_ns\"\n    else:\n        # (Model)建立Pytorch模型\n        BASE_MODEL = models.resnet18\n    \n# (Boolean)是否使用基礎模型權重\nLOAD_BASE_WEIGHTS = True\n\n# (Boolean)基礎模型是否包含完全連接網路頂部的網路層\nINCLUDE_TOP = True\n\n# (Boolean)基礎模型是否可訓練權重(不包括頂部網路層)\nBASE_MODEL_TRAINABLE = True\n\n# (Boolean)是否已有客製模型，僅載入權重\nLOAD_WEIGHTS = False\n\n# (Boolean)是否載入完整客製(模型+權重)\nLOAD_MODEL = False\n\n# (Float)Dropout比率 0.5\nDROPOUT = 0.5\n\n# (Boolean)Bias偏移量\nBIAS = True\n\n# (Boolean)是否印出完整模型\nMODEL_PRINT = False\n\n\n''''回調函數參數設定\n\n學習率遞減\nhttps://zhuanlan.zhihu.com/p/69411064\n\n回調函數Doc\nhttps://pytorch.org/docs/stable/optim.html\n\n模型儲存\nhttps://pytorch.org/tutorials/beginner/saving_loading_models.html\n\n'''\n\n# (Boolean)回調函數 ModelCheckpoint 是否啟用\nCALLBACKS_CHECK_POINTER = True\n\n# (Boolean)回調函數 StepLR 是否啟用\nCALLBACKS_STEPLR = True\n\n# (Boolean)回調函數 ReduceLROnPlateau 是否啟用\nCALLBACKS_REDUCELRONPLATEAU = False\n\n# (Boolean)回調函數 CosineAnnealingWarmRestarts 是否啟用\nCALLBACKS_COSINEANNEALINGWARMRESTAERS = False\n\n# (String)回調函數監控數值(val_auc 僅限雙分類) val_acc/val_loss/val_auc\nMONITOR = 'val_loss'\n\n# (Boolean)回調函數 ModelCheckpoint 是否只儲存最佳模型 False\nSAVE_BEST_ONLY = True\n\n# (Boolean)回調函數 ModelCheckpoint 是否只儲存權重 True\nSAVE_WEIGHTS_ONLY = True\n\n# (Int)學習率衰減的時間段\nSTEP_SIZE = 15\n\n# (Float)學習率衰減的乘數 0.1\nGAMMA = 0.1\n\n# (String)最小，最大之一 在最小模式下，當監視的數量停止減少時，lr將減小； 在最大模式下，當監視的數量停止增加時，它將減少。 min\nMODE = \"min\"\n\n# (Float)學習率降低的因數。new_lr = lr *因子 0.1\nFACTOR = 0.1\n\n# (Int)沒有改善的時期數，此後學習率將降低。例如，如果 耐心= 2，那麼我們將忽略前兩個時期而沒有任何改善，\n# 並且如果損失仍然沒有改善，則只會在第三個時期之後降低LR。 10\nPATIENCE = 10 \n\n# (Float)用於測量新的最佳閾值，僅關注重大變化。 1e-4\nTHRESHOLD = 1e-4 \n\n# (String)rel，abs之一。在rel模式下，“ max”模式下的dynamic_threshold = best *（1 +閾值），在min模式下，\n# dynamic_threshold = best *（1-threshold）。在絕對模式下，dynamic_threshold =最佳+ 最大模式下的閾值或最佳-最小模式下的閾值。 rel\nTHRESHOLD_MODE = \"rel\"\n\n# (Int)減少lr後恢復正常運行之前要等待的時期數。 0 \nCOOLDOWN = 0\n\n# (Float/List)標量或標量列表。所有參數組或每個組的學習率的下限。 0 \nMIN_LR = 0\n\n# (Float)應用於lr的最小衰減。如果新舊lr之間的差異小於eps，則忽略該更新。 1e-8\nSCHEDULER_EPS = 1e-8\n\n# (Int)第一次重啟的迭代次數。\nT_0 = 15\n\n# (Int)重新啟動後，因素增加。 1 \nT_MULT = 1\n\n# (Int)最低學習率。 0\nETA_MIN = 0\n\n# (Boolean)每次更新都會向輸出印出一條消息。 False\nSCHEDULER_VERBOSE = False\n\n# (Boolean)訓練集每批就更新回調函式，否則每時代就更新。 False\nSCHEDULER_BATCH_UPDATE = False\n\n# (Boolean)驗證集回調函式是否啟用。 False\nVAL_ENABLE_SCHEDULER = False\n\n# (Boolean)驗證集通過計算LOSS就更新回調函式，否則不計算就更新。 False\nSCHEDULER_LOSS_UPDATE = False\n\n\n''''編譯參數設定\n\n編譯參數Doc\nhttps://pytorch.org/docs/stable/optim.html\n\n'''\n\n# (String)優化器指定(SGD/Adam/Adamax/RMSprop/Adagrad)，None為客制，須另外撰寫\nOPTIMIZERS_TYPE = \"Adam\"\n\n# (Float)優化器學習率 1e-3/1e-1\nLEARNING_RATE = 1e-3\n\n# (Float)學習速率衰減 0\nLR_DECAY = 0\n\n# (Float)優化器權重衰減 5e-5/5e-4\nWEIGHT_DECAY = 5e-5\n\n# (Float)加速優化器在相關方向上前進，並抑制震盪 0.9\nMOMENTUM = None\n\n# (Tuple Float)用於計算梯度及其平方的移動平均值的係數 (0.9, 0.999)\nBETAS = (0.9, 0.999)\n\n# (Float)分母中添加的項，以提高數值穩定性 1e-8\nEPS = 1e-8\n\n# (Float)平滑常數 0.99\nALPHA = 0.99\n\n# (Boolean)計算居中RMSProp，則通過估計其方差來對梯度進行歸一化 True\nCENTERED = True\n\n# (Float)阻尼動量 0\nDAMPENING = 0\n\n# (Boolean)啟用Nesterov動量 False\nNESTEROV = False\n\n# (String)損失函數，None為客制，須另外撰寫\nBASE_LOSSES = nn.CrossEntropyLoss\n\n# (String)指定還原成適用於輸出，預設mean\nREDUCTION = \"mean\"\n\n# (Boolean)是否印出完整編譯器\nOPTIMIZER_PRINT = False\n\n\n''''訓練參數設定'''\n\n# (Int List)每批訓練的尺寸\nBATCH_SIZE = [256]*FOLD\n\n# (Int)訓練做幾次時代\nEPOCHS = [2]*FOLD\n\n# (Int)指定列印進度條的位置（從0開始）。\nTQDM_POSITION = 0\n\n# (Boolean)保留迭代結束時進度條的所有痕跡。如果是None，只會在position是0時離開\nTQDM_LEAVE = True\n\n# https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2021/02/19/gradient-accumulation.html\n# (Int)假設您要在一批中使用32張圖像，但是一旦超出8張，硬件就會崩潰。\n# 在這種情況下，您可以使用8張圖像的批次並每4批次更新一次權重，因此設置 4。\nACCUM_ITER = 1\n\n\n''''圖表參數設定'''\n\n# (Float)全部SNS圖表的字形縮放\nALL_SNS_FONT_SCALE = 1.0\n\n# (Int)CSV缺失值圖表寬度\nCSV_COUNTPLOT_FIGSIZE_W = 10\n\n# (Int)CSV缺失值圖表高度\nCSV_COUNTPLOT_FIGSIZE_H = 10\n\n# (Int)CSV缺失值圖表標題字型大小\nCSV_COUNTPLOT_TITLE_FONTSIZE = 20\n\n# (Int)CSV缺失值圖表X軸標題字型大小\nCSV_COUNTPLOT_XLABEL_FONTSIZE = 15\n\n# (Int)CSV缺失值圖表Y軸標題字型大小\nCSV_COUNTPLOT_YLABEL_FONTSIZE = 15","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = CUDNN_DETERMINISTIC\n    torch.backends.cudnn.benchmark = CUDNN_BENCHMARK\n\nseed_everything(SEED)","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# 設置sns圖表縮放係數\nsns.set(font_scale = ALL_SNS_FONT_SCALE)","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# 4. 資料處理<a class=\"anchor\" id=\"4\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"markdown","source":"## 4.1 載入CSV檔 <a class=\"anchor\" id=\"4.1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"if LOAD_CSV:\n    print('Reading data...')\n\n    # 讀取訓練資料集CSV檔\n    train_csv = pd.read_csv(TRAIN_CSV_PATH,encoding=\"utf8\")\n\n    print('Reading data completed')","metadata":{"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Reading data...\nReading data completed\n","output_type":"stream"}]},{"cell_type":"code","source":"if LOAD_CSV:\n    # 顯示訓練資料集CSV檔\n    print(train_csv.head())","metadata":{"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"        id_code  diagnosis\n0  000c1434d8d7          2\n1  001639a390f0          4\n2  0024cdab0c1e          1\n3  002c21358ce6          0\n4  005b95c28852          0\n","output_type":"stream"}]},{"cell_type":"code","source":"if LOAD_CSV:\n    print(\"Shape of train_data :\", train_csv.shape)","metadata":{"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Shape of train_data : (3662, 2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 4.2 檢查CSV檔缺失值 <a class=\"anchor\" id=\"4.2\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"# 缺失值比率\nif LOAD_CSV:\n    total = train_csv.isnull().sum().sort_values(ascending = False)\n    percent = (train_csv.isnull().sum()/train_csv.isnull().count()*100).sort_values(ascending = False)\n    missing_train_csv  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    print(missing_train_csv.head())","metadata":{"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"           Total  Percent\ndiagnosis      0      0.0\nid_code        0      0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"if LOAD_CSV:\n    print(train_csv[LABEL_NAME].value_counts())\n    f,ax = plt.subplots(figsize=(CSV_COUNTPLOT_FIGSIZE_W, CSV_COUNTPLOT_FIGSIZE_H))\n    sns.countplot(train_csv[LABEL_NAME], hue = train_csv[LABEL_NAME],ax = ax)\n    plt.title(\"LABEL COUNT\", fontsize=CSV_COUNTPLOT_TITLE_FONTSIZE)\n    plt.xlabel(LABEL_NAME.upper(), fontsize=CSV_COUNTPLOT_XLABEL_FONTSIZE)\n    plt.ylabel(\"COUNT\", fontsize=CSV_COUNTPLOT_YLABEL_FONTSIZE)\n    plt.legend()\n    plt.show()","metadata":{"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"0    1805\n2     999\n1     370\n4     295\n3     193\nName: diagnosis, dtype: int64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x720 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAnQAAAJpCAYAAAAkIa+KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAAA5n0lEQVR4nO3de3hMdwL/8c9MYuIaibg0gnpQkaJ1idjuiq6wy7aUupQNsrR6r21ZLKXSTaU2ka1WS7Xr0lJLtUoal4ZK2V62VNW26FZ/trQkJSIXcUlkZn5/+JmfbOQmYyZfeb+ex/Nszvme7/mO9eR595yZMxan0+kUAAAAjGX19gIAAABQNQQdAACA4Qg6AAAAwxF0AAAAhiPoAAAADEfQAQAAGI6gAwAAMJyvtxcAwHyhoaGSpO+++67Sx/bv319HjhxR165dtWbNmlLHjR07Vrt37y62zcfHRwEBAerUqZNGjx6tO++8s9S1lWXFihXq2bOnJOm9997TjBkzdO+99+qvf/1rJV9NSRkZGVq1apU+++wz/fTTTzp37pz8/f0VGhqqPn36aOjQoWrQoEGJ43744QetWLFC//rXv3TixAk5nU41a9ZMd9xxh2JiYtSmTZsSx1Rk7bt27VJMTIwiIiK0cuVK1/aXX35Zr7zyiiRp9uzZGj16dKnzP/LII5o0aVKxYyoiJCREaWlpFR4PoOIIOgBe8/nnn+vIkSOyWCz66quvdOjQIbVv377MY+69916FhIRIki5cuKAffvhBO3fu1M6dOxUXF6eRI0de9bgnnnii1Dkvz+du77zzjuLi4lRYWKgOHTro7rvvVsOGDZWdna29e/fq+eef16JFi7Rr165ix61YsUJ//etf5XA41KNHD/Xp00eSdODAAa1Zs0Zr167V9OnTFRMTc13WvXDhQg0ePFj169cvc1xERESJv9dvv/1W27dvV4cOHdSvX79i+64WrgDcg6AD4DVr166VJD344IN6/fXXtXbtWs2aNavMY+69917X1bTLUlNT9cc//lGvvfZaqUE3ceJE9yy6gt5//33NmjVLDRs21Msvv6xf//rXJcZ8+eWXiouLK7Ztw4YNio+PV0BAgF555RX16NGj2P49e/bo8ccfV3x8vPz9/TVkyBC3rvvmm2/W0aNH9fe//12TJk0qc2zPnj1L/H/x3nvvafv27QoLC/P43zlQk/EeOgBekZ2drW3btql169Z68skn1aRJE73//vsqKCio9Fy/+tWvJEmnT5929zKvSX5+vuLj4yVJL7zwwlVjTpK6d++ud955p9hxzz//vCQpKSmpRMxJUnh4uObNmydJmjt3rvLz89269jFjxqhp06Z644039PPPP7t1bgDXD0EHwCs2bNigwsJC3XvvvfL19dWgQYOUm5urLVu2VHquf/3rX5KkTp06uXuZ1yQ1NVU5OTnq0qWLevXqVeZYm81W7Ljc3FzddtttioyMLPWY3r17q3PnzsrJyVFqaqrb1i1JderU0ZNPPqkLFy5o/vz5bp0bwPXDLVcAXrF27VpZrVbXLcN7771Xy5Yt09q1a8u8jbh+/XrXhyMKCgp05MgR7dixQ+3atdOzzz5b6nEvv/zyVbf7+fnpoYceutaXcVVffvmlJOkXv/jFNR33y1/+styxv/rVr/TNN99o7969GjZsWOUXWYahQ4fqzTff1Pvvv69x48YpLCzMrfMDcD+CDoDH7dmzR//973/Vq1cv3XTTTZKk9u3bq2PHjvryyy91+PBhtW3b9qrHrl+/vsS2gIAADRo0SK1atSr1nKV9GrNBgwZuD7rMzExJcr2263Hc5TEnT56s5OrKZ7VaNW3aNE2YMEGJiYlavny5288BwL0IOgAe9/bbb0u6dCXoSkOHDtWBAwe0du1azZgx46rHXvmIkYsXL+r48eN68803NX/+fH388cdauXKlrNaS7ya5lkeq1GSRkZHq1auXPvnkE+3cufOqj4QBUH3wHjoAHpWbm6vU1FT5+/uXeKzFwIEDVatWLdf768pTq1YttW7dWrGxserWrZv27NmjzZs3X6+lV1iTJk0kSSdOnKjUcY0bN5akCn0Y4fKYpk2burZdDlmHw1HqcZf3WSyWcs8xdepUWa1WzZs3T3a7vdzxALyHoAPgURs2bFBBQYHy8vJ02223KTQ01PWnZ8+eunjx4jW92f/222+XJH399dfXY9mV0r17d0mXnrN3Lcd99tln5Y69PKZbt26ubZefG5eTk1PqcdnZ2ZIkf3//cs/RoUMHDRkyRN9//73WrVtX7ngA3kPQAfCoy4/pGDhwoIYPH17iT//+/SX9/2fUVVRubq6ksq9OeUr//v0VEBCgr776qtw4u/JK5IABA+Tv76+vv/5an376aanHfPrpp/r6668VEBDg+vuSLgWYJH3zzTcqKiq66rH79u0rNrY8Tz31lOrUqaMFCxbo/PnzFToGgOcRdAA8Zu/evfr+++/Vrl07/e1vf1N8fHyJPy+++KJCQkK0e/duHTlypELzHjt2TNu2bZOkEg+69Yb69etr5syZkqRJkybp448/vuq4ffv2FXsQcv369fXnP/9ZkvSnP/3J9anXK+3du1d/+tOfJEkzZswo9m0OLVq0UEREhE6fPq1XX321xLHfffed3nnnHfn6+uqee+6p0Gtp1qyZxo8fr8zMTL355psVOgaA5/GhCABuM3369FL3xcbGuq66DR8+vNRxVqtVQ4cO1csvv6y3337bFTiXXfnYkqKiIh0/flzbt2/XuXPn1KdPnxLvy7ustMeWSFK/fv1KPJrjyy+/LPX13HrrreV+7dY999yjgoICxcXFacKECQoLC1PXrl3l7++vnJwc7du3T//5z38UGBhY7Ljhw4frzJkzmjdvnkaPHq2IiAh17NhRFotFBw4c0K5du2S1WvX0009f9fEu8fHxGj16tF555RV99NFHioiIkJ+fn3744QelpaXJbrdr1qxZZX4i+H9NmDBBa9eu1dGjRyt8DADPIugAuM3VHily2cSJE/XBBx+oVq1aGjx4cJnzDBs2TAsXLtSGDRs0adKkYg/fvfIcFotFDRo0UFhYmAYPHqzhw4eX+mb/sr5EPiQkpETQ/fjjj/rxxx+vOj4vL69C36M6YsQI9erVS2+99ZY+++wzpaSk6Pz582rQoIFuueUWzZgx46pxO378ePXu3VsrVqzQ559/rn//+9+SLj2qZOTIkYqJiSn1sS6tWrVScnKyli9frh07dujtt9/WxYsX1ahRI/Xr108xMTHF3ndXEfXq1dPEiRMVGxtbqeMAeI7F6XQ6vb0IAAAAXDveQwcAAGA4gg4AAMBwBB0AAIDhCDoAAADDEXQAAACGI+gAAAAMx3PoJGVnn5XDwdNbAABA9WW1WhQYWO+q+wg6SQ6Hk6ADAADG4pYrAACA4Qg6AAAAw3HLFQAA3LDs9iJlZ2eqqKjQ20upMF9fmwIDm8jHp+KZRtABAIAbVnZ2pmrXrqt69W6SxWLx9nLK5XQ6dfZsnrKzM9W4cXCFj+OWKwAAuGEVFRWqXj1/I2JOkiwWi+rV86/0FUWCDgAA3NBMibnLrmW9BB0AAIDheA8dAACoMRr411Ztv1pun/dCwUWdybtQobE//nhU8fHPKjc3Vw0bNtSsWX9Ry5atqnR+gg4AANQYtf1qKXraKrfP+4/E0TqjigVdUtJcDR06Qv3736XU1M2aN+95LViwuErn55YrAACAh2Rnn9ahQ/9Rv379JUn9+vXXoUP/UXZ2dpXmJegAAAA85MSJE2rcuKl8fHwkST4+PmrcuIlOnjxRpXkJOgAAAMMRdAAAAB7SrFkznTp1Una7XZJkt9t16lSmmjZtVqV5CToAAAAPCQxspHbt2uvDD1MlSR9+mKpbbglVYGBgleblU64AAAAeNHXq05ozJ1bLly9RgwYN9Mwzf6nynBan0+l0w9qMlpWVL4ejxv81AABww/n556O66aabXT9Xh+fQVcT/rluSrFaLgoLqX3U8V+gAAECNcSbvQoWfF2cS3kMHAABgOIIOAADAcAQdAACA4Qg6AAAAwxF0AAAAhuNTrgAAoMYIbGiTr83P7fMWFRYoO7fQ7fNWFEFXCe56do27n1UDAAAqxtfmpy8TJ7h93u7TlkgqP+heeeVF7dyZpoyMdK1YsUZt2rRzy/kJukqo7VdL0dNWVXmefySOviGfgQMAAMoWGflrjRgxSo8//qBb5yXoAAAAPOT227tcl3n5UAQAAIDhCDoAAADDEXQAAACGI+gAAAAMx4ciAABAjVFUWPD/HjHi/nkr4sUX52nnzo90+nSWnnrqcfn7N9Rbb62t8vkJOgAAUGNceviv9x4A/NRTU/XUU1PdPi+3XAEAAAxH0AEAABiOoAMAADCcx99Dl5CQoNTUVB0/flwpKSlq3769jh07pscff9w15syZM8rPz9fu3bslSVFRUbLZbPLzu/RlulOmTFFkZKQkad++fZo9e7YKCgoUEhKiefPmKSgoyNMvCwAAwGs8HnR9+/ZVTEyMRo8e7drWokULJScnu36Oj4+X3W4vdtyCBQvUvn37YtscDoemTp2quXPnKjw8XIsWLVJSUpLmzp17fV8EAABANeLxW67h4eEKDg4udX9hYaFSUlI0bNiwcufav3+//Pz8FB4eLkkaNWqUPvjgA7etFQAAwATV7rElaWlpatasmTp27Fhs+5QpU+R0OtW9e3dNnjxZ/v7+ysjIUPPmzV1jGjVqJIfDoZycHAUEBFT4nEFB9d21/Apr0qSBx88JAEBNc/KkVb6+///6Vd36teRXy+b28xRcLNS5/IvljsvNzdGzzz6j48ePqVatWmrRoqWmT5+lwMDAYuOsVmulWqHaBd26detKXJ1btWqVgoODVVhYqPj4eMXFxSkpKclt58zKypfD4Sx3nDsjLDPzjNvmAgAAV+dwOFRU5HD97FfLpnHLn3T7ed4Y/5Lyisp/uLDd7tTvfz9W3bpduru4cOFLeuWVlzRjxuxi4xwOR4lWsFotpV6Eqlafcj1x4oS++OILDRo0qNj2y7dobTaboqOjtXfvXtf29PR017jTp0/LarVW6uocAACAp/j7N3TFnCR17NhJP//8c5XnrVZBt379et15553FLjueO3dOZ85cKlSn06nNmzcrLCxMktSpUydduHBBe/bskSStWbNGAwYM8PzCAQAAKsnhcGj9+nXq1at3lefy+C3XOXPmaOvWrTp16pTGjx+vgIAAbdq0SdKloJs5c2ax8VlZWZo4caLsdrscDofatm2r2NhYSZfuLycmJio2NrbYY0sAAACqu/nz56lu3ToaNuy+Ks/l8aCbNWuWZs2addV9qampJba1bNlSGzZsKHW+bt26KSUlxV3LAwAAuO5eeeVFHTv2oxIS5stqrfoN02r3oQgAAIAb2WuvLdR3332refNeks3mnk/cEnQAAAAe8t//HtbKlcvVsmUrPfLI/ZKk4ODmmju3ak/vIOgAAECNUVBYqDfGv3Rd5q2INm3a6pNP9rj9/AQdAACoMfJyCySV/7w401Srx5YAAACg8gg6AAAAwxF0AAAAhiPoAAAADEfQAQAAGI5PuQIAgBojoIFNtWr7uX3eixcKlHOmYo8uuR4IOgAAUGPUqu2nzTHj3T7vXSuWSxUMuhkz/qT09HRZrRbVqVNXkyZN1S23hFbp/AQdAACAB82c+RfVr19fkvTxxzs0d26cli1bVaU5eQ8dAACAB12OOUnKz8+XxVL1HOMKHQAAgIf99a/PaffuzyVJSUkLqjwfV+gAAAA8bPr0Z/Tee5v00EOPadGiqn+3LEEHAADgJQMG3K29e79Ubm5OleYh6AAAADzk3LlzOnHiZ9fPn3zyT/n7+8vfv2GV5uU9dAAAoMa4eKHg0iNGrsO8FXHhwnk988x0XbhwXlarj/z9/ZWQMF8Wi6VK5yfoAABAjZFzprDCz4u7Hho1CtLrr7/h9nm55QoAAGA4gg4AAMBwBB0AAIDhCDoAAADDEXQAAACGI+gAAAAMx2NLAABAjdHQv45sfu7Pn8KCIuXmna/w+GXLXteyZa9rxYo1atOmXZXPT9ABAIAaw+bnq+dnvuv2eZ+OH17hsd999x8dOLBfN90U7Lbzc8sVAADAQwoLC/XCCwmaMmW6W+cl6AAAADxkyZLF+u1vf6fg4OZunZegAwAA8ID9+7/Wd999q6FDR7h9boIOAADAA776aq+OHPlBI0bco+HDBykz86QmT56o3bs/r/LcfCgCAADAA8aOHaexY8e5fh4+fJASE+e75VOuXKEDAAAwHFfoAABAjVFYUFSpR4xUZt7KevfdFLedn6ADAAA1RmUe/msSbrkCAAAYjqADAAAwHEEHAABuaE6n09tLqJRrWS9BBwAAbli+vjadPZtnTNQ5nU6dPZsnX19bpY7jQxEAAOCGFRjYRNnZmcrPz/H2UirM19emwMAmlTvmOq0FAADA63x8fNW4cbC3l3HdccsVAADAcAQdAACA4Qg6AAAAwxF0AAAAhiPoAAAADEfQAQAAGI6gAwAAMBxBBwAAYDiCDgAAwHAEHQAAgOEIOgAAAMMRdAAAAIYj6AAAAAxH0AEAABiOoAMAADAcQQcAAGA4gg4AAMBwBB0AAIDhCDoAAADDEXQAAACGI+gAAAAMR9ABAAAYzuNBl5CQoKioKIWGhurQoUOu7VFRURowYIAGDx6swYMH6+OPP3bt27dvn+655x71799f999/v7Kysiq0DwAAoCbweND17dtXq1atUkhISIl9CxYsUHJyspKTkxUZGSlJcjgcmjp1qmbPnq3U1FSFh4crKSmp3H0AAAA1hceDLjw8XMHBwRUev3//fvn5+Sk8PFySNGrUKH3wwQfl7gMAAKgpfL29gCtNmTJFTqdT3bt31+TJk+Xv76+MjAw1b97cNaZRo0ZyOBzKyckpc19AQECFzxsUVN+dL6NCmjRp4PFzAgCAG1O1CbpVq1YpODhYhYWFio+PV1xcnMdun2Zl5cvhcJY7zp0Rlpl5xm1zAQCAG5/Vain1IlS1+ZTr5duwNptN0dHR2rt3r2t7enq6a9zp06dltVoVEBBQ5j4AAICaoloE3blz53TmzKUrVk6nU5s3b1ZYWJgkqVOnTrpw4YL27NkjSVqzZo0GDBhQ7j4AAICawuO3XOfMmaOtW7fq1KlTGj9+vAICArR48WJNnDhRdrtdDodDbdu2VWxsrCTJarUqMTFRsbGxKigoUEhIiObNm1fuPgAAgJrC4nQ6y3/z2A2uMu+hi562qsrn+0fiaN5DBwAAKsWI99ABAADg2hB0AAAAhiPoAAAADEfQAQAAGI6gAwAAMBxBBwAAYDiCDgAAwHAEHQAAgOEIOgAAAMMRdAAAAIYj6AAAAAxH0AEAABiOoAMAADAcQQcAAGA4gg4AAMBwBB0AAIDhCDoAAADDEXQAAACGI+gAAAAMR9ABAAAYjqADAAAwHEEHAABgOIIOAADAcAQdAACA4Qg6AAAAwxF0AAAAhiPoAAAADEfQAQAAGI6gAwAAMBxBBwAAYDiCDgAAwHAEHQAAgOEIOgAAAMMRdAAAAIYj6AAAAAxH0AEAABiOoAMAADAcQQcAAGA4gg4AAMBwBB0AAIDhCDoAAADDEXQAAACGI+gAAAAMR9ABAAAYjqADAAAwHEEHAABgOIIOAADAcAQdAACA4Qg6AAAAwxF0AAAAhiPoAAAADEfQAQAAGI6gAwAAMBxBBwAAYDiCDgAAwHAEHQAAgOEIOgAAAMMRdAAAAIYj6AAAAAxH0AEAABiOoAMAADAcQQcAAGA4X0+fMCEhQampqTp+/LhSUlLUvn17ZWdna9q0afrxxx9ls9l08803Ky4uTo0aNZIkhYaGqn379rJaL/VnYmKiQkNDJUlpaWlKTEyU3W5Xx44dNXfuXNWpU8fTLwsAAMBrPH6Frm/fvlq1apVCQkJc2ywWiyZMmKDU1FSlpKSoZcuWSkpKKnbcmjVrlJycrOTkZFfMnT17Vs8884wWL16sbdu2qV69elq6dKlHXw8AAIC3eTzowsPDFRwcXGxbQECAevbs6fq5S5cuSk9PL3euf/7zn+rUqZNat24tSRo1apS2bNni1vUCAABUdx6/5Voeh8Oh1atXKyoqqtj2sWPHym63q3fv3po4caJsNpsyMjLUvHlz15jmzZsrIyPD00sGAADwqmoXdM8995zq1q2rMWPGuLbt2LFDwcHBys/P19SpU7Vw4UJNmjTJbecMCqrvtrkqqkmTBh4/JwAAuDFVq6BLSEjQ0aNHtXjxYtcHICS5btHWr19fI0aM0PLly13bd+3a5RqXnp5e4nZuRWRl5cvhcJY7zp0Rlpl5xm1zAQCAG5/Vain1IlS1eWzJCy+8oP3792vhwoWy2Wyu7bm5ubpw4YIkqaioSKmpqQoLC5MkRUZG6ptvvtGRI0ckXfrgxO9+9zuPrx0AAMCbPH6Fbs6cOdq6datOnTql8ePHKyAgQC+++KJee+01tW7dWqNGjZIktWjRQgsXLtR///tfzZ49WxaLRUVFReratauefPJJSZeu2MXFxenhhx+Ww+FQWFiYZs6c6emXBAAA4FUWp9NZ/r3GG1xlbrlGT1tV5fP9I3E0t1wBAEClGHHLFQAAANeGoAMAADAcQQcAAGA4gg4AAMBwBB0AAIDhCDoAAADDEXQAAACGI+gAAAAMR9ABAAAYjqADAAAwHEEHAABgOIIOAADAcAQdAACA4Qg6AAAAwxF0AAAAhiPoAAAADEfQAQAAGI6gAwAAMBxBBwAAYDiCDgAAwHAEHQAAgOEIOgAAAMMRdAAAAIYj6AAAAAxH0AEAABiOoAMAADAcQQcAAGA4gg4AAMBwBB0AAIDhCDoAAADDEXQAAACGI+gAAAAMR9ABAAAYjqADAAAwHEEHAABgOIIOAADAcAQdAACA4Qg6AAAAwxF0AAAAhiPoAAAADEfQAQAAGI6gAwAAMBxBBwAAYDiCDgAAwHAEHQAAgOEIOgAAAMMRdAAAAIYj6AAAAAxH0AEAABiOoAMAADAcQQcAAGA4gg4AAMBwBB0AAIDhCDoAAADDEXQAAACGI+gAAAAMR9ABAAAYrsygi4mJ0eHDhz21FgAAAFyDMoNu9+7dOnv2rKfWAgAAgGvALVcAAADDEXQAAACG8y1vwOOPPy6bzVahybZv317lBQEAAKByyg26nj17qkmTJp5YCwAAAK5BuUEXExOj2267zS0nS0hIUGpqqo4fP66UlBS1b99ekvTDDz9o+vTpysnJUUBAgBISEtS6desq7QMAAKgpPPoeur59+2rVqlUKCQkptj02NlbR0dFKTU1VdHS0Zs+eXeV9AAAANYVHgy48PFzBwcHFtmVlZengwYMaOHCgJGngwIE6ePCgTp8+fc37AAAAapIyb7k+8cQTatas2XVdQEZGhpo1ayYfHx9Jko+Pj5o2baqMjAw5nc5r2teoUaNKrSEoqL57X1QFNGnSwOPnBAAAN6Zyg64myMrKl8PhLHecOyMsM/OM2+YC4Fn+Df3kV8FP/5eloLBQebkFblgRgJrAarWUehGqzKDr0KGDLBZLhU5isVh08ODBSi8uODhYJ06ckN1ul4+Pj+x2u06ePKng4GA5nc5r2gcA15OfzaZxy5+s8jxvjH9JEkEHoOrKDLpZs2aVGXROp1Pbtm3Trl27rnkBQUFBCgsL08aNGzV48GBt3LhRYWFhrtum17oPAACgprA4nc7y7zX+D6fTqc2bN2vx4sX6/vvv1bt3bz366KPq2rVrmcfNmTNHW7du1alTpxQYGKiAgABt2rRJhw8f1vTp05WXlyd/f38lJCSoTZs2knTN+yqjMrdco6etqvT8/+sfiaO55QoYrEmTBm67QsfvAgAVVdYt10oFnd1u14YNG/T666/rp59+Ur9+/fTII4/o1ltvddtivYGgA1AZBB0Ab7jm99BdVlhYqHfeeUdLly7ViRMndNddd2nRokVq27atWxcKAACAyisz6M6fP6/Vq1dr+fLlysnJ0ZAhQ/TQQw+pZcuWnlofAAAAylFm0PXp00e5ubmKiIjQhAkTFBwcrIKCAv2f//N/rjq+Xbt212WRAAAAKF2ZQZeTkyNJ2rVrl3bv3l3qOKfTKYvFom+//datiwMAAED5ygy6FStWeGodAAAAuEZlBl1ERISn1gEAAIBrZPX2AgAAAFA11/zVXz4+PmrUqJF69OihBx98UB06dLguCwQAAEDZrvmrv+x2uzIzM7Vjxw6NHDlSb731ljp37nxdFgkAAIDSlRl0Y8aMKXeCyZMna/z48XrppZe0ZMkSty0MAAAAFVPl99BZLBaNGjVK+/btc8NyAAAAUFlu+VBEgwYNVFhY6I6pAAAAUEluCbrdu3erVatW7pgKAAAAlVTud7mWxm6369SpU9q+fbuWLVumqVOnun1xAAAAKF+ZQde1a9dSP+V6Wa1atTRu3DjFxMS4dWEAAAComDKD7vnnny/3OXS33Xab/P39r8viAAAAUL4yg27o0KGeWgcAAACuUZlBd6X09HR9+eWXOnHihCSpWbNmCg8PV3Bw8HVbHAAAAMpXbtBlZmbqL3/5i9LS0uRwOIrts1qt6tevn5555hk1adLkui0SAAAApSsz6LKzsxUdHa28vDw99thj6tevn0JCQiRJx48f1/bt27Vy5UqNGTNGb7/9tgICAjyxZgAAAFyhzKBbtGiRioqK9P7776tZs2bF9nXo0EEdOnTQiBEjNGrUKL366quaMWPGdV0sAAAASirzwcLbt2/Xo48+WiLmrtS0aVM9/PDD2rZtm9sXBwAAgPKVGXSZmZlq06ZNuZO0bdtWmZmZblsUAAAAKq7MoAsMDNSxY8fKneTYsWMKDAx026IAAABQcWUGXa9evbR06VKdO3eu1DHnzp3T0qVL1bt3b7cvDgAAAOUrM+gmTpyoU6dOaejQoXr//fd19uxZ176zZ88qJSVFw4YNU1ZWlp544onrvlgAAACUVOanXIODg7VixQpNnTpV06ZNk8VicX3NV15enpxOp8LCwrRgwQLddNNNHlkwAAAAiiv3wcK33HKLNmzYoN27d2vPnj3FvimiR48e6tGjx3VfJAAAAEpXZtCdPHlSzz33nO677z5FRkYqIiKixJiPP/5Ya9eu1bPPPqugoKDrtlAAAABcXZnvoVu2bJl++ukn9erVq9QxvXr10rFjx7Rs2TK3Lw4AAADlKzPoPvroI40aNUoWi6XUMRaLRSNHjtT27dvdvjgAAACUr8ygS09PV7t27cqdpG3btjp+/LjbFgUAAICKKzPoateurfz8/HInOXfunGrXru22RQEAAKDiygy6W2+9VWlpaeVOsn37dt16661uWxQAAAAqrsygi46O1rvvvqv169eXOmbDhg167733NGbMGLcvDgAAAOUr87El/fv3V0xMjGbMmKG33npLkZGRat68uSwWi9LT0/XJJ59o//79GjdunH7zm994as0AAAC4QrkPFp4+fboiIiL05ptvatmyZSosLJQk2Ww2devWTYsWLVKfPn2u+0IBAABwdeUGnSRFRUUpKipKRUVFysnJkSQFBATI17dChwMAAOA6qlSR+fr6qnHjxtdrLQAAALgGZX4oAgAAANUfQQcAAGA4gg4AAMBwBB0AAIDhCDoAAADDEXQAAACGI+gAAAAMR9ABAAAYjqADAAAwHEEHAABgOIIOAADAcAQdAACA4Qg6AAAAwxF0AAAAhiPoAAAADEfQAQAAGI6gAwAAMBxBBwAAYDiCDgAAwHAEHQAAgOEIOgAAAMMRdAAAAIYj6AAAAAxH0AEAABjO19sLuOzYsWN6/PHHXT+fOXNG+fn52r17t6KiomSz2eTn5ydJmjJliiIjIyVJ+/bt0+zZs1VQUKCQkBDNmzdPQUFBXnkNAAAA3lBtgq5FixZKTk52/RwfHy+73e76ecGCBWrfvn2xYxwOh6ZOnaq5c+cqPDxcixYtUlJSkubOneuxdQMAAHhbtbzlWlhYqJSUFA0bNqzMcfv375efn5/Cw8MlSaNGjdIHH3zgiSUCAABUG9XmCt2V0tLS1KxZM3Xs2NG1bcqUKXI6nerevbsmT54sf39/ZWRkqHnz5q4xjRo1ksPhUE5OjgICAip8vqCg+u5cfoU0adLA4+cEUP3wuwCAO1TLoFu3bl2xq3OrVq1ScHCwCgsLFR8fr7i4OCUlJbntfFlZ+XI4nOWOc+cv3szMM26bC4Bn8bsAgDdYrZZSL0JVu1uuJ06c0BdffKFBgwa5tgUHB0uSbDaboqOjtXfvXtf29PR017jTp0/LarVW6uocAACA6apd0K1fv1533nmnAgMDJUnnzp3TmTOX/gvW6XRq8+bNCgsLkyR16tRJFy5c0J49eyRJa9as0YABA7yzcAAAAC+pdrdc169fr5kzZ7p+zsrK0sSJE2W32+VwONS2bVvFxsZKkqxWqxITExUbG1vssSUAAAA1SbULutTU1GI/t2zZUhs2bCh1fLdu3ZSSknKdVwUAAFB9VbtbrgAAAKgcgg4AAMBwBB0AAIDhCDoAAADDEXQAAACGI+gAAAAMR9ABAAAYjqADAAAwHEEHAABgOIIOAADAcAQdAACA4Qg6AAAAwxF0AAAAhiPoAAAADEfQAQAAGI6gAwAAMBxBBwAAYDiCDgAAwHAEHQAAgOEIOgAAAMMRdAAAAIYj6AAAAAxH0AEAABiOoAMAADAcQQcAAGA4gg4AAMBwBB0AAIDhCDoAAADDEXQAAACGI+gAAAAMR9ABAAAYjqADAAAwHEEHAABgOIIOAADAcAQdAACA4Qg6AAAAwxF0AAAAhiPoAAAADEfQAQAAGI6gAwAAMBxBBwAAYDiCDgAAwHAEHQAAgOEIOgAAAMMRdAAAAIYj6AAAAAxH0AEAABiOoAMAADAcQQcAAGA4gg4AAMBwBB0AAIDhCDoAAADDEXQAAACGI+gAAAAMR9ABAAAYjqADAAAwHEEHAABgOIIOAADAcAQdAACA4Qg6AAAAwxF0AAAAhiPoAAAADOfr7QVcKSoqSjabTX5+fpKkKVOmKDIyUvv27dPs2bNVUFCgkJAQzZs3T0FBQZJU5j4AAICaoNpdoVuwYIGSk5OVnJysyMhIORwOTZ06VbNnz1ZqaqrCw8OVlJQkSWXuAwAAqCmqXdD9r/3798vPz0/h4eGSpFGjRumDDz4odx8AAEBNUa1uuUqXbrM6nU51795dkydPVkZGhpo3b+7a36hRIzkcDuXk5JS5LyAgwAurBwAA8LxqFXSrVq1ScHCwCgsLFR8fr7i4OP3mN7+57ucNCqp/3c/xv5o0aeDxcwKofvhdAMAdqlXQBQcHS5JsNpuio6P16KOPKiYmRunp6a4xp0+fltVqVUBAgIKDg0vdVxlZWflyOJzljnPnL97MzDNumwuAZ/G7AIA3WK2WUi9CVZv30J07d05nzlz6xeZ0OrV582aFhYWpU6dOunDhgvbs2SNJWrNmjQYMGCBJZe4DAACoKarNFbqsrCxNnDhRdrtdDodDbdu2VWxsrKxWqxITExUbG1vs0SSSytwHAABQU1SboGvZsqU2bNhw1X3dunVTSkpKpfcBAADUBNXmlisAAACuDUEHAABgOIIOAADAcAQdAACA4Qg6AAAAwxF0AAAAhiPoAAAADEfQAQAAGI6gAwAAMBxBBwAAYDiCDgAAwHAEHQAAgOEIOgAAAMMRdAAAAIYj6AAAAAxH0AEAABiOoAMAADAcQQcAAGA4gg4AAMBwBB0AAIDhCDoAAADDEXQAAACGI+gAAAAMR9ABAAAYjqADAAAwHEEHAABgOIIOAADAcAQdAACA4Qg6AAAAwxF0AAAAhiPoAAAADEfQAQAAGM7X2wsATBLY0CZfm1+V5ykqLFB2bqEbVgQAAEEHVIqvzU9fJk6o8jzdpy2RRNABANyDW64AAACGI+gAAAAMR9ABAAAYjqADAAAwHEEHAABgOIIOAADAcAQdAACA4Qg6AAAAwxF0AAAAhiPoAAAADEfQAQAAGI6gAwAAMBxBBwAAYDiCDgAAwHAEHQAAgOEIOgAAAMMRdAAAAIYj6AAAAAxH0AEAABiOoAMAADCcr7cXAAAAYKKG/nVk86t6ShUWFCk373yV5iDoAAAAroHNz1fPz3y3yvM8HT+8ynNwyxUAAMBwBB0AAIDhCDoAAADDEXQAAACGI+gAAAAMR9ABAAAYjqADAAAwXLV5Dl12dramTZumH3/8UTabTTfffLPi4uLUqFEjhYaGqn379rJaL/VnYmKiQkNDJUlpaWlKTEyU3W5Xx44dNXfuXNWpU8ebLwUAAMCjqs0VOovFogkTJig1NVUpKSlq2bKlkpKSXPvXrFmj5ORkJScnu2Lu7NmzeuaZZ7R48WJt27ZN9erV09KlS731EgAAALyi2gRdQECAevbs6fq5S5cuSk9PL/OYf/7zn+rUqZNat24tSRo1apS2bNlyPZcJAABQ7VSbW65XcjgcWr16taKiolzbxo4dK7vdrt69e2vixImy2WzKyMhQ8+bNXWOaN2+ujIwMbywZAADAa6pl0D333HOqW7euxowZI0nasWOHgoODlZ+fr6lTp2rhwoWaNGmS284XFFTfbXNVVJMmDTx+TlQv/BuAxL8DAJdU9XdBtQu6hIQEHT16VIsXL3Z9CCI4OFiSVL9+fY0YMULLly93bd+1a5fr2PT0dNfYysjKypfD4Sx3nDt/8WZmnnHbXPAc/g1A4t8BgEs8/bvAarWUehGq2ryHTpJeeOEF7d+/XwsXLpTNZpMk5ebm6sKFC5KkoqIipaamKiwsTJIUGRmpb775RkeOHJF06YMTv/vd77yydgAAAG+pNlfovv/+e7322mtq3bq1Ro0aJUlq0aKFJkyYoNmzZ8tisaioqEhdu3bVk08+KenSFbu4uDg9/PDDcjgcCgsL08yZM735MgAAADyu2gTdLbfcou++++6q+1JSUko9rl+/furXr9/1WhYAAEC1V61uuQIAAKDyCDoAAADDEXQAAACGI+gAAAAMR9ABAAAYjqADAAAwHEEHAABgOIIOAADAcAQdAACA4Qg6AAAAwxF0AAAAhqs23+UKAIApAhrYVKu2X5XnuXihQDlnCt2wItR0BB0AAJVUq7afNseMr/I8d61YLhF0cANuuQIAABiOoAMAADAcQQcAAGA4gg4AAMBwBB0AAIDhCDoAAADDEXQAAACGI+gAAAAMR9ABAAAYjqADAAAwHEEHAABgOIIOAADAcAQdAACA4Qg6AAAAwxF0AAAAhiPoAAAADEfQAQAAGI6gAwAAMBxBBwAAYDiCDgAAwHAEHQAAgOEIOgAAAMMRdAAAAIYj6AAAAAxH0AEAABiOoAMAADAcQQcAAGA4gg4AAMBwBB0AAIDhCDoAAADDEXQAAACGI+gAAAAMR9ABAAAYjqADAAAwHEEHAABgOIIOAADAcAQdAACA4Qg6AAAAwxF0AAAAhiPoAAAADEfQAQAAGI6gAwAAMBxBBwAAYDiCDgAAwHAEHQAAgOEIOgAAAMMRdAAAAIYj6AAAAAxH0AEAABiOoAMAADDcDRF0P/zwg0aOHKn+/ftr5MiROnLkiLeXBAAA4DE3RNDFxsYqOjpaqampio6O1uzZs729JAAAAI/x9fYCqiorK0sHDx7U8uXLJUkDBw7Uc889p9OnT6tRo0YVmsNqtVT4fI0D613TOqtyTlQvNv8gt8zDvwGzNa5fsd8v5eHfgbnqNOZ3AaSGAXXdMk9F/h2UNcbidDqdblmJl+zfv19//vOftWnTJte2u+66S/PmzVPHjh29uDIAAADPuCFuuQIAANRkxgddcHCwTpw4IbvdLkmy2+06efKkgoODvbwyAAAAzzA+6IKCghQWFqaNGzdKkjZu3KiwsLAKv38OAADAdMa/h06SDh8+rOnTpysvL0/+/v5KSEhQmzZtvL0sAAAAj7ghgg4AAKAmM/6WKwAAQE1H0AEAABiOoAMAADAcQQcAAGA4gu4G9cMPP2jkyJHq37+/Ro4cqSNHjnh7SaighIQERUVFKTQ0VIcOHfL2clAJ2dnZevDBB9W/f38NGjRITzzxhE6fPu3tZaESHnvsMd1zzz0aMmSIoqOj9e2333p7SaikV155pUb+/iToblCxsbGKjo5WamqqoqOjNXv2bG8vCRXUt29frVq1SiEhId5eCirJYrFowoQJSk1NVUpKilq2bKmkpCRvLwuVkJCQoPfff18bNmzQ/fffr6efftrbS0IlHDhwQPv27auRvz8JuhtQVlaWDh48qIEDB0qSBg4cqIMHD3KlwBDh4eF804mhAgIC1LNnT9fPXbp0UXp6uhdXhMpq0KCB63/n5+fLYin/C9NRPRQWFiouLk7PPvust5fiFb7eXgDcLyMjQ82aNZOPj48kycfHR02bNlVGRgbfoAF4iMPh0OrVqxUVFeXtpaCSZs6cqU8//VROp1NLlizx9nJQQS+99JLuuecetWjRwttL8Qqu0AHAdfDcc8+pbt26GjNmjLeXgkqKj4/Xjh07NGnSJCUmJnp7OaiAr776Svv371d0dLS3l+I1BN0NKDg4WCdOnJDdbpck2e12nTx5ktt4gIckJCTo6NGjevHFF2W18mvWVEOGDNGuXbuUnZ3t7aWgHF988YUOHz6svn37KioqSj///LMeeOABffLJJ95emsfwm+YGFBQUpLCwMG3cuFGStHHjRoWFhXG7FfCAF154Qfv379fChQtls9m8vRxUwtmzZ5WRkeH6OS0tTQ0bNlRAQID3FoUKeeihh/TJJ58oLS1NaWlpuummm7R06VL16tXL20vzGL7L9QZ1+PBhTZ8+XXl5efL391dCQoLatGnj7WWhAubMmaOtW7fq1KlTCgwMVEBAgDZt2uTtZaECvv/+ew0cOFCtW7dW7dq1JUktWrTQwoULvbwyVMSpU6f02GOP6fz587JarWrYsKH+/Oc/q2PHjt5eGiopKipKixcvVvv27b29FI8h6AAAAAzHLVcAAADDEXQAAACGI+gAAAAMR9ABAAAYjqADAAAwHEEHwDgvv/yyQkNDFRoaqg4dOqhHjx4aNmyY5s+fr8zMzGJjQ0ND9dZbb5WY49y5c+rSpYtuv/125efnX/U8DodD69atU3R0tMLDw9WpUydFRUVp2rRp+uqrr0qcJzQ0tMT2Q4cOKTQ0VLt27Spx/pdffln9+/dX586d9Ytf/EJ//OMfdejQoRLrOH36tOLi4tS3b1917txZvXr10gMPPKAPP/zQNea9995TaGiozp4969p2/PhxTZ06Vb/+9a/VuXNn3XnnnXr00Uf1xRdflPI3C8BUfJcrACM1aNDA9T2bZ86c0cGDB7V69Wq9/fbbWrJkiTp16lTm8WlpaTp//rwk6cMPP9SQIUOK7Xc4HHrqqaf00UcfaeTIkXrwwQdVr149HTlyROvXr9eoUaN08OBB13cmX/bqq6/q9ddfL/PcZ8+eVUxMjH766Sc99NBD6ty5s7KysrRy5UqNGDFCr732mn7xi19Iki5evKg//OEPOn/+vB555BG1atVKP//8sz799FP961//Ur9+/a56jtzcXI0cOVJNmjTR5MmT1bRpUx0/flxpaWn66quv1KNHjzLXCMAsBB0AI/n4+KhLly6unyMjI/X73/9eo0eP1uTJk7Vly5YSsXWljRs3qmXLlnI6ndq0aVOJoFu5cqW2bdumZcuW6Y477nBtj4iI0H333ad33nmnxJwRERHauXOnvv32W4WFhZV67hdffFHfffed1q1bp9DQUNf23/zmN4qJidGUKVP04Ycfqnbt2tq9e7cOHTqkd955R7fddptr7ODBg1XWY0RTU1N16tQpJScnKygoyLV92LBhZR4HwEzccgVww/D399fUqVN19OhRffrpp6WOy83N1SeffKK77rpLd999tz777DOdPn262Jg333xTv/3tb4vF3JVGjBhRIhh/+9vfql27dnr11VdLPff58+f17rvvatCgQcViTpJq1aqlSZMmKTMzUx988IEkKS8vT5LUpEmTEnNZLJZSz5OXl6datWqpYcOGlToOgJkIOgA3lJ49e8rX11f//ve/Sx2zdetWXbx40RV0RUVFSk1Nde3PyMjQ8ePHK/09kBaLRQ8//LC2bt2qw4cPX3XMgQMHdO7cuVJvlUZERMjf39/1PrewsDBZrVY9/fTT2rNnj4qKiiq0lo4dO6qwsFDTpk3T/v375XA4KvVaAJiFoANwQ/Hz81NgYKBOnTpV6piNGzeqbdu26tChg0JDQ3XLLbcU+77ckydPSpJuuummYsc5HA4VFRW5/lzt1uXdd9+tli1bavHixVc994kTJyRJISEhpa6vefPmrnGtW7fWtGnT9MUXX2j06NHq1q2bHnjgAW3ZsqXU4yXpjjvu0Lhx47R582YNGzZM4eHhmjhxoj777LMyjwNgJoIOwA2nrPeInTx5Urt379Zdd93l2nbXXXdpz549+vnnn4uN/d9bk3PmzFHHjh1df3bs2FFifh8fHz300EPatGmTfvrpp6q9kP9n/Pjx2r59u2bPnq0+ffro66+/1lNPPaW//e1vZR43Y8YMpaamatq0aYqIiNDHH3+s+++/X6tXr3bLugBUHwQdgBtKQUGBcnJy1Lhx46vu37JlixwOh3r37q28vDzl5eWpd+/ecjqd2rx5sySpadOmklQi8CZMmKB33323zPfISZc+sNC0adOrftq1WbNmki49UqQ06enprnFXHjd69Gi99NJL2rlzpyIjI7V06VJlZ2eXuZabb75ZDzzwgBYvXqy0tDSFhYVp/vz5fDACuMEQdABuKJ9//rmKioqKfQL2SpdvrY4YMUI9evRwPcNOunQrVpKCg4MVEhJS4oMVzZs3V+fOndW+ffsy12Cz2fTAAw9o/fr1JaKwY8eOqlu3rtLS0q567J49e5SXl1fmY0Xq1q2r6Oho2e12/fjjj2Wu5UqNGjXS0KFDlZubq6ysrAofB6D6I+gA3DDy8vKUlJSkm2++Wb/85S9L7P/pp5/073//W+PGjdOKFSuK/ZkwYYIOHDigI0eOSJL+8Ic/KDU1tcQDgSvqvvvuU8OGDV3PyrusTp06Gj58uJKTk0s8RLioqEgvvviimjZtqgEDBkiScnJyZLfbS8x/9OhRSSr2SJIr/e+ndq88zmazqUGDBpV+TQCqL55DB8BIdrtd+/btk3TpQb0HDhzQ6tWrdf78eS1ZsuSqz6DbtGmTrFar7r///hK3NNu1a6c33nhDGzdu1BNPPKGxY8dqz549evDBBzVy5Ej96le/Ur169ZSVleX6RGzdunVLXZ+fn5/GjRunpKSkEvueeuop7d27V2PHji3xYOEDBw7otddeU+3atSVduuL4wgsvaOjQoercubOsVqv27t2rv//97+rTp49atGhx1fOvX79eKSkpGjJkiEJDQ1VUVKTPPvtM//jHP/T73/9efn5+Ffp7BmAGgg6Akc6cOaORI0fKYrGofv36atWqle655x6NGTPmqs9sky4F3R133FEi5qRLV7p++ctfatOmTXriiSdktVr10ksv6b333tO6deu0bt06FRYWqmnTpurevbvWrFmjrl27lrnG6OhoLVmyRDk5OcW216tXTytXrtSSJUu0du1azZ8/X/Xr11dERITWrl1b7Pl0t99+u/r27astW7ZoyZIlstvtatGihR599FHFxMSUeu4777xTx44d09q1a5WRkSEfHx+1atVKs2bN0n333VfmugGYx+LknbEAAABG4z10AAAAhiPoAAAADEfQAQAAGI6gAwAAMBxBBwAAYDiCDgAAwHAEHQAAgOEIOgAAAMMRdAAAAIb7v9MBGTMygdkFAAAAAElFTkSuQmCC\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# 5. 定義模型方法<a class=\"anchor\" id=\"5\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"def build_optimizers(model):\n    if OPTIMIZERS_TYPE == None:\n        print(\"Custiom OPTIMIZERS\")\n    elif OPTIMIZERS_TYPE == \"SGD\":\n        RETURN_OPTIMIZERS = optim.SGD(model.parameters(), \n                                       lr = LEARNING_RATE, momentum = MOMENTUM, \n                                      dampening = DAMPENING, weight_decay = WEIGHT_DECAY, \n                                      nesterov = NESTEROV)\n    elif OPTIMIZERS_TYPE == \"Adam\":\n        RETURN_OPTIMIZERS = optim.Adam(model.parameters(), \n                                       lr = LEARNING_RATE, betas = BETAS, eps = EPS, \n                                       weight_decay = WEIGHT_DECAY)\n    elif OPTIMIZERS_TYPE == \"Adamax\":\n        RETURN_OPTIMIZERS = optim.Adamax(model.parameters(), \n                                         lr = LEARNING_RATE, betas = BETAS, eps = EPS, \n                                         weight_decay = WEIGHT_DECAY)\n    elif OPTIMIZERS_TYPE == \"RMSprop\":\n        RETURN_OPTIMIZERS = optim.RMSprop(model.parameters(), \n                                          lr = LEARNING_RATE, alpha = ALPHA, eps = EPS, \n                                          weight_decay = WEIGHT_DECAY, momentum = MOMENTUM, \n                                          centered = CENTERED)\n    elif OPTIMIZERS_TYPE == \"Adagrad\":\n        RETURN_OPTIMIZERS = optim.Adagrad(model.parameters(), \n                                          lr = LEARNING_RATE, lr_decay = LR_DECAY, \n                                          weight_decay = WEIGHT_DECAY)\n    return RETURN_OPTIMIZERS","metadata":{"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# reference: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/173733\nclass MyCrossEntropyLoss(_WeightedLoss):\n    def __init__(self, weight=None, reduction='mean'):\n        super().__init__(weight=weight, reduction=reduction)\n        self.weight = weight\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        lsm = F.log_softmax(inputs, -1)\n\n        if self.weight is not None:\n            lsm = lsm * self.weight.unsqueeze(0)\n\n        loss = -(targets * lsm).sum(-1)\n\n        if  self.reduction == 'sum':\n            loss = loss.sum()\n        elif  self.reduction == 'mean':\n            loss = loss.mean()\n\n        return loss\n    \ndef build_losses():\n    if BASE_LOSSES == None:\n        RETURN_LOSSES = MyCrossEntropyLoss(reduction = REDUCTION).to(DEVICE)\n        print(\"Custiom LOSSES\")\n    else:\n        RETURN_LOSSES = BASE_LOSSES(reduction = REDUCTION).to(DEVICE)\n    return RETURN_LOSSES","metadata":{"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class build_default_model(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        if USE_BASE_TIMM_MODEL:\n            self.model = timm.create_model(BASE_MODEL, pretrained = LOAD_BASE_WEIGHTS)\n        else:\n            self.model = BASE_MODEL(pretrained = LOAD_BASE_WEIGHTS)\n\n        if not BASE_MODEL_TRAINABLE:\n            for param in model.parameters():\n                param.requires_grad = False\n\n        if INCLUDE_TOP:\n            # Alternatively, it can be generalized to nn.Linear(num_ftrs, CLASSES)\n            if USE_BASE_TIMM_MODEL:\n                n_features = self.model.classifier.in_features\n                self.model.classifier = nn.Linear(n_features, CLASSES)\n            else:\n                n_features = self.model.fc.in_features\n                self.model.fc = nn.Linear(n_features, CLASSES)\n        else:\n            if USE_BASE_TIMM_MODEL:\n                self.model.classifier = nn.Sequential(\n                    nn.Dropout(DROPOUT),\n                    nn.Linear(n_features, CLASSES, bias = BIAS)\n                )\n            else:\n                self.model.fc = nn.Sequential(\n                    nn.Dropout(DROPOUT),\n                    nn.Linear(n_features, CLASSES, bias = BIAS)\n                )\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","metadata":{"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class build_custiom_model(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","metadata":{"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# 6. 定義回調函數方法 <a class=\"anchor\" id=\"6\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"def get_callbacks(optimizer):\n    if CALLBACKS_STEPLR:\n        # 等間隔調整學習率，調整倍數為gamma倍，調整間隔為step_size。間隔單位是step。需要注意的是，step通常是指epoch，不要弄成iteration了。\n        callbacks_scheduler = lr_scheduler.StepLR(optimizer, step_size = STEP_SIZE, gamma = GAMMA)\n    elif CALLBACKS_REDUCELRONPLATEAU:\n        # 當某指標不再變化（下降或升高），調整學習率，這是非常實用的學習率調整策略。例如，當驗證集的loss不再下降時，進行學習率調整；\n        # 或者監測驗證集的accuracy，當accuracy不再上升時，則調整學習率。\n        callbacks_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,  mode = MODE, factor = FACTOR, patience = PATIENCE, \n                                                   threshold = THRESHOLD, threshold_mode = THRESHOLD_MODE, cooldown = COOLDOWN, \n                                                   min_lr = MIN_LR, eps = SCHEDULER_EPS, verbose = SCHEDULER_VERBOSE)\n    elif CALLBACKS_COSINEANNEALINGWARMRESTAERS:\n        # 使用餘弦退火時間表設置每個參數組的學習率\n        callbacks_scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = T_0, T_mult = T_MULT, eta_min = ETA_MIN, \n                                                             verbose = SCHEDULER_VERBOSE)\n    else:\n        callbacks_scheduler = None \n    return callbacks_scheduler","metadata":{"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# 7. 製作資料集＆資料擴增&訓練模型 <a class=\"anchor\" id=\"7\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, df, one_hot_label = False, transforms = None):\n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.one_hot_label = one_hot_label\n        self.transforms = transforms\n        self.labels = self.df[LABEL_NAME].values\n        \n        if one_hot_label is True:\n            self.labels = np.eye(self.df[LABEL_NAME].max()+1)[self.labels]\n            #print(self.labels)\n        \n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, index: int):\n        label = self.labels[index]\n        image_name = self.df[IMAGE_NAME].values[index]\n        if IMAGE_NAME_HAVE_EXTENSION:\n            image_path = TRAIN_DATA_PATH + image_name\n        else:\n            image_path = TRAIN_DATA_PATH + image_name + IMAGE_NAME_EXTENSION\n        image = cv2.imread(image_path)\n        \n        if COLOR_CONVERT_RGB:\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transforms is not None:\n            image = self.transforms(image = image)['image']\n            \n        return image, label","metadata":{"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# 確定是否將應用此增強。機率為 p = 1.0 意味著我們總是從上面應用轉換。\n# p = 0 將意味著將忽略轉換塊。\n# 0 < p < 1.0 等於每個擴增都具有以一定概率應用的選項。\n# OneOf 隨機選取一種增強擴增\n\ndef get_train_transforms():\n    return A.Compose([\n        A.Blur(blur_limit = BLUR_LIMIT, \n               p = P_BLUR), # 模糊\n        A.HorizontalFlip(p = P_HORIZONTALFLIP), # 水平翻轉\n        A.VerticalFlip(p = P_VERTICALFLIP), # 垂直翻轉\n        A.Flip(p = P_FLIP), # 水平和垂直翻轉\n        A.Resize(height = RESIZE_HEIGHT, \n                 width = RESIZE_WIDTH, \n                 p = P_RESIZE), # 縮放\n        A.RandomResizedCrop(height = RANDOMRESIZEDCROP_HEIGHT, \n                            width = RANDOMRESIZEDCROP_WIDTH, \n                            scale = RANDOMRESIZEDCROP_SCALE, \n                            p = P_RANDOMRESIZEDCROP), #隨機縮放剪裁\n        A.RandomRotate90(p = P_RANDOMROTATE90), # 隨機旋轉90度\n        A.ShiftScaleRotate(shift_limit = SHIFTSCALEROTATE_SHIFT_LIMIT, \n                           scale_limit = SHIFTSCALEROTATE_SCALE_LIMIT, \n                           rotate_limit = SHIFTSCALEROTATE_ROTATE_LIMIT, \n                           p = P_SHIFTSCALEROTATE), # 平移縮放旋轉\n        A.ElasticTransform(alpha = ELATICTRANSFORM_ALPHA, \n                           sigma = ELATICTRANSFORM_SIGMA, \n                           alpha_affine = ELATICTRANSFORM_ALPHA_AFFINE, \n                           p = P_ELATICTRANSFORM), # 彈性變換\n        A.GridDistortion(num_steps = GRIDDISTORTION_NUM_STEPS, \n                         p = P_GRIDDISTORTION), # 網格失真\n        A.RandomBrightnessContrast(brightness_limit = RANDOMBRIGHTNESSCONTRAST_BRIGHTNESS_LIMIT, \n                                   contrast_limit = RANDOMBRIGHTNESSCONTRAST_CONTRAST_LIMIT, \n                                   p = P_RANDOMBRIGHTNESSCONTRAST_CONTRAST), # 隨機亮度對比度\n        A.HueSaturationValue(hue_shift_limit = HUESATURATIONVALUE_HUE_SHIFT_LIMIT, \n                             sat_shift_limit = HUESATURATIONVALUE_SAT_SHIFT_LIMIT, \n                             val_shift_limit = HUESATURATIONVALUE_VAL_SHIFT_LIMIT, \n                             p = P_HUESATURATIONVALUE), # 隨機色調飽和度值\n        A.CLAHE(clip_limit = CLAHE_CLIP_LIMIT, \n                p = P_CLAHE), # 將對比度受限的自適應直方圖均衡化應用於輸入圖像\n        A.Cutout(num_holes = COARSEDROPOUT_NUM_HOLES, \n                        max_h_size = COARSEDROPOUT_MAX_H_SIZE, \n                        max_w_size = COARSEDROPOUT_MAX_W_SIZE, \n                        p = P_COARSEDROPOUT), # 隨機在圖像上生成黑色矩形\n        A.Normalize(\n             mean = NORMALIZE_MEAN, \n             std = NORMALIZE_STD, \n            max_pixel_value = NORMALIZE_MAX_PIXEL_VALUE, \n            p = P_NORMALIZE), # 正規化。\n        ToTensorV2(p = P_TOTENSORV2) # 歸一化\n    ], p = P_TRAIN_TRANSFORMS)\n\ndef get_val_transforms():\n    return A.Compose([\n        A.Resize(height = RESIZE_HEIGHT, \n                 width = RESIZE_WIDTH, \n                 p = P_RESIZE), # 縮放\n        A.Normalize(\n             mean = NORMALIZE_MEAN,\n             std = NORMALIZE_STD, \n            max_pixel_value = NORMALIZE_MAX_PIXEL_VALUE, \n            p = P_NORMALIZE), # 正規化。\n        ToTensorV2(p = P_TOTENSORV2) # 歸一化\n    ], p = P_VAL_TRANSFORMS)","metadata":{"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def prepare_dataloader(fold, df, train_index, valid_index):\n    \n    if LOAD_CSV:\n        if FOLD >1:\n            train_data = df.loc[train_index,:]\n            validation_data = df.loc[valid_index,:]\n        else:\n            X_train, X_val, Y_train, Y_val = train_test_split(train_csv[IMAGE_NAME], \n                                                              train_csv[LABEL_NAME], \n                                                              test_size = DATA_SPLIT, \n                                                              random_state = SEED)\n            train_data = pd.DataFrame(X_train)\n            train_data.columns = [IMAGE_NAME]\n            train_data[LABEL_NAME] = Y_train\n\n            validation_data = pd.DataFrame(X_val)\n            validation_data.columns = [IMAGE_NAME]\n            validation_data[LABEL_NAME] = Y_val\n        \n    train_set = MyDataset(train_data, transforms = get_train_transforms())\n    val_set = MyDataset(validation_data, transforms = get_val_transforms())\n    \n    #for metrics\n    dataset_sizes = { 'train': len(train_set), 'val': len(val_set)}\n    print(dataset_sizes)\n    \n    train_loader = DataLoader(train_set, batch_size = BATCH_SIZE[fold], pin_memory = PIN_MEMORY, \n                                               shuffle = True, num_workers = NUM_WORKERS, drop_last = DROP_LAST)\n    \n    val_loader = DataLoader(val_set, batch_size = BATCH_SIZE[fold], pin_memory = PIN_MEMORY, \n                                               shuffle = False, num_workers = NUM_WORKERS)\n    \n    return train_loader, val_loader","metadata":{"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(epoch, model, scaler, train_loss, optimizer, train_loader, \n                    scheduler = None, scheduler_batch_update = False):\n    # 設定模型為訓練模式\n    model.train()\n\n#     running_loss = None\n\n    # 遍歷enumaretad批處理\n    pbar = tqdm(enumerate(train_loader), total=len(train_loader), \n                position = TQDM_POSITION, leave = TQDM_LEAVE)\n    for batch_idx, (inputs, labels) in pbar:      \n        # 提取輸入和標籤\n        inputs = inputs.to(DEVICE).float()\n        labels = labels.to(DEVICE).long()\n\n        # 前向過程(model + loss)開啟 autocast\n        with autocast():\n            outputs = model(inputs)\n            loss = train_loss(outputs, labels)\n            \n        # 歸一化損失以說明批次累積\n        loss = loss / ACCUM_ITER \n            \n        # Scales loss. 為了梯度放大\n        # 反向傳播在autocast上下文之外\n        scaler.scale(loss).backward()\n\n#         if running_loss is None:\n#             running_loss = loss.item()\n#         else:\n#             running_loss = running_loss * .99 + loss.item() * .01\n\n        # 權重更新\n        if ((batch_idx + 1) %  ACCUM_ITER == 0) or ((batch_idx + 1) == len(train_loader)):\n\n            # scaler.step() 首先把梯度的值unscale回來.\n            # 如果梯度的值不是 infs 或者 NaNs, 那麼調用optimizer.step()來更新權重,\n            # 否則，忽略step調用，從而保證權重不更新（不被破壞）\n            scaler.step(optimizer)\n            \n            # 準備著，看是否要增大scaler\n            scaler.update()\n            \n            optimizer.zero_grad() \n\n#             description = f'epoch {epoch} loss: {running_loss:.4f}'  \n#             pbar.set_description(description)\n            \n            if scheduler is not None and scheduler_batch_update:\n                scheduler.step()\n                \n    if scheduler is not None and not scheduler_batch_update:\n        scheduler.step()\n        \ndef valid_one_epoch(epoch, model, val_loss, val_loader, \n                    scheduler = None, scheduler_loss_update = False):\n    # 設定模型為評估模式\n    model.eval()\n\n#     loss_sum = 0\n#     sample_num = 0\n#     image_preds_all = []\n#     image_targets_all = []\n    \n    # 遍歷enumaretad批處理\n    pbar = tqdm(enumerate(val_loader), total=len(val_loader), \n                position = TQDM_POSITION, leave = TQDM_LEAVE)\n    for batch_idx, (inputs, labels) in pbar:\n        # 提取輸入和標籤\n        inputs = inputs.to(DEVICE).float()\n        labels = labels.to(DEVICE).long()\n        \n        outputs = model(inputs)\n        \n        outputs_all += [torch.argmax(outputs, 1).detach().cpu().numpy()]\n        labels_all += [labels.detach().cpu().numpy()]\n        \n        loss = val_loss(outputs, labels)\n        \n#         loss_sum += loss.item()*labels.shape[0]\n#         sample_num += labels.shape[0]\n\n#         description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n#         pbar.set_description(description)\n    \n    outputs_all = np.concatenate(outputs_all)\n    labels_all = np.concatenate(labels_all)\n    print('validation multi-class accuracy = {:.4f}'.format((outputs_all == labels_all).mean()))\n    \n    if scheduler is not None and VAL_ENABLE_SCHEDULER:\n        if scheduler_loss_update:\n            scheduler.step(loss_sum/sample_num)\n        else:\n            scheduler.step()","metadata":{"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#save the losses and metrics for further visualization\nlosses = {'train':[], 'val':[]}\nmetrics = {'train':[], 'val':[]}\n\n# 宣告為訓練後混淆矩陣預測用\nall_labels = []; all_pred = []","metadata":{"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def train_process(fold, skf, train_index, valid_index):\n    if skf:\n        print('FOLD %i - IMAGE SIZE %i WITH %s AND BATCH_SIZE %i'%(fold+1,IMAGE_SIZE[fold],MODEL_NAME.upper(),BATCH_SIZE[fold]))\n    else:\n        print('IMAGE SIZE %i WITH %s AND BATCH_SIZE %i'%(IMAGE_SIZE[fold],MODEL_NAME.upper(),BATCH_SIZE[fold]))\n        \n    if LOAD_CSV and skf:\n        # (String)訓練模型FOLD>1的儲存路徑\n        SAVE_MODEL_PATH = PROJECT_PATH+r'/models/'+MODEL_NAME+'_fold_%i.pt'%(fold+1)\n    else:\n        SAVE_MODEL_PATH = TRAIN_MODEL_PATH\n    \n    train_loader, val_loader = prepare_dataloader(fold, train_csv, train_index, valid_index)\n    \n    # 載入模型或權重\n    if LOAD_MODEL:\n        # load model\n        model = torch.load(LOAD_MODEL_PATH)\n    elif USE_BASE_MODEL:\n        # 創建model，默認是torch.FloatTensor\n        model = build_default_model()\n    else:\n        # ==== INIT CUSTIOM MODEL\n        model = build_custiom_model()\n        if LOAD_WEIGHTS:\n            # load model weights\n            model.load_state_dict(LOAD_WEIGHTS_PATH)\n\n    model.to(DEVICE)\n    optimizer = build_optimizers(model)\n    \n    # 在訓練最開始之前實例化一個GradScaler對象\n    scaler = GradScaler()\n    \n    scheduler = get_callbacks(optimizer) # 回調函式\n\n    train_loss = build_losses() # train loss\n    val_loss = build_losses() # val loss\n\n    if MODEL_PRINT:\n        # Print model's state_dict\n        print(\"Model's state_dict:\")\n        for param_tensor in model.state_dict():\n            print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n\n    if OPTIMIZER_PRINT:\n        # Print optimizer's state_dict\n        print(\"Optimizer's state_dict:\")\n        for var_name in optimizer.state_dict():\n            print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n               \n    for epoch in range(EPOCHS[fold]):\n        train_one_epoch(epoch, model, scaler, train_loss, optimizer, train_loader, scheduler = scheduler, \n                        scheduler_batch_update = SCHEDULER_BATCH_UPDATE)\n\n        with torch.no_grad():\n            valid_one_epoch(epoch, model, val_loss, val_loader, scheduler = scheduler, \n                            scheduler_loss_update = SCHEDULER_LOSS_UPDATE)\n\n#         torch.save(model.state_dict(),'{}_fold_{}_{}'.format(CFG['model_arch'], fold, epoch))\n            \n            \n            \n            \n            \n            \n            \n            \n    \n    \n#     val_acc = None\n#     val_loss = None\n#     val_auc = None\n#     early_stopping = 0\n    \n#     for epoch in range(EPOCHS):\n#         print('Epoch: {}/{}'.format(epoch, EPOCHS - 1))\n#         print('-' * 10)\n        \n#         # Each epoch has a training and validation phase\n#         for phase in ['train', 'val']:\n#             if phase == 'train':\n#                 model.train() # Set model to training mode\n#             else:\n#                 model.eval() # Set model to evaluate mode\n                \n#             running_loss = 0.0\n#             running_corrects = 0.0\n            \n#             # 宣告為計算每次迭代auc\n#             valid_preds, valid_targets = [], []\n                \n#             # Iterate over data.\n#             pbar = tqdm(loaders[phase], total = len(loaders[phase]), position = TQDM_POSITION, leave = TQDM_LEAVE)\n#             for idx, data in enumerate(pbar):\n#                 # get the inputs; data is a list of [inputs, labels]\n#                 inputs, labels = data[0].to(DEVICE), data[1].to(DEVICE).long()\n                \n#                 # zero the parameter gradients\n#                 optimizer.zero_grad()\n                \n#                 # forward\n#                 # track history if only in train\n#                 with torch.set_grad_enabled(phase=='train'):\n#                     outputs = model(inputs)\n#                     _, pred = torch.max(outputs, 1)\n#                     loss = criterion(outputs, labels)\n\n#                     # backward + optimize only if in training phase\n#                     if phase == 'train':\n#                         loss.backward()\n#                         optimizer.step()\n#                     else:\n#                         valid_preds.append(torch.softmax(outputs,1)[:,1].detach().cpu().numpy())\n#                         valid_targets.append(labels.detach().cpu().numpy())\n                   \n#                 # statistics\n#                 running_loss += loss.item()*inputs.size(0)\n#                 running_corrects += torch.sum(pred == labels.data)\n            \n#             epoch_loss = running_loss / dataset_sizes[phase]\n#             epoch_acc = running_corrects.double()/dataset_sizes[phase]\n#             losses[phase].append(epoch_loss)\n#             accuracies[phase].append(epoch_acc)\n            \n#             # 為了計算每次迭代auc\n#             valid_preds = np.concatenate(valid_preds)\n#             valid_targets = np.concatenate(valid_targets)\n#             epoch_auc =  roc_auc_score(valid_targets, valid_preds)\n            \n#             # 為了計算全部迭代混淆矩陣\n#             all_pred = np.concatenate(valid_preds)\n#             all_labels = np.concatenate(valid_targets)\n            \n# #             print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n            \n#             if phase == 'val':\n                \n#                 if CALLBACKS_CHECK_POINTER:\n#                     save_model = False\n#                     if SAVE_BEST_ONLY:\n#                         if epoch_acc > val_acc and MONITOR == \"val_acc\":\n#                             val_acc = epoch_acc\n#                             save_model = True\n#                         elif epoch_loss < val_loss and MONITOR == \"val_loss\":\n#                             val_loss = epoch_loss\n#                             save_model = True\n#                         elif epoch_auc > val_auc and MONITOR == \"val_auc\":\n#                             val_auc = epoch_auc\n#                             save_model = True\n#                     else:\n#                         if MONITOR == \"val_acc\":\n#                             val_acc = epoch_acc\n#                         elif MONITOR == \"val_loss\":\n#                             val_loss = epoch_loss\n#                         elif MONITOR == \"val_auc\":\n#                             val_auc = epoch_auc\n#                         save_model = True\n                        \n#                     if SAVE_WEIGHTS_ONLY and save_model:\n#                         torch.save(model.state_dict(), SAVE_MODEL_PATH)\n#                     elif not SAVE_WEIGHTS_ONLY and save_model:\n#                         torch.save(model, SAVE_MODEL_PATH)\n                \n# #         scheduler.step()\n    \n#     if SAVE_BEST_ONLY:\n#         if MONITOR == \"val_acc\":\n#             print('Best val Acc: {:4f}'.format(val_acc))\n#         elif MONITOR == \"val_loss\":\n#             print('Best val Loss: {:4f}'.format(val_loss))\n#         elif MONITOR == \"val_auc\":\n#             print('Best val AUC: {:4f}'.format(val_auc))\n            \n#     del train_loader, val_loader\n#     if LOAD_CSV and skf:\n#         del model\n#     torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# def train_process(fold, skf, train_index, valid_index):\n#     if skf:\n#         print('FOLD %i - IMAGE SIZE %i WITH %s AND BATCH_SIZE %i'%(fold+1,IMAGE_SIZE[fold],MODEL_NAME.upper(),BATCH_SIZE[fold]))\n#     else:\n#         print('IMAGE SIZE %i WITH %s AND BATCH_SIZE %i'%(IMAGE_SIZE[fold],MODEL_NAME.upper(),BATCH_SIZE[fold]))\n    \n#     loaders = prepare_dataloader(train_csv, train_index, valid_index)\n    \n#     val_acc = 0.0\n#     val_loss = 0.0\n#     val_auc = 0.0\n#     early_stopping = 0\n    \n#     if LOAD_CSV and skf:\n#         # (String)訓練模型FOLD>1的儲存路徑\n#         SAVE_MODEL_PATH = PROJECT_PATH+r'/models/'+MODEL_NAME+'_fold_%i.pt'%(fold+1)\n#     else:\n#         SAVE_MODEL_PATH = TRAIN_MODEL_PATH\n    \n#     since = time.time()\n#     for epoch in range(EPOCHS):  \n#         print('Epoch: {}/{}'.format(epoch, EPOCHS - 1))\n#         print('-' * 10)\n        \n#         # Each epoch has a training and validation phase\n#         for phase in ['train', 'val']:\n#             if phase == 'train':\n#                 model.train() # Set model to training mode\n#             else:\n#                 model.eval() # Set model to evaluate mode\n                \n#             running_loss = 0.0\n#             running_corrects = 0.0\n            \n#             # 宣告為計算每次迭代auc\n#             valid_preds, valid_targets = [], []\n                \n#             # Iterate over data.\n#             pbar = tqdm(loaders[phase], total = len(loaders[phase]), position = TQDM_POSITION, leave = TQDM_LEAVE)\n#             for idx, data in enumerate(pbar):\n#                 # get the inputs; data is a list of [inputs, labels]\n#                 inputs, labels = data[0].to(DEVICE), data[1].to(DEVICE).long()\n                \n#                 # zero the parameter gradients\n#                 optimizer.zero_grad()\n                \n#                 # forward\n#                 # track history if only in train\n#                 with torch.set_grad_enabled(phase=='train'):\n#                     outputs = model(inputs)\n#                     _, pred = torch.max(outp, 1)\n#                     loss = criterion(outputs, labels)\n\n#                     # backward + optimize only if in training phase\n#                     if phase == 'train':\n#                         loss.backward()\n#                         optimizer.step()\n#                     else:\n#                         valid_preds.append(torch.softmax(outputs,1)[:,1].detach().cpu().numpy())\n#                         valid_targets.append(labels.detach().cpu().numpy())\n                   \n#                 # statistics\n#                 running_loss += loss.item()*inputs.size(0)\n#                 running_corrects += torch.sum(pred == labels.data)\n            \n#             epoch_loss = running_loss / dataset_sizes[phase]\n#             epoch_acc = running_corrects.double()/dataset_sizes[phase]\n#             losses[phase].append(epoch_loss)\n#             accuracies[phase].append(epoch_acc)\n            \n#             # 為了計算每次迭代auc\n#             valid_preds = np.concatenate(valid_preds)\n#             valid_targets = np.concatenate(valid_targets)\n#             epoch_auc =  roc_auc_score(valid_targets, valid_preds)\n            \n#             # 為了計算全部迭代混淆矩陣\n#             all_pred = np.concatenate(valid_preds)\n#             all_labels = np.concatenate(valid_targets)\n            \n#             print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n            \n#             if phase == 'val':\n#                 print('Time: {}m {}s'.format((time.time()- since)//60, (time.time()- since)%60))\n                \n#                 if CALLBACKS_CHECK_POINTER:\n#                     save_model = False\n#                     if SAVE_BEST_ONLY:\n#                         if epoch_acc > val_acc and MONITOR == \"val_acc\":\n#                             val_acc = epoch_acc\n#                             save_model = True\n#                         elif epoch_loss < val_loss and MONITOR == \"val_loss\":\n#                             val_loss = epoch_loss\n#                             save_model = True\n#                         elif epoch_auc > val_auc and MONITOR == \"val_auc\":\n#                             val_auc = epoch_auc\n#                             save_model = True\n#                     else:\n#                         if MONITOR == \"val_acc\":\n#                             val_acc = epoch_acc\n#                         elif MONITOR == \"val_loss\":\n#                             val_loss = epoch_loss\n#                         elif MONITOR == \"val_auc\":\n#                             val_auc = epoch_auc\n#                         save_model = True\n                        \n#                     if SAVE_WEIGHTS_ONLY and save_model:\n#                         torch.save(model.state_dict(), SAVE_MODEL_PATH)\n#                     elif not SAVE_WEIGHTS_ONLY and save_model:\n#                         torch.save(model, SAVE_MODEL_PATH)\n                \n# #         scheduler.step()\n#     time_elapsed = time.time() - since\n#     print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    \n#     if SAVE_BEST_ONLY:\n#         if MONITOR == \"val_acc\":\n#             print('Best val Acc: {:4f}'.format(val_acc))\n#         elif MONITOR == \"val_loss\":\n#             print('Best val Loss: {:4f}'.format(val_loss))\n#         elif MONITOR == \"val_auc\":\n#             print('Best val AUC: {:4f}'.format(val_auc))\n            \n#     del loaders\n#     if LOAD_CSV and skf:\n#         del model\n#     torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    try:\n        since = time.time()\n        \n        if FOLD > 1:\n            for fold,(train_index, valid_index) in enumerate(SKF.split(np.arange(train_csv.shape[0]), train_csv[LABEL_NAME])):\n                train_process(fold = fold, skf = True, train_index = train_index, valid_index = valid_index)\n        else:\n            train_process(fold = 0, skf = False, train_index = None, valid_index = None)\n            \n        time_elapsed = time.time() - since\n        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))  \n    except Exception as exception:\n        print(exception)\n        raise","metadata":{"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"IMAGE SIZE 224 WITH EFFICIENTNETB7 AND BATCH_SIZE 256\n{'train': 2929, 'val': 733}\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 2/12 [01:01<05:07, 30.78s/it]","output_type":"stream"}]},{"cell_type":"markdown","source":"# 8. 混淆矩陣<a class=\"anchor\" id=\"8\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"markdown","source":"# 9. 待辦事項<a class=\"anchor\" id=\"9\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"markdown","source":"改訓練\n1. 回調函數(提早停止，tensroboard)\n2. 列印訓練過程\n3. 混淆矩陣\n4. focal loss\n5. 製作資料集(無csv訓練)\n6. 訓練(無csv訓練)\n\nhttps://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n\n7. 做成config控制","metadata":{}}]}