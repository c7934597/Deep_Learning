{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Image_Classification_Pytorch (Training)"],"metadata":{}},{"cell_type":"markdown","source":["<a class=\"anchor\" id=\"0\"></a>\n","# Table of Contents\n","\n","1. [套件安裝與載入](#1)\n","1. [環境檢測與設定](#2)\n","1. [開發參數設定](#3)\n","1. [資料處理](#4)\n","    -  [載入CSV檔](#4.1)\n","    -  [檢查CSV檔缺失值](#4.2)\n","1. [定義模型方法](#5)\n","1. [定義回調函數方法](#6)\n","1. [製作資料集＆資料擴增回調函數＆訓練模型](#7)\n","1. [混淆矩陣 & Quadratic Weighted Kappa](#8)\n","1. [待辦事項](#9)"],"metadata":{}},{"cell_type":"markdown","source":["# 1. 套件安裝與載入<a class=\"anchor\" id=\"1\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}},{"cell_type":"code","source":["!pip3 install git+https://github.com/rwightman/pytorch-image-models.git\n","# !pip3 install iterative-stratification"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 資料處理套件\n","import os\n","import gc\n","import cv2\n","import sys\n","import time\n","import timm\n","import copy\n","import random\n","import datetime\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import albumentations as A\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from tqdm import tqdm\n","from albumentations.pytorch.transforms import ToTensorV2\n","# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.metrics import (roc_auc_score, confusion_matrix, accuracy_score, \n","                             precision_score, recall_score, f1_score, classification_report, cohen_kappa_score)\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 設定顯示中文字體\n","from matplotlib.font_manager import FontProperties\n","plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei'] # 用來正常顯示中文標籤\n","plt.rcParams['font.family'] = 'AR PL UMing CN'\n","plt.rcParams['axes.unicode_minus'] = False # 用來正常顯示負號"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pytorch深度學習模組套件\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as data\n","import torch.nn.functional as F\n","import torchvision\n","\n","from torch.optim import lr_scheduler\n","from torch.cuda.amp import autocast, GradScaler\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from torchvision import models"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. 環境檢測與設定<a class=\"anchor\" id=\"2\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}},{"cell_type":"code","source":["DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","DEVICE"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 查看pytorch版本\n","print(torch.__version__)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''執行環境參數設定'''\n","\n","# (Boolean)是否為本機\n","LOCAL = False\n","\n","# (Boolean)是否為 Colab\n","COLAB = False\n","\n","\n","'''檔案路徑參數設定'''\n","\n","# (String)Root路徑\n","if LOCAL:\n","    PATH = r'../'\n","    OUTPUT_PATH = PATH\n","elif COLAB:\n","    PATH = r'/content/drive/My Drive/Colab Notebooks/'\n","    OUTPUT_PATH = PATH\n","else:\n","    PATH = r'../input/'\n","    OUTPUT_PATH = r'/kaggle/working/'\n","    \n","# (String)資料根路徑\n","DATA_ROOT_PATH = PATH+r'resized-2015-2019-diabetic-retinopathy-detection/' \n","\n","# (String)訓練資料路徑\n","TRAIN_DATA_PATH = DATA_ROOT_PATH+r'resized_traintest15_train19/'\n","\n","# (String)訓練CSV路徑\n","TRAIN_CSV_PATH = DATA_ROOT_PATH+r'labels/traintestLabels15_trainLabels19.csv'\n","\n","# (String)專案名稱\n","PROJECT_NAME = 'aptos2019-blindness-detection'\n","\n","# (String)模型/權重名稱\n","MODEL_NAME = 'efficientnet_v2_b0'\n","\n","# (String)讀取預訓練模型/權重的路徑\n","LOAD_MODEL_PATH = PATH+r'/models/pretrain_models/'+MODEL_NAME+'.pth'\n","\n","# (Boolean)是否建立訓練模型儲存的資料夾\n","MODEL_TIME_FOLDER = False\n","if MODEL_TIME_FOLDER:\n","    # (String)專案檔案儲存路徑\n","    PROJECT_PATH = OUTPUT_PATH+PROJECT_NAME+'/'+PROJECT_NAME+' '+datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n","    # (String)訓練模型的儲存路徑\n","    TRAIN_MODEL_PATH = PROJECT_PATH+r'/models/'+MODEL_NAME+'.pth'\n","else:\n","    # (String)訓練模型的儲存路徑\n","    TRAIN_MODEL_PATH = MODEL_NAME+'.pth'\n","\n","# (Boolean)是否要匯入Library\n","IMPORT_PYTORCH_LIBRARY = False\n","\n","# (String)Library的路徑\n","PYTORCH_LIBRARY_PATH = PATH + \"PyTorch_Library/\""],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if DEVICE != torch.device(\"cpu\"):\n","    !nvidia-smi"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if DEVICE != torch.device(\"cpu\"):\n","    !nvcc --version"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if not LOCAL and COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    \n","if MODEL_TIME_FOLDER:\n","    if not os.path.isdir(PROJECT_PATH+r'/models/'):\n","        os.makedirs(PROJECT_PATH+r'/models/')\n","    \n","if IMPORT_PYTORCH_LIBRARY:\n","    sys.path.append(PYTORCH_LIBRARY_PATH + \"Custom_Loss.py\")\n","    sys.path.append(PYTORCH_LIBRARY_PATH + \"Custom_Model.py\")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. 開發參數設定<a class=\"anchor\" id=\"3\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}},{"cell_type":"code","source":["'''客製參數設定'''\n","\n","\n","'''資料參數設定'''\n","\n","# (Int)分類數量\n","CLASSES = 5\n","\n","# (Int)有CSV檔該參數才有用，1則為不做交叉驗證\n","FOLD = 1\n","    \n","# (Int)圖片尺寸\n","IMAGE_SIZE = [224]*FOLD\n","\n","# (String)圖片副檔名\n","IMAGE_NAME_EXTENSION = '.jpg'\n","\n","# (String)CSV圖片檔名欄位\n","IMAGE_NAME = 'image'\n","\n","# (String)CSV標籤欄位\n","LABEL_NAME = 'level'\n","\n","# (String)CSV標籤欄位類型\n","LABEL_NAME_TYPE = 'string'\n","\n","# (Boolean)CSV圖片檔名欄位是否包含副檔名\n","IMAGE_NAME_HAVE_EXTENSION = False\n","\n","# (Boolean)是否轉DataSet時，讓標籤做獨熱編碼\n","ONE_HOT_LABEL = False\n","\n","#  (Boolean)圖像轉為RGB\n","COLOR_CONVERT_RGB = True\n","\n","# (Int)不同的種子會產生不同的Random或分層K-FOLD分裂, 42則是預設固定種子\n","SEED = 42\n","\n","if FOLD == 1:\n","    # (Float)驗證集佔訓練集的比率，FOLD>1則不啟用\n","    DATA_SPLIT = 0.2\n","else:\n","    # (String)切分訓練集跟驗證集方式 StratifiedKFold, MultilabelStratifiedKFold\n","    KF = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=SEED)\n","\n","# (Boolean)是否資料轉Tensor時啟動鎖頁內存(GPU內存)，而不鎖頁內存就是會使用到硬碟虛擬內存\n","PIN_MEMORY = False\n","\n","# (Int)要用於數據加載的子進程數。0表示將在主進程中加載數據。（默認值：0）\n","NUM_WORKERS = 0\n","\n","# (Boolean)批次處理在大小不合適的情況下，是否刪除最後一個不完整的批次\n","DROP_LAST = False\n","    \n","# (Boolean)如為True每次返回的卷積算法將是確定的，即默認算法\n","CUDNN_DETERMINISTIC = True\n","\n","# (Boolean)PyTorch 中對模型裡的卷積層進行預先的優化，也就是在每一個卷積層中測試 cuDNN 提供的所有卷積實現算法，\n","# 然後選擇最快的那個。這樣在模型啟動的時候，只要額外多花一點點預處理時間，就可以較大幅度地減少訓練時間\n","CUDNN_BENCHMARK = True\n","\n","\n","'''資料擴增參數設定\n","\n","資料擴增教學\n","https://zhuanlan.zhihu.com/p/107399127\n","\n","資料擴增Doc\n","https://vfdev-5-albumentations.readthedocs.io/en/docs_pytorch_fix/api/augmentations.html\n","'''\n","\n","# (Float)訓練集資料擴增的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_TRAIN_TRANSFORMS = 1.0\n","\n","# (Float)驗證集資料擴增的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_VAL_TRANSFORMS = 1.0\n","\n","# 以下資料擴增為訓練集使用=============================================\n","\n","# (Float)模糊的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_BLUR = 0\n","\n","# (Int)模糊的上限\n","BLUR_LIMIT = 3\n","\n","# (Float)水平翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_HORIZONTALFLIP = 0\n","\n","# (Float)垂直翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_VERTICALFLIP = 0\n","\n","# (Float)水平和垂直翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_FLIP = 0\n","\n","# (Float)隨機旋轉90度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_RANDOMROTATE90 = 0\n","\n","# (Float)平移縮放旋轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_SHIFTSCALEROTATE = 0\n","\n","# (Float)平移縮放旋轉的平移上限\n","SHIFTSCALEROTATE_SHIFT_LIMIT = 0.0625\n","\n","# (Float)平移縮放旋轉的縮放上限\n","SHIFTSCALEROTATE_SCALE_LIMIT = 0.1\n","\n","# (Float)平移縮放旋轉的旋轉上限\n","SHIFTSCALEROTATE_ROTATE_LIMIT = 45\n","\n","# (Float)彈性變換的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_ELATICTRANSFORM = 0\n","\n","# (Float)彈性變換的alpha高斯過濾參數\n","ELATICTRANSFORM_ALPHA = 1\n","\n","# (Float)彈性變換的sigma高斯過濾參數\n","ELATICTRANSFORM_SIGMA = 50\n","\n","# (Float)彈性變換的alpha_affine，範圍為（-alpha_affine，alpha_affine）\n","ELATICTRANSFORM_ALPHA_AFFINE = 50\n","\n","# (Float)網格失真的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_GRIDDISTORTION = 0\n","\n","# (Int)網格失真的每一條邊上網格單元數量\n","GRIDDISTORTION_NUM_STEPS = 5\n","\n","# (Float)隨機亮度對比度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_RANDOMBRIGHTNESSCONTRAST_CONTRAST = 0\n","\n","# (Float)隨機亮度的上限\n","RANDOMBRIGHTNESSCONTRAST_BRIGHTNESS_LIMIT = 0.2\n","\n","# (Float)隨機對比度的上限\n","RANDOMBRIGHTNESSCONTRAST_CONTRAST_LIMIT = 0.2\n","\n","# (Float)隨機色調飽和度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_HUESATURATIONVALUE = 0\n","\n","# (Float)隨機色調飽和度的色調上限\n","HUESATURATIONVALUE_HUE_SHIFT_LIMIT = 20\n","\n","# (Float)隨機色調飽和度的飽和度上限\n","HUESATURATIONVALUE_SAT_SHIFT_LIMIT = 30\n","\n","# (Float)隨機色調飽和度的值上限\n","HUESATURATIONVALUE_VAL_SHIFT_LIMIT = 20\n","\n","# (Float)對比度受限自適應直方圖均衡的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_CLAHE = 0\n","\n","# (Float)對比度受限自適應直方圖均衡的對比度上限\n","CLAHE_CLIP_LIMIT = 4.0\n","\n","# (Float)隨機在圖像上生成黑色矩形的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_COARSEDROPOUT = 0\n","\n","# (Int)隨機在圖像上生成黑色矩形的數量\n","COARSEDROPOUT_NUM_HOLES = 8\n","\n","# (Int)隨機在圖像上生成黑色矩形的最大高度\n","COARSEDROPOUT_MAX_H_SIZE = 8\n","\n","# (Int)隨機在圖像上生成黑色矩形的最大寬度\n","COARSEDROPOUT_MAX_W_SIZE = 8\n","\n","# (Float)隨機縮放剪裁的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_RANDOMRESIZEDCROP = 0\n","\n","# (Float Tuple)隨機縮放剪裁之前的圖像比例縮放\n","RANDOMRESIZEDCROP_SCALE = (0.08, 1.0)\n","\n","# (Int List)隨機縮放剪裁之前的圖像高度\n","RANDOMRESIZEDCROP_HEIGHT = IMAGE_SIZE\n","\n","# (Int List)隨機縮放剪裁之前的圖像寬度\n","RANDOMRESIZEDCROP_WIDTH = IMAGE_SIZE\n","\n","# 以上資料擴增為訓練集使用=============================================\n","\n","# 以下資料擴增為訓練集和驗證集共用======================================\n","\n","# (Float)縮放的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_RESIZE = 1.0\n","\n","# (Int List)縮放後的圖片高度\n","RESIZE_HEIGHT = IMAGE_SIZE\n","\n","# (Int List)縮放後的圖片寬度\n","RESIZE_WIDTH = IMAGE_SIZE\n","\n","# (Float)正規化的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_NORMALIZE = 1.0\n","\n","# (Float List)正規化的平均值([0,1]的參考平均值:[0.485, 0.456, 0.406], [-1,1]的參考平均值:[0.5, 0.5, 0.5])\n","NORMALIZE_MEAN = [0.485, 0.456, 0.406]\n","\n","# (Float List)正規化的標準差([0,1]的參考標準差[0.229, 0.224, 0.225], [-1,1]的參考標準差[0.5, 0.5, 0.5])\n","NORMALIZE_STD = [0.229, 0.224, 0.225]\n","\n","# (Float)正規化的PIXEL最大值(參考PIXEL最大值255.0)\n","NORMALIZE_MAX_PIXEL_VALUE = 255.0\n","\n","# (Float)歸一化的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","# ToTensorV2()將[0, 255]的PIL.Image或[H, W, C]的numpy.ndarray數據，\n","# 轉換為形狀[C, H, W]的torch.FloadTensor，並歸一化。\n","P_TOTENSORV2 = 1.0\n","\n","# 以上資料擴增為訓練集和驗證集共用======================================\n","\n","\n","''''模型參數設定'''\n","\n","# (Boolean)是否依照設定路徑，載入完整客製(模型+權重)\n","LOAD_MODEL = False\n","\n","# (Model)使用客制模型，None則使用基本模型\n","CUSTOM_MODEL = None\n","if CUSTOM_MODEL is None:\n","    # (Boolean)使用timm模型，如為False則使用基礎Pytorch模型\n","    TIMM_MODEL = True\n","    if TIMM_MODEL:\n","        # https://github.com/rwightman/pytorch-image-models#getting-started-documentation\n","        # (Model)建立timm模型\n","        BASE_MODEL = \"tf_efficientnetv2_b0\"\n","    else:\n","        # (Model)建立Pytorch模型\n","        BASE_MODEL = models.resnet18\n","\n","# (Boolean)是否載入權重，否則重訓\n","LOAD_WEIGHTS = False\n","    \n","# (Boolean)模型是否增加TOP層\n","INCULDE_TOP = True\n","\n","# (Boolean)模型是否使用分類層輸出，否則為全連接層\n","CLASSIFIER_OUTPUT = True\n","\n","# (Float)Dropout比率\n","DROPOUT = 0.5\n","\n","# (Boolean)Bias偏移量\n","BIAS = True\n","\n","# (Boolean)是否印出完整模型\n","MODEL_PRINT = False\n","\n","\n","''''回調函數參數設定\n","\n","學習率遞減\n","https://zhuanlan.zhihu.com/p/69411064\n","\n","回調函數Doc\n","https://pytorch.org/docs/stable/optim.html\n","\n","'''\n","\n","# (Boolean)回調函數 ModelCheckpoint 是否啟用\n","CALLBACKS_CHECK_POINTER = False\n","\n","# (Boolean)回調函數 EarlyStopping 是否啟用\n","CALLBACKS_EARLY_STOPPING = False\n","\n","# (Boolean)回調函數 StepLR 是否啟用\n","CALLBACKS_STEPLR = True\n","\n","# (Boolean)回調函數 ReduceLROnPlateau 是否啟用\n","CALLBACKS_REDUCELRONPLATEAU = False\n","\n","# (Boolean)回調函數 CosineAnnealingWarmRestarts 是否啟用\n","CALLBACKS_COSINEANNEALINGWARMRESTAERS = False\n","\n","# (Boolean)回調函數 TensorBoard 是否啟用(訓練epoch step指標計算有啟用才有用)\n","CALLBACKS_TENSOR_BOARD = False\n","\n","# (String)回調函數監控數值(val_auc 僅限雙分類) val_acc/val_loss/val_auc\n","MONITOR = 'val_loss'\n","\n","# (Boolean)回調函數 ModelCheckpoint 是否只儲存最佳 False\n","SAVE_BEST_ONLY = True\n","\n","# (Boolean)回調函數 ModelCheckpoint 是否只儲存權重 True\n","SAVE_WEIGHTS_ONLY = True\n","\n","# (Int)回調函數 EarlyStopping 沒有改善的時期數，之後訓練將停止 10\n","PATIENCE_ELS = 5\n","\n","# (Int)學習率衰減的時間段，意思每過多少epoch會衰減\n","STEP_SIZE = 5\n","\n","# (Float)學習率衰減的乘數 0.1\n","GAMMA = 0.1\n","\n","# (String)最小，最大之一 在最小模式下，當監視的數量停止減少時，lr將減小； 在最大模式下，當監視的數量停止增加時，它將減少。 min\n","MODE = \"min\"\n","\n","# (Float)學習率降低的因數。new_lr = lr *因子 0.1\n","FACTOR = 0.1\n","\n","# (Int)沒有改善的時期數，此後學習率將降低。例如，如果 耐心= 2，那麼我們將忽略前兩個時期而沒有任何改善，\n","# 並且如果損失仍然沒有改善，則只會在第三個時期之後降低LR。 10\n","PATIENCE = 10 \n","\n","# (Float)用於測量新的最佳閾值，僅關注重大變化。 1e-4\n","THRESHOLD = 1e-4 \n","\n","# (String)rel，abs之一。在rel模式下，“ max”模式下的dynamic_threshold = best *（1 +閾值），在min模式下，\n","# dynamic_threshold = best *（1-threshold）。在絕對模式下，dynamic_threshold =最佳+ 最大模式下的閾值或最佳-最小模式下的閾值。 rel\n","THRESHOLD_MODE = \"rel\"\n","\n","# (Int)減少lr後恢復正常運行之前要等待的時期數。 0 \n","COOLDOWN = 0\n","\n","# (Float/List)標量或標量列表。所有參數組或每個組的學習率的下限。 0 \n","MIN_LR = 0\n","\n","# (Float)應用於lr的最小衰減。如果新舊lr之間的差異小於eps，則忽略該更新。 1e-8\n","SCHEDULER_EPS = 1e-8\n","\n","# (Int)第一次重啟的迭代次數。\n","T_0 = 15\n","\n","# (Int)重新啟動後，因素增加。 1 \n","T_MULT = 1\n","\n","# (Int)最低學習率。 0\n","ETA_MIN = 0\n","\n","# (Boolean)每次更新，學習率回調函式都會向輸出印出一條消息。 False\n","SCHEDULER_VERBOSE = False\n","\n","# (Boolean)訓練集每批就更新學習率回調函式，否則每時代就更新。 False\n","SCHEDULER_BATCH_UPDATE = False\n","\n","# (Boolean)驗證集學習率回調函式是否啟用。 False\n","VAL_ENABLE_SCHEDULER = False\n","\n","# (Boolean)驗證集通過計算LOSS就更新學習率回調函式，否則不計算就更新。 False\n","SCHEDULER_LOSS_UPDATE = False\n","\n","# (String)TensorBoard儲存檔案的註解\n","TENSOR_BOARD_COMMENT = PROJECT_NAME\n","\n","\n","''''編譯參數設定\n","\n","編譯參數Doc\n","https://pytorch.org/docs/stable/optim.html\n","\n","'''\n","\n","# (String)優化器指定(SGD/Adam/Adamax/RMSprop/Adagrad)\n","OPTIMIZERS_TYPE = \"Adam\"\n","\n","# (Float)優化器學習率 1e-3/1e-1\n","LEARNING_RATE = 1e-3\n","\n","# (Float)學習速率衰減 0\n","LR_DECAY = 0\n","\n","# (Float)優化器權重衰減 5e-5/5e-4\n","WEIGHT_DECAY = 5e-5\n","\n","# (Float)加速優化器在相關方向上前進，並抑制震盪 0.9\n","MOMENTUM = None\n","\n","# (Tuple Float)用於計算梯度及其平方的移動平均值的係數 (0.9, 0.999)\n","BETAS = (0.9, 0.999)\n","\n","# (Float)分母中添加的項，以提高數值穩定性 1e-8\n","EPS = 1e-8\n","\n","# (Float)平滑常數 0.99\n","ALPHA = 0.99\n","\n","# (Boolean)計算居中RMSProp，則通過估計其方差來對梯度進行歸一化 True\n","CENTERED = True\n","\n","# (Float)阻尼動量 0\n","DAMPENING = 0\n","\n","# (Boolean)啟用Nesterov動量 False\n","NESTEROV = False\n","\n","# (Boolean)客制損失函數\n","CUSTOM_LOSSES = nn.CrossEntropyLoss()\n","\n","# (Boolean)是否要重塑標籤張量\n","VIEW_LABEL_TENSOR = False\n","if VIEW_LABEL_TENSOR:\n","    # # (Int)計算損失函數的標籤VIEW_A 1\n","    LOSS_LABEL_VIEW_A = 1\n","\n","    # # (Int)計算損失函數的標籤VIEW_B -1\n","    LOSS_LABEL_VIEW_B = -1\n","\n","# (Dtype)訓練時輸入tensor dtype\n","INPUTS_TENSOR_DTYPE = torch.float\n","\n","# (Dtype)訓練時標籤tensor dtype\n","LABELS_TENSOR_DTYPE = torch.long\n","\n","# https://blog.csdn.net/jzlin1997/article/details/110048060\n","# (Boolean)是否進到Loss前的Ootput，要特別經過激活函數 False\n","USE_ACTIVITION_BEFORE_LOSS = False\n","if USE_ACTIVITION_BEFORE_LOSS:\n","    # Loss前Ootput的激活函數\n","    ACTIVITION_BEFORE_LOSS = nn.Sigmoid()\n","\n","# (String )評價指標的圖表顯示 accuracy/auc\n","PLOT_METRICS = 'accuracy'\n","\n","# (Boolean)是否印出完整編譯器\n","OPTIMIZER_PRINT = False\n","\n","\n","''''訓練參數設定'''\n","\n","# (Boolean)是否啟用混合精度訓練\n","AMP_SCALE_TRAIN = True\n","\n","# (Int List)每批訓練的尺寸\n","BATCH_SIZE = [256]*FOLD\n","\n","# (Int)訓練做幾次時代\n","EPOCHS = [10]*FOLD\n","\n","# (Int)指定列印進度條的位置（從0開始）\n","TQDM_POSITION = 0\n","\n","# (Boolean)保留迭代結束時進度條的所有痕跡。如果是None，只會在position是0時離開\n","TQDM_LEAVE = True\n","\n","# https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2021/02/19/gradient-accumulation.html\n","# (Int)假設您要在一批中使用32張圖像，但是一旦超出8張，硬件就會崩潰\n","# 在這種情況下，您可以使用8張圖像的批次並每4批次更新一次權重，因此設置 4\n","ACCUM_ITER = 1\n","\n","# (Boolean)是否計算每個Epoch Step指標，會造成CPU使用率變高\n","CALCULATE_EPOCH_STEP = False\n","\n","\n","''''圖表參數設定'''\n","\n","# (Float)全部SNS圖表的字形縮放\n","ALL_SNS_FONT_SCALE = 1.0\n","\n","# (Int)CSV缺失值圖表寬度\n","CSV_COUNTPLOT_FIGSIZE_W = 10\n","\n","# (Int)CSV缺失值圖表高度\n","CSV_COUNTPLOT_FIGSIZE_H = 10\n","\n","# (Int)CSV缺失值圖表標題字型大小\n","CSV_COUNTPLOT_TITLE_FONTSIZE = 20\n","\n","# (Int)CSV缺失值圖表X軸標題字型大小\n","CSV_COUNTPLOT_XLABEL_FONTSIZE = 15\n","\n","# (Int)CSV缺失值圖表Y軸標題字型大小\n","CSV_COUNTPLOT_YLABEL_FONTSIZE = 15\n","\n","# (Int)訓練歷程圖表寬度\n","TRAINING_CURVES_FIGSIZE_W = 20\n","\n","# (Int)訓練歷程圖表高度\n","TRAINING_CURVES_FIGSIZE_H = 10\n","\n","# (Int)訓練歷程圖表SCATTER的標記點大小 \n","TRAINING_CURVES_SCATTER_SCALAR = 200\n","\n","# (Float)訓練歷程圖表SCATTER的指標文字離標記點X距離係數\n","TRAINING_CURVES_SCATTER_METRICS_TEXT_XSCALAR = 0.03\n","\n","# (Float)訓練歷程圖表SCATTER的指標文字標記點Y距離係數\n","TRAINING_CURVES_SCATTER_METRICS_TEXT_YSCALAR = 0.13\n","\n","# (Float)訓練歷程圖表SCATTER的損失文字標記點X距離係數\n","TRAINING_CURVES_SCATTER_LOSS_TEXT_XSCALAR = 0.03\n","\n","# (Float)訓練歷程圖表SCATTER的損失文字標記點Y距離係數\n","TRAINING_CURVES_SCATTER_LOSS_TEXT_YSCALAR = 0.05\n","\n","# (Int)訓練歷程圖表SCATTER的文字大小\n","TRAINING_CURVES_SCATTER_TEXTSIZE = 15\n","\n","# (Int)訓練歷程圖表X軸標題字型大小\n","TRAINING_CURVES_XLABEL_FONTSIZE = 15\n","\n","# (Int)訓練歷程圖表Y軸標題字型大小\n","TRAINING_CURVES_YLABEL_FONTSIZE = 15\n","\n","# (Int)訓練歷程圖表標題字型大小\n","TRAINING_CURVES_TITLE_FONTSIZE = 20\n","\n","# (Float)訓練歷程圖表格線粗度\n","TRAINING_CURVES_GRID_ALPHA = 0\n","\n","# (Int)混淆矩陣圖表寬度\n","CONFUSION_MATRIX_FIGSIZE_W = 10\n","\n","# (Int)混淆矩陣圖表高度\n","CONFUSION_MATRIX_FIGSIZE_H = 10\n","\n","# (Int)混淆矩陣圖表內容字型大小\n","CONFUSION_MATRIX_HEATMAP_FONTSIZE = 15\n","\n","# (Int)混淆矩陣圖表標題字型大小\n","CONFUSION_MATRIX_TITLE_FONTSIZE = 20\n","\n","# (Int)混淆矩陣圖表X軸標題字型大小\n","CONFUSION_MATRIX_XLABEL_FONTSIZE = 15\n","\n","# (Int)混淆矩陣圖表Y軸標題字型大小\n","CONFUSION_MATRIX_YLABEL_FONTSIZE = 15\n","\n","# (String)預設'binary'：僅在目標為二進制，兩分類時適用。\n","#'micro'：通過計算總的真陽性，假陰性和假陽性來全局計算指標，多分類時適用。\n","#'macro'：計算每個標籤的指標，並找到其未加權平均值。這沒有考慮標籤不平衡，多分類時適用。\n","AVERAGE = 'macro'"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = CUDNN_DETERMINISTIC\n","    torch.backends.cudnn.benchmark = CUDNN_BENCHMARK\n","\n","seed_everything(SEED)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 設置sns圖表縮放係數\n","sns.set(font_scale = ALL_SNS_FONT_SCALE)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. 資料處理<a class=\"anchor\" id=\"4\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}},{"cell_type":"markdown","source":["## 4.1 載入CSV檔 <a class=\"anchor\" id=\"4.1\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}},{"cell_type":"code","source":["print('Reading data...')\n","\n","# 讀取訓練資料集CSV檔\n","train_csv = pd.read_csv(TRAIN_CSV_PATH,encoding=\"utf8\")\n","\n","print('Reading data completed')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 顯示訓練資料集CSV檔\n","train_csv.head()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Shape of train_data :\", train_csv.shape)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.2 檢查CSV檔缺失值 <a class=\"anchor\" id=\"4.2\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}},{"cell_type":"code","source":["# 缺失值比率\n","total = train_csv.isnull().sum().sort_values(ascending = False)\n","percent = (train_csv.isnull().sum()/train_csv.isnull().count()*100).sort_values(ascending = False)\n","missing_train_csv  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n","missing_train_csv.head(missing_train_csv.shape[0])"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_csv[LABEL_NAME].value_counts()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f,ax = plt.subplots(figsize=(CSV_COUNTPLOT_FIGSIZE_W, CSV_COUNTPLOT_FIGSIZE_H))\n","sns.countplot(train_csv[LABEL_NAME], hue = train_csv[LABEL_NAME],ax = ax)\n","plt.title(\"LABEL COUNT\", fontsize=CSV_COUNTPLOT_TITLE_FONTSIZE)\n","plt.xlabel(LABEL_NAME.upper(), fontsize=CSV_COUNTPLOT_XLABEL_FONTSIZE)\n","plt.ylabel(\"COUNT\", fontsize=CSV_COUNTPLOT_YLABEL_FONTSIZE)\n","plt.legend()\n","plt.show()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5. 定義模型方法<a class=\"anchor\" id=\"5\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}},{"cell_type":"code","source":["def build_optimizers(model):\n","    if OPTIMIZERS_TYPE == \"SGD\":\n","        RETURN_OPTIMIZERS = optim.SGD(model.parameters(), \n","                                      lr = LEARNING_RATE, momentum = MOMENTUM, \n","                                      dampening = DAMPENING, weight_decay = WEIGHT_DECAY, \n","                                      nesterov = NESTEROV)\n","    elif OPTIMIZERS_TYPE == \"Adam\":\n","        RETURN_OPTIMIZERS = optim.Adam(model.parameters(), \n","                                       lr = LEARNING_RATE, betas = BETAS, eps = EPS, \n","                                       weight_decay = WEIGHT_DECAY)\n","    elif OPTIMIZERS_TYPE == \"Adamax\":\n","        RETURN_OPTIMIZERS = optim.Adamax(model.parameters(), \n","                                         lr = LEARNING_RATE, betas = BETAS, eps = EPS, \n","                                         weight_decay = WEIGHT_DECAY)\n","    elif OPTIMIZERS_TYPE == \"RMSprop\":\n","        RETURN_OPTIMIZERS = optim.RMSprop(model.parameters(), \n","                                          lr = LEARNING_RATE, alpha = ALPHA, eps = EPS, \n","                                          weight_decay = WEIGHT_DECAY, momentum = MOMENTUM, \n","                                          centered = CENTERED)\n","    elif OPTIMIZERS_TYPE == \"Adagrad\":\n","        RETURN_OPTIMIZERS = optim.Adagrad(model.parameters(), \n","                                          lr = LEARNING_RATE, lr_decay = LR_DECAY, \n","                                          weight_decay = WEIGHT_DECAY)\n","    return RETURN_OPTIMIZERS"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_losses():\n","    return CUSTOM_LOSSES.to(DEVICE)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class build_model(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        \n","        if LOAD_MODEL:\n","            # 載入預訓練模型\n","            self.model = torch.load(LOAD_MODEL_PATH)\n","        elif CUSTOM_MODEL is not None:\n","            # 載入模型架構\n","            self.model = CUSTOM_MODEL\n","        elif TIMM_MODEL:\n","            self.model = timm.create_model(BASE_MODEL, pretrained = LOAD_WEIGHTS)\n","        else:\n","            self.model = BASE_MODEL(pretrained = LOAD_WEIGHTS)\n","\n","        if not LOAD_WEIGHTS:\n","            for param in self.model.parameters():\n","                param.requires_grad = False\n","\n","        if INCULDE_TOP:\n","            if CLASSIFIER_OUTPUT:\n","                n_features = self.model.classifier.in_features\n","                self.model.classifier = nn.Sequential(\n","                    nn.Dropout(DROPOUT), \n","                    nn.Linear(n_features, CLASSES, bias = BIAS)\n","                    )\n","            else:\n","                n_features = self.model.fc.in_features\n","                self.model.fc = nn.Sequential(\n","                    nn.Dropout(DROPOUT), \n","                    nn.Linear(n_features, CLASSES, bias = BIAS)\n","                    )\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","        return x"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 6. 定義回調函數方法 <a class=\"anchor\" id=\"6\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}},{"cell_type":"code","source":["def get_callbacks(optimizer):\n","    if CALLBACKS_STEPLR:\n","        # 等間隔調整學習率，調整倍數為gamma倍，調整間隔為step_size。間隔單位是step。需要注意的是，step通常是指epoch，不要弄成iteration了。\n","        callbacks_scheduler = lr_scheduler.StepLR(optimizer, step_size = STEP_SIZE, gamma = GAMMA)\n","    elif CALLBACKS_REDUCELRONPLATEAU:\n","        # 當某指標不再變化（下降或升高），調整學習率，這是非常實用的學習率調整策略。例如，當驗證集的loss不再下降時，進行學習率調整；\n","        # 或者監測驗證集的accuracy，當accuracy不再上升時，則調整學習率。\n","        callbacks_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,  mode = MODE, factor = FACTOR, patience = PATIENCE, \n","                                                   threshold = THRESHOLD, threshold_mode = THRESHOLD_MODE, cooldown = COOLDOWN, \n","                                                   min_lr = MIN_LR, eps = SCHEDULER_EPS, verbose = SCHEDULER_VERBOSE)\n","    elif CALLBACKS_COSINEANNEALINGWARMRESTAERS:\n","        # 使用餘弦退火時間表設置每個參數組的學習率\n","        callbacks_scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = T_0, T_mult = T_MULT, eta_min = ETA_MIN, \n","                                                             verbose = SCHEDULER_VERBOSE)\n","    else:\n","        callbacks_scheduler = None \n","    return callbacks_scheduler"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 7. 製作資料集＆資料擴增＆訓練模型 <a class=\"anchor\" id=\"7\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}},{"cell_type":"code","source":["class MyDataset(Dataset):\n","    def __init__(self, df, one_hot_label = False, transforms = None):\n","        super().__init__()\n","        self.df = df.reset_index(drop=True).copy()\n","        self.transforms = transforms\n","        self.labels = self.df[LABEL_NAME].values\n","        \n","        if one_hot_label is True:\n","            self.labels = np.eye(self.df[LABEL_NAME].max()+1)[self.labels]\n","        \n","    def __len__(self):\n","        return self.df.shape[0]\n","\n","    def __getitem__(self, index: int):\n","        label = self.labels[index]\n","        image_name = self.df[IMAGE_NAME].values[index]\n","\n","        if IMAGE_NAME_HAVE_EXTENSION:\n","            image_path = TRAIN_DATA_PATH + image_name\n","        else:\n","            image_path = TRAIN_DATA_PATH + image_name + IMAGE_NAME_EXTENSION\n","            \n","        image = cv2.imread(image_path)\n","        \n","        if COLOR_CONVERT_RGB:\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        \n","        if self.transforms is not None:\n","            image = self.transforms(image = image)['image']\n","            \n","        return image, label"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 確定是否將應用此增強。機率為 p = 1.0 意味著我們總是從上面應用轉換。\n","# p = 0 將意味著將忽略轉換塊。\n","# 0 < p < 1.0 等於每個擴增都具有以一定概率應用的選項。\n","# OneOf 隨機選取一種增強擴增\n","\n","def get_train_transforms(fold):\n","    return A.Compose([\n","        A.Blur(blur_limit = BLUR_LIMIT, \n","               p = P_BLUR), # 模糊\n","        A.HorizontalFlip(p = P_HORIZONTALFLIP), # 水平翻轉\n","        A.VerticalFlip(p = P_VERTICALFLIP), # 垂直翻轉\n","        A.Flip(p = P_FLIP), # 水平和垂直翻轉\n","        A.Resize(height = RESIZE_HEIGHT[fold], \n","                 width = RESIZE_WIDTH[fold], \n","                 p = P_RESIZE), # 縮放\n","        A.RandomResizedCrop(height = RANDOMRESIZEDCROP_HEIGHT[fold], \n","                            width = RANDOMRESIZEDCROP_WIDTH[fold], \n","                            scale = RANDOMRESIZEDCROP_SCALE, \n","                            p = P_RANDOMRESIZEDCROP), #隨機縮放剪裁\n","        A.RandomRotate90(p = P_RANDOMROTATE90), # 隨機旋轉90度\n","        A.ShiftScaleRotate(shift_limit = SHIFTSCALEROTATE_SHIFT_LIMIT, \n","                           scale_limit = SHIFTSCALEROTATE_SCALE_LIMIT, \n","                           rotate_limit = SHIFTSCALEROTATE_ROTATE_LIMIT, \n","                           p = P_SHIFTSCALEROTATE), # 平移縮放旋轉\n","        A.ElasticTransform(alpha = ELATICTRANSFORM_ALPHA, \n","                           sigma = ELATICTRANSFORM_SIGMA, \n","                           alpha_affine = ELATICTRANSFORM_ALPHA_AFFINE, \n","                           p = P_ELATICTRANSFORM), # 彈性變換\n","        A.GridDistortion(num_steps = GRIDDISTORTION_NUM_STEPS, \n","                         p = P_GRIDDISTORTION), # 網格失真\n","        A.RandomBrightnessContrast(brightness_limit = RANDOMBRIGHTNESSCONTRAST_BRIGHTNESS_LIMIT, \n","                                   contrast_limit = RANDOMBRIGHTNESSCONTRAST_CONTRAST_LIMIT, \n","                                   p = P_RANDOMBRIGHTNESSCONTRAST_CONTRAST), # 隨機亮度對比度\n","        A.HueSaturationValue(hue_shift_limit = HUESATURATIONVALUE_HUE_SHIFT_LIMIT, \n","                             sat_shift_limit = HUESATURATIONVALUE_SAT_SHIFT_LIMIT, \n","                             val_shift_limit = HUESATURATIONVALUE_VAL_SHIFT_LIMIT, \n","                             p = P_HUESATURATIONVALUE), # 隨機色調飽和度值\n","        A.CLAHE(clip_limit = CLAHE_CLIP_LIMIT, \n","                p = P_CLAHE), # 將對比度受限的自適應直方圖均衡化應用於輸入圖像\n","        A.Cutout(num_holes = COARSEDROPOUT_NUM_HOLES, \n","                        max_h_size = COARSEDROPOUT_MAX_H_SIZE, \n","                        max_w_size = COARSEDROPOUT_MAX_W_SIZE, \n","                        p = P_COARSEDROPOUT), # 隨機在圖像上生成黑色矩形\n","        A.Normalize(\n","             mean = NORMALIZE_MEAN, \n","             std = NORMALIZE_STD, \n","            max_pixel_value = NORMALIZE_MAX_PIXEL_VALUE, \n","            p = P_NORMALIZE), # 正規化。\n","        ToTensorV2(p = P_TOTENSORV2) # 歸一化\n","    ], p = P_TRAIN_TRANSFORMS)\n","\n","def get_val_transforms(fold):\n","    return A.Compose([\n","        A.Resize(height = RESIZE_HEIGHT[fold], \n","                 width = RESIZE_WIDTH[fold], \n","                 p = P_RESIZE), # 縮放\n","        A.Normalize(\n","             mean = NORMALIZE_MEAN,\n","             std = NORMALIZE_STD, \n","            max_pixel_value = NORMALIZE_MAX_PIXEL_VALUE, \n","            p = P_NORMALIZE), # 正規化。\n","        ToTensorV2(p = P_TOTENSORV2) # 歸一化\n","    ], p = P_VAL_TRANSFORMS)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_dataloader(fold, train_index, valid_index):\n","    \n","    if FOLD >1:\n","        train_data = train_csv.loc[train_index,:]\n","        validation_data = train_csv.loc[valid_index,:]\n","    else:\n","        X_train, X_val, Y_train, Y_val = train_test_split(train_csv[IMAGE_NAME], \n","                                                              train_csv[LABEL_NAME], \n","                                                              test_size = DATA_SPLIT, \n","                                                              random_state = SEED)\n","        train_data = pd.DataFrame(X_train)\n","        train_data.columns = [IMAGE_NAME]\n","        train_data[LABEL_NAME] = Y_train\n","\n","        validation_data = pd.DataFrame(X_val)\n","        validation_data.columns = [IMAGE_NAME]\n","        validation_data[LABEL_NAME] = Y_val\n","        \n","    train_dataset = MyDataset(train_data, one_hot_label = ONE_HOT_LABEL, transforms = get_train_transforms(fold))\n","    val_dataset = MyDataset(validation_data, one_hot_label = ONE_HOT_LABEL, transforms = get_val_transforms(fold))\n","    \n","    # 紀錄訓練集跟驗證集大小\n","    train_dataset_size = len(train_dataset)\n","    val_dataset_size = len(val_dataset)\n","    \n","    #for metrics\n","    dataset_sizes = { 'train': train_dataset_size, 'val': val_dataset_size}\n","    print(dataset_sizes)\n","    \n","    train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE[fold], pin_memory = PIN_MEMORY, \n","                                               shuffle = True, num_workers = NUM_WORKERS, drop_last = DROP_LAST)\n","    \n","    val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE[fold], pin_memory = PIN_MEMORY, \n","                                               shuffle = False, num_workers = NUM_WORKERS)\n","    \n","    del train_data, validation_data, train_dataset, val_dataset, dataset_sizes\n","    if FOLD <=1:\n","        del X_train, X_val, Y_train, Y_val\n","    gc.collect()\n","    \n","    return train_loader, val_loader, train_dataset_size, val_dataset_size"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def display_training_curves(fold, kf, train_metrics, val_metrics):\n","    plt.figure(figsize=(TRAINING_CURVES_FIGSIZE_W,TRAINING_CURVES_FIGSIZE_H))\n","    plt.plot(np.arange(EPOCHS[fold]),train_metrics[PLOT_METRICS],'-o',label='TRAIN '+PLOT_METRICS.upper(),color='#ff7f0e')\n","    plt.plot(np.arange(EPOCHS[fold]),val_metrics[PLOT_METRICS],'-o',label='VALIDATION '+PLOT_METRICS.upper(),color='#1f77b4')\n","    x = np.argmax( val_metrics[PLOT_METRICS] ); y = np.max( val_metrics[PLOT_METRICS] )\n","    xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n","    plt.scatter(x,y,s=TRAINING_CURVES_SCATTER_SCALAR,color='#1f77b4')\n","    plt.text(x-TRAINING_CURVES_SCATTER_METRICS_TEXT_XSCALAR*xdist,y-TRAINING_CURVES_SCATTER_METRICS_TEXT_YSCALAR*ydist,'max '+PLOT_METRICS+'\\n%.4f'%y,size=TRAINING_CURVES_SCATTER_TEXTSIZE)\n","    plt.ylabel(PLOT_METRICS.upper(),size=TRAINING_CURVES_YLABEL_FONTSIZE); plt.xlabel('EPOCH',size=TRAINING_CURVES_XLABEL_FONTSIZE)\n","    plt.grid(alpha=TRAINING_CURVES_GRID_ALPHA)\n","    plt.legend(loc=2)\n","    plt2 = plt.gca().twinx()\n","    plt2.plot(np.arange(EPOCHS[fold]),train_metrics['loss'],'-o',label='TRAIN LOSS',color='#2ca02c')\n","    plt2.plot(np.arange(EPOCHS[fold]),val_metrics['loss'],'-o',label='VALIDATION LOSS',color='#d62728')\n","    x = np.argmin( val_metrics['loss'] ); y = np.min( val_metrics['loss'] )\n","    ydist = plt.ylim()[1] - plt.ylim()[0]\n","    plt.scatter(x,y,s=TRAINING_CURVES_SCATTER_SCALAR,color='#d62728')\n","    plt.text(x-TRAINING_CURVES_SCATTER_LOSS_TEXT_XSCALAR*xdist,y+TRAINING_CURVES_SCATTER_LOSS_TEXT_YSCALAR*ydist,'min loss\\n%.4f'%y,size=TRAINING_CURVES_SCATTER_TEXTSIZE)\n","    plt.ylabel('LOSS',size=TRAINING_CURVES_YLABEL_FONTSIZE)\n","    if kf:\n","        plt.title('FOLD %i - IMAGE SIZE %i, %s'%\n","                  (fold+1, IMAGE_SIZE[fold], MODEL_NAME.upper()), size=TRAINING_CURVES_TITLE_FONTSIZE)\n","    else:\n","        plt.title(' IMAGE SIZE %i, %s'%\n","                  (IMAGE_SIZE[fold], MODEL_NAME.upper()), size=TRAINING_CURVES_TITLE_FONTSIZE)\n","    plt.grid(alpha=TRAINING_CURVES_GRID_ALPHA)\n","    plt.legend(loc=3)\n","    plt.show()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_one_epoch(fold, epoch, model, scaler, train_loss, optimizer, train_loader, train_dataset_size, \n","                    train_metrics, writer = None, scheduler = None, scheduler_batch_update = False):\n","    # 設定模型為訓練模式\n","    model.train()\n","    \n","    # 計算迭代目前的step\n","    epoch_step = 0\n","\n","    # 計算當下loss\n","    running_loss = 0.0\n","    \n","    # 計算每迭代loss\n","    epoch_loss = 0.0\n","    \n","    # 計算每迭代accuracy\n","    epoch_accuracy = 0.0\n","    \n","    # 計算每迭代auc\n","    epoch_auc = 0.0\n","    \n","    # 加總每批輸出\n","    outputs_all = []\n","    \n","    # 加總每批標籤\n","    labels_all = []\n","\n","    # 遍歷enumaretad批處理\n","    pbar = tqdm(enumerate(train_loader), total=len(train_loader), \n","                position = TQDM_POSITION, leave = TQDM_LEAVE)\n","    for batch_idx, (inputs, labels) in pbar:\n","        # 提取輸入和標籤\n","        inputs = torch.tensor(inputs.to(DEVICE), dtype = INPUTS_TENSOR_DTYPE)\n","        labels = torch.tensor(labels.to(DEVICE), dtype = LABELS_TENSOR_DTYPE)\n","        \n","        if VIEW_LABEL_TENSOR:\n","            labels = labels.view(LOSS_LABEL_VIEW_A, LOSS_LABEL_VIEW_B)\n","        \n","        if AMP_SCALE_TRAIN:\n","            # 前向過程(model + loss)開啟 autocast\n","            with autocast():\n","                outputs = model(inputs)\n","                if USE_ACTIVITION_BEFORE_LOSS:\n","                    outputs = ACTIVITION_BEFORE_LOSS(outputs)\n","                loss = train_loss(outputs, labels)\n","        else:\n","            outputs = model(inputs)\n","            if USE_ACTIVITION_BEFORE_LOSS:\n","                outputs = ACTIVITION_BEFORE_LOSS(outputs)\n","            loss = train_loss(outputs, labels)\n","            \n","        # 歸一化損失以說明批次累積\n","        loss = loss / ACCUM_ITER \n","            \n","        if AMP_SCALE_TRAIN:\n","            # Scales loss. 為了梯度放大\n","            # 反向傳播在autocast上下文之外\n","            scaler.scale(loss).backward()\n","        else:\n","            loss.backward()\n","\n","        # 權重更新\n","        if ((batch_idx + 1) %  ACCUM_ITER == 0) or ((batch_idx + 1) == len(train_loader)):\n","\n","            if AMP_SCALE_TRAIN:\n","                # scaler.step() 首先把梯度的值unscale回來.\n","                # 如果梯度的值不是 infs 或者 NaNs, 那麼調用optimizer.step()來更新權重,\n","                # 否則，忽略step調用，從而保證權重不更新（不被破壞）\n","                scaler.step(optimizer)\n","\n","                # 準備著，看是否要增大scaler\n","                scaler.update()\n","            else:\n","                optimizer.step()\n","            \n","            # 零參數梯度\n","            optimizer.zero_grad() \n","            \n","            if scheduler is not None and scheduler_batch_update:\n","                scheduler.step()\n","            \n","        if CALCULATE_EPOCH_STEP:\n","            # step / epoch statistics\n","            epoch_step += 1\n","            epoch_step_outputs_all = []\n","            epoch_step_labels_all = []\n","            epoch_step_outputs_all = np.concatenate([torch.argmax(outputs, 1).detach().cpu().numpy()])\n","            epoch_step_labels_all = np.concatenate([labels.detach().cpu().numpy()])\n","            \n","            if PLOT_METRICS == \"accuracy\":\n","                epoch_step_accuracy = (epoch_step_outputs_all == epoch_step_labels_all).mean()\n","                print(f\"Step {epoch_step} / Epoch {epoch+1} - Train Loss: {loss.item():.4f}, Train Accuracy: {epoch_step_accuracy:.4f}\")\n","            else:\n","                epoch_step_auc =  roc_auc_score(epoch_step_labels_all, epoch_step_outputs_all)\n","                print(f\"Step {epoch_step} / Epoch {epoch+1} - Train Loss: {loss.item():.4f}, Train Auc: {epoch_step_auc:.4f}\")\n","            \n","            if CALLBACKS_TENSOR_BOARD:\n","                epoch_len = train_dataset_size // train_loader.batch_size\n","                writer.add_scalar(\"Loss/Train\", loss.item(), epoch_len * epoch + epoch_step)\n","                if PLOT_METRICS == \"accuracy\":\n","                    writer.add_scalar(\"Accuracy/Train\", epoch_step_accuracy, epoch_len * epoch + epoch_step)\n","                else:\n","                    writer.add_scalar(\"Auc/Train\", epoch_step_auc, epoch_len * epoch + epoch_step)\n","            \n","        # epoch statistics\n","        running_loss += loss.item()*inputs.size(0)\n","        outputs_all += [torch.argmax(outputs, 1).detach().cpu().numpy()]\n","        labels_all += [labels.detach().cpu().numpy()]\n","    outputs_all = np.concatenate(outputs_all)\n","    labels_all = np.concatenate(labels_all)\n","    \n","    epoch_loss = running_loss / train_dataset_size\n","    train_metrics['loss'].append(epoch_loss)   \n","    if PLOT_METRICS == \"accuracy\":\n","        epoch_accuracy = (outputs_all == labels_all).mean()\n","        train_metrics[PLOT_METRICS].append(epoch_accuracy)\n","        print(f\"Epoch {epoch+1}/{EPOCHS[fold]} - Train Average Loss: {epoch_loss:.4f}, Train Average Accuracy: {epoch_accuracy:.4f}\")\n","    elif PLOT_METRICS == \"auc\":\n","        epoch_auc =  roc_auc_score(labels_all, outputs_all)\n","        train_metrics[PLOT_METRICS].append(epoch_auc)\n","        print(f\"Epoch {epoch+1}/{EPOCHS[fold]} - Train Average Loss: {epoch_loss:.4f}, Train Average Auc: {epoch_auc:.4f}\")\n","       \n","    if scheduler is not None and not scheduler_batch_update:\n","        scheduler.step()\n","        \n","    del model, epoch_step, running_loss, epoch_loss, epoch_accuracy, epoch_auc\n","    del outputs_all, labels_all\n","    if CALCULATE_EPOCH_STEP:\n","        del epoch_step_outputs_all, epoch_step_labels_all\n","    gc.collect()\n","        \n","def valid_one_epoch(fold, epoch, model, val_loss, val_loader, val_dataset_size, val_metrics, monitor_metrics, save_model_path, \n","                    writer = None, scheduler = None, scheduler_loss_update = False):\n","    # 設定模型為評估模式\n","    model.eval()\n","    \n","    # 計算迭代目前的step\n","    epoch_step = 0\n","\n","    # 計算每批loss\n","    running_loss = 0.0\n","    \n","    # 計算每迭代loss\n","    epoch_loss = 0.0\n","    \n","    # 計算每迭代accuracy\n","    epoch_accuracy = 0.0\n","    \n","    # 計算每迭代auc\n","    epoch_auc = 0.0\n","    \n","    # 計算提早停止次數\n","    early_stopping = 0\n","    \n","    # 加總每批輸出\n","    outputs_all = []\n","    \n","    # 加總每批標籤\n","    labels_all = []\n","    \n","    # 遍歷enumaretad批處理\n","    pbar = tqdm(enumerate(val_loader), total=len(val_loader), \n","                position = TQDM_POSITION, leave = TQDM_LEAVE)\n","    for batch_idx, (inputs, labels) in pbar:\n","        # 提取輸入和標籤\n","        inputs = torch.tensor(inputs.to(DEVICE), dtype = INPUTS_TENSOR_DTYPE)\n","        labels = torch.tensor(labels.to(DEVICE), dtype = LABELS_TENSOR_DTYPE)\n","        \n","        if VIEW_LABEL_TENSOR:\n","            labels = labels.view(LOSS_LABEL_VIEW_A, LOSS_LABEL_VIEW_B)\n","        \n","        outputs = model(inputs)\n","        if USE_ACTIVITION_BEFORE_LOSS:\n","            outputs = ACTIVITION_BEFORE_LOSS(outputs)\n","        loss = val_loss(outputs, labels)\n","        \n","        if CALCULATE_EPOCH_STEP:\n","            # step / epoch statistics\n","            epoch_step += 1\n","            epoch_step_outputs_all = []\n","            epoch_step_labels_all = []\n","            epoch_step_outputs_all = np.concatenate([torch.argmax(outputs, 1).detach().cpu().numpy()])\n","            epoch_step_labels_all = np.concatenate([labels.detach().cpu().numpy()])\n","  \n","            if PLOT_METRICS == \"accuracy\":\n","                epoch_step_accuracy = (epoch_step_outputs_all == epoch_step_labels_all).mean()\n","                print(f\"Step {epoch_step} / Epoch {epoch+1} - Val Loss: {loss.item():.4f}, Val Accuracy: {epoch_step_accuracy:.4f}\")\n","            else:\n","                epoch_step_auc =  roc_auc_score(epoch_step_labels_all, epoch_step_outputs_all)\n","                print(f\"Step {epoch_step} / Epoch {epoch+1} - Val Loss: {loss.item():.4f}, Val Auc: {epoch_step_auc:.4f}\")\n","            \n","            if CALLBACKS_TENSOR_BOARD:\n","                epoch_len = val_dataset_size // val_loader.batch_size\n","                writer.add_scalar(\"Loss/Val\", loss.item(), epoch_len * epoch + epoch_step)\n","                if PLOT_METRICS == \"accuracy\":\n","                    writer.add_scalar(\"Accuracy/Val\", epoch_step_accuracy, epoch_len * epoch + epoch_step)\n","                else:\n","                    writer.add_scalar(\"Auc/Val\", epoch_step_auc, epoch_len * epoch + epoch_step)\n","            \n","        # epoch statistics\n","        running_loss += loss.item()*inputs.size(0)\n","        outputs_all += [torch.argmax(outputs, 1).detach().cpu().numpy()]\n","        labels_all += [labels.detach().cpu().numpy()]\n","    \n","    outputs_all = np.concatenate(outputs_all)\n","    labels_all = np.concatenate(labels_all)\n","    \n","    # 為了計算全部迭代混淆矩陣\n","    all_outputs.append(outputs_all)\n","    all_labels.append(labels_all)\n","        \n","    epoch_loss = running_loss / val_dataset_size\n","    val_metrics['loss'].append(epoch_loss)\n","    if PLOT_METRICS == \"accuracy\":\n","        epoch_accuracy = (outputs_all == labels_all).mean()\n","        val_metrics[PLOT_METRICS].append(epoch_accuracy)\n","        print(f\"Epoch {epoch+1}/{EPOCHS[fold]} - Val Average Loss: {epoch_loss:.4f}, Val Average Accuracy: {epoch_accuracy:.4f}\")         \n","    elif PLOT_METRICS == \"auc\":\n","        epoch_auc =  roc_auc_score(labels_all, outputs_all)\n","        val_metrics[PLOT_METRICS].append(epoch_auc)\n","        print(f\"Epoch {epoch+1}/{EPOCHS[fold]} - Val Average Loss: {epoch_loss:.4f}, Val Average Auc: {epoch_auc:.4f}\")\n","        \n","    if CALLBACKS_CHECK_POINTER:\n","        save_model = False\n","        if SAVE_BEST_ONLY:\n","            if (epoch_loss < monitor_metrics or monitor_metrics == 0) and MONITOR == \"val_loss\":\n","                monitor_metrics = epoch_loss\n","                save_model = True\n","            elif epoch_accuracy > monitor_metrics and MONITOR == \"val_acc\" and PLOT_METRICS == \"accuracy\":\n","                monitor_metrics = epoch_accuracy\n","                save_model = True \n","            elif epoch_auc > monitor_metrics and MONITOR == \"val_auc\" and PLOT_METRICS == \"auc\":\n","                monitor_metrics = epoch_auc\n","                save_model = True\n","            else:\n","                early_stopping += 1\n","        else:\n","            if MONITOR == \"val_loss\":\n","                if monitor_metrics is not 0:\n","                    if epoch_loss >= monitor_metrics:\n","                        early_stopping += 1\n","                monitor_metrics = epoch_loss\n","            elif MONITOR == \"val_acc\":\n","                if monitor_metrics is not 0:\n","                    if epoch_accuracy <= monitor_metrics:\n","                        early_stopping += 1\n","                monitor_metrics = epoch_accuracy\n","            elif MONITOR == \"val_auc\":\n","                if monitor_metrics is not 0:\n","                    if epoch_auc <= monitor_metrics:\n","                        early_stopping += 1\n","                monitor_metrics = epoch_auc\n","            save_model = True\n","            \n","        if SAVE_WEIGHTS_ONLY and save_model:\n","            torch.save(model.state_dict(), save_model_path)\n","            print('Save weights')\n","        elif not SAVE_WEIGHTS_ONLY and save_model:\n","            torch.save(model, save_model_path)\n","            print('Save model')\n","\n","    if scheduler is not None and VAL_ENABLE_SCHEDULER:\n","        if scheduler_loss_update:\n","            scheduler.step(epoch_loss)\n","        else:\n","            scheduler.step()\n","            \n","    del model, epoch_step, running_loss, epoch_loss, epoch_accuracy, epoch_auc\n","    del outputs_all, labels_all\n","    if CALCULATE_EPOCH_STEP:\n","        del epoch_step_outputs_all, epoch_step_labels_all\n","    gc.collect()\n","            \n","    return early_stopping"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_process(fold, kf, train_index, valid_index):\n","    if kf:\n","        print('Fold %i - image size %i with %s and batch size %i'%(fold+1,IMAGE_SIZE[fold],MODEL_NAME.upper(),BATCH_SIZE[fold]))\n","    else:\n","        print('Image size %i with %s and batch_size %i'%(IMAGE_SIZE[fold],MODEL_NAME.upper(),BATCH_SIZE[fold]))\n","        \n","    if kf:\n","        # (String)訓練模型FOLD>1的儲存路徑\n","        if MODEL_TIME_FOLDER:\n","            SAVE_MODEL_PATH = PROJECT_PATH+r'/models/'+MODEL_NAME+'_fold_%i.pt'%(fold+1)\n","        else:\n","            SAVE_MODEL_PATH = MODEL_NAME+'_fold_%i.pt'%(fold+1)\n","    else:\n","        SAVE_MODEL_PATH = TRAIN_MODEL_PATH\n","    \n","    train_loader, val_loader, train_dataset_size, val_dataset_size = prepare_dataloader(fold, train_index, valid_index)\n","\n","    # 創建model\n","    model = build_model()\n","    \n","    if CUSTOM_MODEL is not None and LOAD_WEIGHTS:\n","        # 載入預訓練權重\n","        model.load_state_dict(torch.load(LOAD_MODEL_PATH))\n","\n","    model.to(DEVICE)\n","    optimizer = build_optimizers(model)\n","    \n","    # 在訓練最開始之前實例化一個GradScaler對象\n","    scaler = GradScaler()\n","    \n","    if CALLBACKS_TENSOR_BOARD:\n","        # 在訓練最開始之前實例化一個SummaryWriter對象\n","        writer = SummaryWriter(comment=TENSOR_BOARD_COMMENT)\n","    else:\n","        writer = None\n","    \n","    scheduler = get_callbacks(optimizer) # 回調函式\n","\n","    train_loss = build_losses() # train loss\n","    val_loss = build_losses() # val loss\n","\n","    if MODEL_PRINT:\n","        # Print model's state_dict\n","        print(\"Model's state_dict:\")\n","        for param_tensor in model.state_dict():\n","            print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n","\n","    if OPTIMIZER_PRINT:\n","        # Print optimizer's state_dict\n","        print(\"Optimizer's state_dict:\")\n","        for var_name in optimizer.state_dict():\n","            print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n","            \n","    # 紀錄最好指標\n","    monitor_metrics = 0.0\n","    \n","    #save the losses and metrics for further visualization\n","    train_metrics = {PLOT_METRICS:[], 'loss':[]}\n","    val_metrics = {PLOT_METRICS:[], 'loss':[]}\n","               \n","    for epoch in range(EPOCHS[fold]):\n","        train_one_epoch(fold, epoch, model, scaler, train_loss, optimizer, train_loader, train_dataset_size, \n","                        train_metrics, writer, scheduler = scheduler, scheduler_batch_update = SCHEDULER_BATCH_UPDATE)\n","\n","        with torch.no_grad():\n","            early_stopping = valid_one_epoch(fold, epoch, model, val_loss, val_loader, val_dataset_size, \n","                                             val_metrics, monitor_metrics, SAVE_MODEL_PATH, writer, \n","                                             scheduler = scheduler, scheduler_loss_update = SCHEDULER_LOSS_UPDATE)\n","        \n","        if CALLBACKS_EARLY_STOPPING:\n","            if early_stopping >= PATIENCE_ELS:\n","                break\n","            \n","    display_training_curves(fold, kf, train_metrics, val_metrics)\n","    \n","    if not CALLBACKS_CHECK_POINTER:\n","        if SAVE_WEIGHTS_ONLY:\n","            torch.save(model.state_dict(), SAVE_MODEL_PATH)\n","            print('Save weights')\n","        else:\n","            torch.save(model, SAVE_MODEL_PATH)\n","            print('Save model')\n","    \n","    if CALLBACKS_TENSOR_BOARD:\n","        writer.flush()\n","        writer.close()\n","        \n","    torch.cuda.empty_cache()\n","    \n","    del model, optimizer, train_loader, val_loader, scaler, scheduler, train_loss, val_loss\n","    del train_dataset_size, val_dataset_size, monitor_metrics, early_stopping\n","    gc.collect()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main():\n","    try:\n","        print('Training start')\n","        since = time.time()\n","        if FOLD > 1:\n","            for fold,(train_index, valid_index) in enumerate(KF.split(np.arange(train_csv.shape[0]), train_csv[LABEL_NAME])):\n","                train_process(fold = fold, kf = True, train_index = train_index, valid_index = valid_index)\n","        else:\n","            train_process(fold = 0, kf = False, train_index = None, valid_index = None)\n","        time_elapsed = time.time() - since\n","        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    except Exception as exception:\n","        print(exception)\n","        raise"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 宣告為訓練後混淆矩陣預測\n","all_labels = []; all_outputs = []"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    main()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 8. 混淆矩陣 & Quadratic Weighted Kappa<a class=\"anchor\" id=\"8\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}},{"cell_type":"code","source":["cm_correct_labels = np.concatenate(all_labels)\n","cm_predictions = np.concatenate(all_outputs)\n","print(\"Correct   labels: \", cm_correct_labels.shape, cm_correct_labels)\n","print(\"Predicted labels: \", cm_predictions.shape, cm_predictions)\n","cm_correct_labels = torch.tensor(cm_correct_labels)\n","cm_predictions = torch.tensor(cm_predictions)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''混淆矩陣包含四個要素:TP(True Positive)正確預測成功的正樣本, TN(True Negative)正確預測成功的負樣本, \n","FP(False Positive)錯誤預測成正樣本，實際上為負樣本, FN(False Negative)錯誤預測成負樣本(或者說沒能預測出來的正樣本)'''\n","cm = confusion_matrix(cm_correct_labels, cm_predictions)\n","cm = cm/cm.sum(axis=1)[:, np.newaxis]\n","\n","f,ax = plt.subplots(figsize = (CONFUSION_MATRIX_FIGSIZE_W, CONFUSION_MATRIX_FIGSIZE_H))\n","sns.heatmap(cm, annot = True, ax = ax, annot_kws={\"size\": CONFUSION_MATRIX_HEATMAP_FONTSIZE})\n","plt.title(\"CONFUSION MATRIX\", fontsize=CONFUSION_MATRIX_TITLE_FONTSIZE)\n","plt.xlabel(\"PREDICTED\", fontsize=CONFUSION_MATRIX_XLABEL_FONTSIZE)\n","plt.ylabel(\"TRUE\", fontsize=CONFUSION_MATRIX_YLABEL_FONTSIZE)\n","plt.show()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Accuracy = (TP+TN)/(TP+FP+TN+FN)\n","Precision(準確率) = TP/(TP+FP)\n","Recall(召回率) = TP/(TP+FN)\n","F1-score(Recall與Precision的調和平均數) = 2 * Precision * Recall / (Precision + Recall)\n","'''\n","accuracy = accuracy_score(cm_correct_labels, cm_predictions)\n","precision = precision_score(cm_correct_labels, cm_predictions, labels = range(CLASSES), average = AVERAGE)\n","recall = recall_score(cm_correct_labels, cm_predictions, labels = range(CLASSES), average = AVERAGE)\n","score = f1_score( cm_correct_labels, cm_predictions, labels = range(CLASSES), average = AVERAGE)\n","print('Accuracy: {:.3f}, Precision: {:.3f}, Recall: {:.3f}, F1 score: {:.3f}'.format(accuracy, precision, recall, score))"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Classification report on training Data\n","print(classification_report(cm_correct_labels, cm_predictions))"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Quadratic Weighted Kappa\n","# https://www.kaggle.com/ashwan1/understanding-kappa-using-dummy-classifier#\n","cohen_kappa_score(cm_predictions, cm_correct_labels, weights='quadratic')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 9. 待辦事項<a class=\"anchor\" id=\"9\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}}]}