{"cells":[{"metadata":{},"cell_type":"markdown","source":["# Image_Classification_TFRecord (Training)"]},{"metadata":{},"cell_type":"markdown","source":["<a class=\"anchor\" id=\"0\"></a>\n","# Table of Contents\n","\n","1. [套件安裝與載入](#1)\n","1. [環境檢測與設定](#2)\n","1. [開發參數設定](#3)\n","1. [資料處理](#4)\n","    -  [載入資料集](#4.1)\n","    -  [定義資料集生成方法](#4.2)\n","1. [資料視覺化](#5)\n","1. [定義模型方法](#6)\n","1. [定義回調函數方法](#7)\n","1. [製作資料集＆資料擴增&訓練模型](#8)\n","1. [混淆矩陣](#9)\n","1. [待辦事項](#10)"]},{"metadata":{"id":"bUJCH3yIky4W"},"cell_type":"markdown","source":["# 1. 套件安裝與載入<a class=\"anchor\" id=\"1\"></a>\n","[Back to Table of Contents](#0)"]},{"metadata":{"trusted":true},"cell_type":"code","source":["!pip install -q efficientnet\n","import efficientnet.tfkeras as efn"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# !pip install tensorflow-addons\n","# import tensorflow_addons.optimizers as addons_optimizers"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# 資料處理套件\n","import os\n","import gc\n","import sys\n","import PIL\n","import random\n","import datetime\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from collections import Counter\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":null,"outputs":[]},{"metadata":{"id":"ToAwBKMcky4b","trusted":true},"cell_type":"code","source":["# 設定顯示中文字體\n","from matplotlib.font_manager import FontProperties\n","plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei'] # 用來正常顯示中文標籤\n","plt.rcParams['font.family'] = 'AR PL UMing CN'\n","plt.rcParams['axes.unicode_minus'] = False # 用來正常顯示負號"],"execution_count":null,"outputs":[]},{"metadata":{"id":"DNhU-tX9ky4i","trusted":true},"cell_type":"code","source":["# tensorflow深度學習模組套件\n","import tensorflow as tf, re, math\n","import tensorflow.keras.backend as K\n","import tensorflow.keras.layers as layers\n","import tensorflow.keras.losses as losses\n","import tensorflow.keras.callbacks as callbacks\n","import tensorflow.keras.optimizers as optimizers\n","import tensorflow.keras.applications as applications\n","\n","from tensorflow import keras\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.python.client import device_lib"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# 2. 環境檢測與設定<a class=\"anchor\" id=\"2\"></a>\n","[Back to Table of Contents](#0)"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# 查看設備\n","print(device_lib.list_local_devices())"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# 查看tensorflow版本\n","print(tf.__version__)\n","\n","# 查看圖像通道位置\n","print(K.image_data_format())"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["'''執行環境參數設定'''\n","\n","# (Boolean)是否為本機\n","LOCAL = False\n","\n","# (Boolean)是否為 Colab\n","COLAB = False\n","\n","if not LOCAL and not COLAB:\n","    from kaggle_datasets import KaggleDatasets\n","\n","# (String)CPU/GPU/TPU\n","DEVICE = \"TPU\"\n","\n","\n","'''檔案路徑參數設定'''\n","\n","# (String)TFRecord資料檔名是否包含-IPIXELxIPIXEL\n","TFRECORD_FILENAME_IPIXEL = True\n","\n","# (String)TFRecord資料檔名\n","TFRECORD_GCS_PATH = 'mango-tfrecords'\n","\n","# (String)Root路徑\n","if LOCAL:\n","    PATH = r'../'\n","elif COLAB:\n","    PATH = r'/content/drive/My Drive/Colab Notebooks/'\n","else:\n","    PATH = r'../input/'\n","    OUTPUT_PATH = r'/kaggle/working/'\n","\n","# (String)資料根路徑\n","DATA_ROOT_PATH = PATH+r'mango-tfrecords-224x224/' \n","\n","# (String)訓練資料路徑\n","TRAIN_DATA_PATH = DATA_ROOT_PATH\n","\n","# (String)訓練CSV路徑，如為None則不讀CSV檔\n","TRAIN_CSV_PATH = DATA_ROOT_PATH+'train_cropped.csv'\n","\n","# (String)測試資料路徑\n","TEST_DATA_PATH = DATA_ROOT_PATH\n","\n","# (String)測試CSV路徑，如為None則不讀CSV檔\n","TEST_CSV_PATH = DATA_ROOT_PATH+'test_Final_example.csv'\n","\n","# (String)專案名稱\n","PROJECT_NAME = 'mango-tfrecords-224x224'\n","\n","# (String)專案檔案儲存路徑\n","if LOCAL or COLAB:\n","    OUTPUT_PATH = PATH\n","PROJECT_PATH = OUTPUT_PATH+PROJECT_NAME+' '+datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n","\n","# (String)權重名稱(使用哪個權重)\n","WEIGHTS_NAME = 'efficientnetb6'\n","\n","# (String)模型名稱(使用哪個模型)\n","MODEL_NAME = 'efficientnetb6'\n","\n","# (String)讀取預訓練權重的儲存路徑\n","LOAD_WEIGHTS_PATH = PROJECT_PATH+r'/models/backup/'+WEIGHTS_NAME+'.h5'\n","\n","# (String)讀取預訓練模型的儲存路徑\n","LOAD_MODEL_PATH = PROJECT_PATH+r'/models/backup/'+MODEL_NAME+'.h5'\n","\n","# (String)CSV的儲存路徑\n","CSV_SAVE_PATH = PROJECT_PATH+r'/csv/'+MODEL_NAME+'.csv'\n","\n","# (String)TensorBoard logs的儲存路徑 %tensorboard --logdir logs/fit\n","TENSORBOARD_LOGS_PATH = PROJECT_PATH+r'/logs/fit'\n","\n","# (String)訓練模型的儲存路徑\n","TRAIN_MODEL_PATH = PROJECT_PATH+r'/models/'+MODEL_NAME+'.h5'"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["if not LOCAL and COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["if DEVICE != \"CPU\":\n","    !nvidia-smi"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["if DEVICE == \"TPU\":\n","    print(\"connecting to TPU...\")\n","    try:\n","        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","        print('Running on TPU ', tpu.master())\n","    except ValueError:\n","        print(\"Could not connect to TPU\")\n","        tpu = None\n","\n","    if tpu:\n","        try:\n","            print(\"initializing  TPU ...\")\n","            tf.config.experimental_connect_to_cluster(tpu)\n","            tf.tpu.experimental.initialize_tpu_system(tpu)\n","            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","            print(\"TPU initialized\")\n","        except _:\n","            print(\"failed to initialize TPU\")\n","    else:\n","        DEVICE = \"GPU\"\n","\n","if DEVICE != \"TPU\":\n","    print(\"Using default strategy for CPU and single GPU\")\n","    strategy = tf.distribute.get_strategy()\n","\n","if DEVICE == \"GPU\":\n","    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n","    \n","\n","AUTO     = tf.data.experimental.AUTOTUNE\n","REPLICAS = strategy.num_replicas_in_sync\n","print(f'REPLICAS: {REPLICAS}')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# 動態申請顯存\n","config = tf.compat.v1.ConfigProto()\n","config.gpu_options.allow_growth = True\n","session = tf.compat.v1.Session(config=config)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["if not os.path.isdir(PROJECT_PATH+r'/models/'):\n","    os.makedirs(PROJECT_PATH+r'/models/')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# 3. 開發參數設定<a class=\"anchor\" id=\"3\"></a>\n","[Back to Table of Contents](#0)"]},{"metadata":{"trusted":true},"cell_type":"code","source":["'''客製參數設定'''\n","\n","\n","'''資料參數設定'''\n","\n","# (Int)分類數量\n","CLASSES = 3\n","\n","# (Int)如果訓練集TFRecord數目為15，FOLD設定必須整除，\n","# 例如3 or 5 or 15即5 or 3 or 1分層驗證，不可設定1，因為至少要分層。\n","FOLD = 3\n","\n","# (Int)圖片尺寸\n","IMAGE_SIZE = [224]*FOLD\n","\n","# (String)TFRecord圖片檔名欄位(不包含路徑)\n","TFRECORD_IMAGE_NAME = 'image_name'\n","\n","# (String)TFRecord標籤欄位\n","TFRECORD_LABEL_NAME = 'label'\n","\n","# (Boolean)是否顯示資料視覺化\n","DISPLAY_DATASET = False\n","\n","if DISPLAY_DATASET:\n","    # (Int)資料視覺化第幾折資料集\n","    DISPLAY_FOLD_DATASET = 1\n","\n","    # (Int)資料視覺化圖片SIZE\n","    DISPLAY_IMAGE_SIZE = 224\n","\n","    # (Int)資料視覺化圖片行數\n","    DISPLAY_IMAGE_COLUMN = 6\n","\n","    # (Int)資料視覺化圖片列數\n","    DISPLAY_IMAGE_ROW = 5\n","    \n","# (Int)不同的種子會產生不同的Random或分層K-FOLD分裂, 42則是預設固定種子\n","SEED = 42\n","\n","# (String)切分訓練集跟驗證集方式\n","SKF = KFold(n_splits = FOLD,shuffle = True,random_state = SEED)\n","\n","\n","'''資料擴增參數設定'''\n","\n","# (Float)隨機旋轉角度\n","ROT_ = 15.0\n","\n","# (Float)隨機錯切變換，效果就是讓所有點的x坐標(或者y坐標)保持不變，而對應的y坐標(或者x坐標)則按比例發生平移\n","SHR_ = 1.0\n","\n","# (Float)上下部隨機縮放範圍\n","HZOOM_ = 1.0\n","\n","# (Float)左右部隨機縮放範圍\n","WZOOM_ = 1.0\n","\n","# (Float)上下部隨機平移範圍\n","HSHIFT_ = 1.0\n","\n","# (Float)左右部部隨機平移範圍\n","WSHIFT_ = 1.0\n","    \n","# (Boolean)是否混合組合擴增圖片\n","MIXUP_AND_CUTMIX = False\n","\n","if MIXUP_AND_CUTMIX:\n","    # (Int)混合組合擴增圖片IMAGE_SIZE\n","    MIXUP_AND_CUTMIX_IMAGE_SIZE = 224\n","\n","    # (Int)混合組合擴增圖片BATCH_SIZE\n","    MIXUP_AND_CUTMIX_BATCH_SIZE = 32\n","\n","\n","''''模型參數設定'''\n","\n","# (Boolean)使用TF模型，如為False則須客制另外撰寫\n","USE_BASE_MODEL = True\n","\n","if USE_BASE_MODEL:\n","    # (Boolean)使用EFFICIENTNET模型\n","    USE_EFFICIENTNET_MODEL = True\n","    if USE_EFFICIENTNET_MODEL:\n","        # (Int List)使用哪一種EFFICIENTNET\n","        EFF_NET = [0]*FOLD\n","\n","        # (Model List)列出每種縮放尺寸的EFFICIENTNET\n","        BASE_MODEL = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n","                efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6, efn.EfficientNetB7]\n","    else:\n","        # (Model)建立TF模型\n","        BASE_MODEL = applications.MobileNetV2\n","\n","# (Boolean)是否使用TF權重\n","LOAD_TF_WEIGHTS = True\n","\n","if LOAD_TF_WEIGHTS:\n","    # (String)TF預訓練權重為 imagenet/noisy-student\n","    WEIGHTS = 'imagenet'\n","else:\n","    WEIGHTS = None\n","\n","# (Boolean)TF模型是否包含完全連接網路頂部的網路層\n","INCLUDE_TOP = False\n","    \n","# (Boolean)TF模型是否可訓練權重(不包括頂部網路層)\n","BASE_MODEL_TRAINABLE = True\n","\n","# (Boolean)是否載入客製權重\n","LOAD_WEIGHTS = False\n","    \n","# (Boolean)是否載入客製模型\n","LOAD_MODEL = False\n","\n","# (Float)Dropout比率 0.5\n","DROPOUT = 0.5\n","\n","# 最後輸出時的激活函數，雙分類為sigmoid，多分類為softmax\n","ACTIVATION_FUNCTION = 'softmax'\n","\n","# (Boolean)是否印出完整模型\n","MODEL_PRINT = False\n","\n","# (Boolean)是否儲存模型圖表\n","SAVE_MODEL_DIAGRAM = False\n","\n","if SAVE_MODEL_DIAGRAM:\n","    # (Boolean)是否儲存模型圖表網路形狀\n","    SAVE_MODEL_SHAPE = True\n","    \n","    # (String)儲存模型圖表完整檔名\n","    SAVE_MODEL_FILENAME = PROJECT_PATH+r'/models/'+MODEL_NAME+'.png'\n","    \n","    \n","''''回調函數參數設定'''\n","\n","# (Boolean)回調函數 ModelCheckpoint / ParallelModelCheckpoint 是否啟用\n","CALLBACKS_CHECK_POINTER = True\n","\n","# (Boolean)回調函數 EarlyStoppin 是否啟用\n","CALLBACKS_EARLY_STOPPING = False\n","\n","# (Boolean)回調函數 CSVLogger 是否啟用\n","CALLBACKS_CSV_LOGGER = False\n","\n","# (Boolean)回調函數 LearningRateScheduler 是否啟用\n","CALLBACKS_LR_SCHEDULER = True\n","\n","# (Boolean)回調函數 ReduceLROnPlateau 是否啟用\n","CALLBACKS_REDUCE_LR = True\n","\n","# (Boolean)回調函數 TensorBoard 是否啟用\n","CALLBACKS_TENSOR_BOARD = False\n","\n","# (String)回調函數監控數值 acc/val_acc/loss/val_loss\n","MONITOR = 'val_loss'\n","\n","# (Boolean)回調函數 ModelCheckpoint / ParallelModelCheckpoint 是否只儲存最佳模型 False\n","SAVE_BEST_ONLY = True\n","\n","# (Boolean)回調函數 ModelCheckpoint / ParallelModelCheckpoint 是否只儲存權重 False\n","SAVE_WEIGHTS_ONLY = False\n","\n","# (Int)回調函數 EarlyStopping 沒有改善的時期數，之後訓練將停止 10\n","PATIENCE_ELS = 10\n","\n","# (Boolean)回調函數 CSVLogger True為是否接下去原有CSV檔，False為覆蓋 \n","APPEND = True\n","\n","# (Float)回調函數 LearningRateSchedule 初始學習率 0.000003\n","LEARNING_RATE_START = 0.000003\n","\n","# (Float)回調函數 LearningRateSchedule 最大學習率 0.000020\n","LEARNING_RATE_MAX = 0.000020\n","\n","# (Float)回調函數 LearningRateSchedule 最小學習率 0.000001\n","LEARNING_RATE_MIN = 0.000001\n","\n","# (Float)回調函數 LearningRateSchedule 學習率多少時期後開始上升 5\n","LEARNING_RATE_RAMPUP_EPOCHS = 5\n","\n","# (Float)回調函數 LearningRateSchedule 學習率支撐時期 0\n","LEARNING_RATE_SUSTAIN_EPOCHS = 0\n","\n","# (Float)回調函數 LearningRateSchedule 學習率衰減 0.8\n","LEARNING_RATE_EXP_DECAY = 0.8\n","\n","# (Float)回調函數 ReduceLROnPlateau 被降低的因數。新的學習速率 = 學習速率 * 因數 0.2\n","FACTOR = 0.2\n","\n","# (Int)回調函數 ReduceLROnPlateau 沒有進步的訓練輪數，在這之後訓練速率會被降低 5 \n","PATIENCE_RLR = 5\n","\n","# (Float)回調函數 ReduceLROnPlateau 最小學習率 0\n","LEARNING_RATE_MIN_RLR = 0\n","\n","# (String)回調函數 TensorBoard 'batch'或'epoch'或整數。使用時'batch'，每批之後將損失和指標寫入TensorBoard\n","# 同樣適用於'epoch'。如果使用整數，假設1000，回調將每1000批將指標和損失寫入TensorBoard\n","UPDATE_FREQ = 'epoch'\n","\n","# (Boolean)回調函數 TensorBoard 是否在TensorBoard中可視化圖形。當write_graph設置為True時，日誌文件可能會變得很大\n","WRITE_GRAPH = True\n","\n","# (Int/String)回調函數 TensorBoard 分析批次以採樣計算特徵。profile_batch必須是非負整數或整數元組。一對正整數表示要分析的批次範圍\n","# 默認情況下，它將配置第二批。將profile_batch = 0設置為禁用分析 5 / '10,20'\n","PROFILE_BATCH = 5\n","\n","\n","''''編譯參數設定'''\n","\n","if not CALLBACKS_LR_SCHEDULER:\n","    # (Float)優化器學習率 1e-3/1e-1\n","    LEARNING_RATE = None\n","    \n","    # (Float)優化器權重衰減 5e-5/5e-4\n","    WEIGHT_DECAY = None\n","\n","# (Float)加速優化器在相關方向上前進，並抑制震盪 0.9\n","MOMENTUM = None\n","\n","# (Float)優化器模糊因子比率 1e-7\n","EPSILON = None\n","\n","# (String)優化器指定，None為客制，須另外撰寫\n","BASE_OPTIMIZERS = optimizers.Adam()\n","\n","# (Float)標籤平滑比率，將one-hot的編碼方式變得更加soft 0.1\n","LABEL_SMOOTHING = 0\n","\n","# (String)損失函數，None為客制，須另外撰寫 losses.CategoricalCrossentropy(label_smoothing = LABEL_SMOOTHING)\n","BASE_LOSSES = None\n","\n","# (Float)focusing parameter for modulating factor (1-p)\n","LOSSES_GAMMA = 2.\n","\n","# (Float)the same as weighing factor in balanced cross entropy\n","LOSSES_ALPHA = .25\n","\n","# (String List)評價指標，None為客制，須另外撰寫\n","BASE_METRICS = ['accuracy']\n","\n","# (String )評價指標的圖表顯示\n","PLOT_METRICS = 'accuracy'\n","\n","\n","''''訓練參數設定'''\n","\n","# (Int)每批訓練的尺寸\n","BATCH_SIZE = [32]*FOLD\n","\n","# (Int)訓練做幾次時代\n","EPOCHS = [24]*FOLD\n","\n","# (Int)從多少時代開始訓練\n","INITIAL_EPOCH = 0\n","\n","# (Int)日誌顯示，0為靜音，1為進度條，2為顯示每個紀錄\n","VERBOSE = 1\n","\n","\n","''''圖表參數設定'''\n","\n","# (Float)全部SNS圖表的字形縮放\n","ALL_SNS_FONT_SCALE = 1.0\n","\n","# (Int)CSV缺失值圖表寬度\n","CSV_COUNTPLOT_FIGSIZE_W = 10\n","\n","# (Int)CSV缺失值圖表高度\n","CSV_COUNTPLOT_FIGSIZE_H = 10\n","\n","# (Int)CSV缺失值圖表標題字型大小\n","CSV_COUNTPLOT_TITLE_FONTSIZE = 20\n","\n","# (Int)CSV缺失值圖表X軸標題字型大小\n","CSV_COUNTPLOT_XLABEL_FONTSIZE = 15\n","\n","# (Int)CSV缺失值圖表Y軸標題字型大小\n","CSV_COUNTPLOT_YLABEL_FONTSIZE = 15\n","\n","# (Int)訓練歷程圖表寬度\n","TRAINING_CURVES_FIGSIZE_W = 20\n","\n","# (Int)訓練歷程圖表高度\n","TRAINING_CURVES_FIGSIZE_H = 10\n","\n","# (Int)訓練歷程圖表SCATTER的標記點大小 \n","TRAINING_CURVES_SCATTER_SCALAR = 200\n","\n","# (Float)訓練歷程圖表SCATTER的指標文字離標記點X距離係數\n","TRAINING_CURVES_SCATTER_METRICS_TEXT_XSCALAR = 0.03\n","\n","# (Float)訓練歷程圖表SCATTER的指標文字標記點Y距離係數\n","TRAINING_CURVES_SCATTER_METRICS_TEXT_YSCALAR = 0.13\n","\n","# (Float)訓練歷程圖表SCATTER的損失文字標記點X距離係數\n","TRAINING_CURVES_SCATTER_LOSS_TEXT_XSCALAR = 0.03\n","\n","# (Float)訓練歷程圖表SCATTER的損失文字標記點Y距離係數\n","TRAINING_CURVES_SCATTER_LOSS_TEXT_YSCALAR = 0.05\n","\n","# (Int)訓練歷程圖表SCATTER的文字大小\n","TRAINING_CURVES_SCATTER_TEXTSIZE = 15\n","\n","# (Int)訓練歷程圖表X軸標題字型大小\n","TRAINING_CURVES_XLABEL_FONTSIZE = 15\n","\n","# (Int)訓練歷程圖表Y軸標題字型大小\n","TRAINING_CURVES_YLABEL_FONTSIZE = 15\n","\n","# (Int)訓練歷程圖表標題字型大小\n","TRAINING_CURVES_TITLE_FONTSIZE = 20\n","\n","# (Float)訓練歷程圖表格線粗度\n","TRAINING_CURVES_GRID_ALPHA = 0\n","\n","# (Int)混淆矩陣圖表寬度\n","CONFUSION_MATRIX_FIGSIZE_W = 10\n","\n","# (Int)混淆矩陣圖表高度\n","CONFUSION_MATRIX_FIGSIZE_H = 10\n","\n","# (Int)混淆矩陣圖表內容字型大小\n","CONFUSION_MATRIX_HEATMAP_FONTSIZE = 15\n","\n","# (Int)混淆矩陣圖表標題字型大小\n","CONFUSION_MATRIX_TITLE_FONTSIZE = 20\n","\n","# (Int)混淆矩陣圖表X軸標題字型大小\n","CONFUSION_MATRIX_XLABEL_FONTSIZE = 15\n","\n","# (Int)混淆矩陣圖表Y軸標題字型大小\n","CONFUSION_MATRIX_YLABEL_FONTSIZE = 15\n","\n","# (String)預設'binary'：僅在目標為二進制，兩分類時適用。\n","#'micro'：通過計算總的真陽性，假陰性和假陽性來全局計算指標，多分類時適用。\n","#'macro'：計算每個標籤的指標，並找到其未加權平均值。這沒有考慮標籤不平衡，多分類時適用。\n","AVERAGE = 'macro'"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","    \n","seed_everything(SEED)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# 設置sns圖表縮放係數\n","sns.set(font_scale = ALL_SNS_FONT_SCALE)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["if DISPLAY_DATASET:\n","    # 因實際折數從零開始\n","    DISPLAY_FOLD_DATASET = DISPLAY_FOLD_DATASET-1"],"execution_count":null,"outputs":[]},{"metadata":{"id":"UIMDkuytky4t"},"cell_type":"markdown","source":["# 4. 資料處理<a class=\"anchor\" id=\"4\"></a>\n","[Back to Table of Contents](#0)"]},{"metadata":{},"cell_type":"markdown","source":["## 4.1 載入資料集 <a class=\"anchor\" id=\"4.1\"></a>\n","[Back to Table of Contents](#0)"]},{"metadata":{"trusted":true},"cell_type":"code","source":["GCS_PATH = [None]*FOLD; GCS_PATH2 = [None]*FOLD\n","for i,k in enumerate(IMAGE_SIZE):\n","    if TFRECORD_FILENAME_IPIXEL:\n","        GCS_PATH[i] = KaggleDatasets().get_gcs_path(TFRECORD_GCS_PATH+'-%ix%i'%(k,k))\n","    else:\n","        GCS_PATH[i] = KaggleDatasets().get_gcs_path(TFRECORD_GCS_PATH)\n","files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))\n","files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))\n","files_train_length = len(files_train)\n","files_test_length = len(files_test)\n","print('Train TFRecord Counts : '+str(files_train_length))\n","print('Test TFRecord Counts : '+str(files_test_length))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["files_train"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["files_test"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 4.2 定義資料集生成方法 <a class=\"anchor\" id=\"4.2\"></a>\n","[Back to Table of Contents](#0)"]},{"metadata":{"trusted":true},"cell_type":"code","source":["def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n","    # returns 3x3 transformmatrix which transforms indicies\n","        \n","    # CONVERT DEGREES TO RADIANS\n","    rotation = math.pi * rotation / 180.\n","    shear = math.pi * shear / 180.\n","\n","    def get_3x3_mat(lst):\n","        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n","    \n","    # ROTATION MATRIX\n","    c1   = tf.math.cos(rotation)\n","    s1   = tf.math.sin(rotation)\n","    one  = tf.constant([1],dtype='float32')\n","    zero = tf.constant([0],dtype='float32')\n","    \n","    rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n","                                   -s1,  c1,   zero, \n","                                   zero, zero, one])    \n","    # SHEAR MATRIX\n","    c2 = tf.math.cos(shear)\n","    s2 = tf.math.sin(shear)    \n","    \n","    shear_matrix = get_3x3_mat([one,  s2,   zero, \n","                                zero, c2,   zero, \n","                                zero, zero, one])        \n","    # ZOOM MATRIX\n","    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero, \n","                               zero,            one/width_zoom, zero, \n","                               zero,            zero,           one])    \n","    # SHIFT MATRIX\n","    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n","                                zero, one,  width_shift, \n","                                zero, zero, one])\n","    \n","    return K.dot(K.dot(rotation_matrix, shear_matrix), \n","                 K.dot(zoom_matrix,     shift_matrix))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def transform(image, dim=256):    \n","    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n","    # output - image randomly rotated, sheared, zoomed, and shifted\n","    xdim = dim%2 #fix for size 331\n","    \n","    rot = ROT_ * tf.random.normal([1], dtype='float32')\n","    shr = SHR_ * tf.random.normal([1], dtype='float32') \n","    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / HZOOM_\n","    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / WZOOM_\n","    h_shift = HSHIFT_ * tf.random.normal([1], dtype='float32') \n","    w_shift = WSHIFT_ * tf.random.normal([1], dtype='float32') \n","\n","    # GET TRANSFORMATION MATRIX\n","    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n","\n","    # LIST DESTINATION PIXEL INDICES\n","    x   = tf.repeat(tf.range(dim//2, -dim//2,-1), dim)\n","    y   = tf.tile(tf.range(-dim//2, dim//2), [dim])\n","    z   = tf.ones([dim*dim], dtype='int32')\n","    idx = tf.stack( [x,y,z] )\n","    \n","    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n","    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n","    idx2 = K.cast(idx2, dtype='int32')\n","    idx2 = K.clip(idx2, -dim//2+xdim+1, dim//2)\n","    \n","    # FIND ORIGIN PIXEL VALUES           \n","    idx3 = tf.stack([dim//2-idx2[0,], dim//2-1+idx2[1,]])\n","    d    = tf.gather_nd(image, tf.transpose(idx3))\n","        \n","    return tf.reshape(d,[dim, dim,3])"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def read_labeled_tfrecord(example):\n","    tfrec_format = {\n","        'image'                        : tf.io.FixedLenFeature([], tf.string),\n","        TFRECORD_IMAGE_NAME            : tf.io.FixedLenFeature([], tf.string),\n","        TFRECORD_LABEL_NAME            : tf.io.FixedLenFeature([], tf.int64)\n","    }           \n","    example = tf.io.parse_single_example(example, tfrec_format)       \n","    return example['image'], example[TFRECORD_LABEL_NAME]"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def read_unlabeled_tfrecord(example, return_image_name):\n","    tfrec_format = {\n","        'image'                        : tf.io.FixedLenFeature([], tf.string),\n","        TFRECORD_IMAGE_NAME            : tf.io.FixedLenFeature([], tf.string),\n","    }\n","    example = tf.io.parse_single_example(example, tfrec_format)      \n","    return example['image'], example[TFRECORD_IMAGE_NAME] if return_image_name else 0"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def prepare_image(img, augment=True, dim=256):\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.resize(img, [dim, dim])\n","    img = tf.cast(img, tf.float32) / 255.0 # # Cast and normalize the image to [0,1]\n","    \n","    if augment:\n","        # Data augmentation\n","        img = transform(img,dim=dim)\n","        # Other augmentations\n","        img = tf.image.random_flip_left_right(img)\n","        img = tf.image.random_hue(img, 0.01)\n","        img = tf.image.random_saturation(img, 0.7, 1.3)\n","        img = tf.image.random_contrast(img, 0.8, 1.2)\n","        img = tf.image.random_brightness(img, 0.1)\n","    \n","    img = tf.image.resize(img, [dim, dim])\n","    img = tf.reshape(img, [dim,dim, 3])\n","    return img"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# function to count how many photos we have in\n","def count_data_items(filenames):\n","    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n","    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n","    return np.sum(n)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def mixup(image, label, PROBABILITY = 1.0):\n","    DIM = MIXUP_AND_CUTMIX_IMAGE_SIZE\n","    BATCH_SIZE = MIXUP_AND_CUTMIX_BATCH_SIZE\n","    \n","    imgs = []; labs = []\n","    for j in range(BATCH_SIZE):\n","\n","        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n","\n","        k = tf.cast( tf.random.uniform([],0,BATCH_SIZE),tf.int32)\n","        a = tf.random.uniform([],0,1)*P # this is beta dist with alpha=1.0\n","\n","        img1 = image[j,]\n","        img2 = image[k,]\n","        imgs.append((1-a)*img1 + a*img2)\n","\n","        if len(label.shape)==1:\n","            lab1 = tf.one_hot(label[j],CLASSES)\n","            lab2 = tf.one_hot(label[k],CLASSES)\n","        else:\n","            lab1 = label[j,]\n","            lab2 = label[k,]\n","        labs.append((1-a)*lab1 + a*lab2)\n","\n","    image2 = tf.reshape(tf.stack(imgs),(BATCH_SIZE,DIM,DIM,3))\n","    label2 = tf.reshape(tf.stack(labs),(BATCH_SIZE,CLASSES))\n","    return image2,label2"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def cutmix(image, label, PROBABILITY = 1.0):\n","    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n","    # output - a batch of images with cutmix applied\n","    DIM = MIXUP_AND_CUTMIX_IMAGE_SIZE\n","    BATCH_SIZE = MIXUP_AND_CUTMIX_BATCH_SIZE\n","    \n","    imgs = []; labs = []\n","    for j in range(BATCH_SIZE):\n","\n","        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.int32)\n","\n","        k = tf.cast( tf.random.uniform([],0,BATCH_SIZE),tf.int32)\n","\n","        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n","        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n","        b = tf.random.uniform([],0,1) # this is beta dist with alpha=1.0\n","        WIDTH = tf.cast( DIM * tf.math.sqrt(1-b),tf.int32) * P\n","        ya = tf.math.maximum(0,y-WIDTH//2)\n","        yb = tf.math.minimum(DIM,y+WIDTH//2)\n","        xa = tf.math.maximum(0,x-WIDTH//2)\n","        xb = tf.math.minimum(DIM,x+WIDTH//2)\n","\n","        one = image[j,ya:yb,0:xa,:]\n","        two = image[k,ya:yb,xa:xb,:]\n","        three = image[j,ya:yb,xb:DIM,:]\n","        middle = tf.concat([one,two,three],axis=1)\n","        img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM,:,:]],axis=0)\n","        imgs.append(img)\n","\n","        a = tf.cast(WIDTH*WIDTH/DIM/DIM,tf.float32)\n","        if len(label.shape)==1:\n","            lab1 = tf.one_hot(label[j],CLASSES)\n","            lab2 = tf.one_hot(label[k],CLASSES)\n","        else:\n","            lab1 = label[j,]\n","            lab2 = label[k,]\n","        labs.append((1-a)*lab1 + a*lab2)\n","        \n","    image2 = tf.reshape(tf.stack(imgs),(BATCH_SIZE,DIM,DIM,3))\n","    label2 = tf.reshape(tf.stack(labs),(BATCH_SIZE,CLASSES))\n","    return image2,label2"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["#create function to apply both cutmix and mixup\n","def mixup_and_cutmix(image,label):\n","    DIM = MIXUP_AND_CUTMIX_IMAGE_SIZE\n","    BATCH_SIZE = MIXUP_AND_CUTMIX_BATCH_SIZE\n","    \n","    #define how often we want to do activate cutmix or mixup\n","    SWITCH = 1/2\n","    \n","    #define how often we want cutmix or mixup to activate when switch is active\n","    CUTMIX_PROB = 2/3\n","    MIXUP_PROB = 2/3\n","    \n","    #apply cutmix and mixup\n","    image2, label2 = cutmix(image, label, CUTMIX_PROB)\n","    image3, label3 = mixup(image, label, MIXUP_PROB)\n","    imgs = []; labs = []\n","    \n","    for j in range(BATCH_SIZE):\n","        P = tf.cast( tf.random.uniform([],0,1)<=SWITCH, tf.float32)\n","        imgs.append(P*image2[j,]+(1-P)*image3[j,])\n","        labs.append(P*label2[j,]+(1-P)*label3[j,])\n","        \n","    #must explicitly reshape so TPU complier knows output shape\n","    image4 = tf.reshape(tf.stack(imgs),(BATCH_SIZE,DIM,DIM,3))\n","    label4 = tf.reshape(tf.stack(labs),(BATCH_SIZE,CLASSES))\n","    return image4,label4"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def get_dataset(files, augment = False, cutmix_aug = False, shuffle = False, repeat = False\n","                , labeled=True, return_image_names=True, batch_size=16, dim=256):\n","    \n","    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n","    ds = ds.cache()\n","    \n","    if repeat:\n","        ds = ds.repeat()\n","    \n","    if shuffle:\n","        ds = ds.shuffle(2048 * REPLICAS)\n","        opt = tf.data.Options()\n","        opt.experimental_deterministic = False\n","        ds = ds.with_options(opt)\n","      \n","    if labeled:\n","        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n","    else:\n","        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_names), num_parallel_calls=AUTO)      \n","    \n","    ds = ds.map(lambda img, imgname_or_label: (prepare_image(img, augment=augment, dim=dim),imgname_or_label), num_parallel_calls=AUTO)\n","    \n","    if cutmix_aug:\n","        #need to batch to use CutMix/mixup\n","        ds = ds.batch(batch_size * REPLICAS)\n","        ds = ds.map(mixup_and_cutmix, num_parallel_calls=AUTO) # note we put AFTER batching\n","        \n","        #now unbatch and shuffle before re-batching\n","        ds = ds.unbatch()\n","#         ds = ds.shuffle(2048 * REPLICAS)\n","        \n","    ds = ds.batch(batch_size * REPLICAS)\n","    ds = ds.prefetch(AUTO)\n","    return ds"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def show_dataset(thumb_size, cols, rows, ds):\n","    mosaic = PIL.Image.new(mode='RGB', size=(thumb_size*cols + (cols-1), thumb_size*rows + (rows-1)))\n","   \n","    for idx, data in enumerate(iter(ds)):\n","        img, target_or_imgid = data\n","        ix  = idx % cols\n","        iy  = idx // cols\n","        img = np.clip(img.numpy() * 255, 0, 255).astype(np.uint8)\n","        img = PIL.Image.fromarray(img)\n","        img = img.resize((thumb_size, thumb_size), resample=PIL.Image.BILINEAR)\n","        mosaic.paste(img, (ix*thumb_size + ix, \n","                           iy*thumb_size + iy))\n","\n","    display(mosaic)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# 5. 資料視覺化<a class=\"anchor\" id=\"5\"></a>\n","[Back to Table of Contents](#0)"]},{"metadata":{"trusted":true},"cell_type":"code","source":["num_training_images = int(count_data_items(files_train))\n","num_test_images = count_data_items(files_test)\n","print('Dataset: {} training images, {} unlabeled test images'.format(num_training_images, num_test_images))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":["# Train Data\n","if DISPLAY_DATASET:\n","    training_dataset = get_dataset(files_train, shuffle = True, batch_size=BATCH_SIZE[DISPLAY_FOLD_DATASET], \n","                                   dim=IMAGE_SIZE[DISPLAY_FOLD_DATASET]).unbatch().take(DISPLAY_IMAGE_COLUMN*DISPLAY_IMAGE_ROW)\n","    show_dataset(DISPLAY_IMAGE_SIZE, DISPLAY_IMAGE_COLUMN, DISPLAY_IMAGE_ROW, training_dataset)"],"execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":["# Train Data With Image Augmentation\n","if DISPLAY_DATASET:\n","    image_augmentation_dataset = get_dataset(files_train, augment= True, shuffle = True, batch_size=BATCH_SIZE[DISPLAY_FOLD_DATASET], \n","                                    dim=IMAGE_SIZE[DISPLAY_FOLD_DATASET]).unbatch().take(DISPLAY_IMAGE_COLUMN*DISPLAY_IMAGE_ROW)\n","    show_dataset(DISPLAY_IMAGE_SIZE, DISPLAY_IMAGE_COLUMN, DISPLAY_IMAGE_ROW, image_augmentation_dataset)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Train Data With Mixup And Cutmix\n","if DISPLAY_DATASET:\n","    if MIXUP_AND_CUTMIX:\n","        training_dataset_mixup_and_cutmix = get_dataset(files_train, cutmix_aug = MIXUP_AND_CUTMIX, shuffle = True, batch_size=BATCH_SIZE[DISPLAY_FOLD_DATASET], \n","                                       dim=IMAGE_SIZE[DISPLAY_FOLD_DATASET]).unbatch().take(DISPLAY_IMAGE_COLUMN*DISPLAY_IMAGE_ROW)\n","        show_dataset(DISPLAY_IMAGE_SIZE, DISPLAY_IMAGE_COLUMN, DISPLAY_IMAGE_ROW, training_dataset_mixup_and_cutmix)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Test Data\n","if DISPLAY_DATASET:\n","    test_dataset = get_dataset(files_test, shuffle = True, labeled=False, batch_size=BATCH_SIZE[DISPLAY_FOLD_DATASET], dim=IMAGE_SIZE[DISPLAY_FOLD_DATASET]).unbatch().take(12*5)\n","    show_dataset(DISPLAY_IMAGE_SIZE, DISPLAY_IMAGE_COLUMN, DISPLAY_IMAGE_ROW, test_dataset)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["del files_train\n","if DISPLAY_DATASET:\n","    del training_dataset, test_dataset, image_augmentation_dataset\n","    if MIXUP_AND_CUTMIX:\n","        del training_dataset_mixup_and_cutmix\n","K.clear_session()\n","gc.collect()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# 6. 定義模型方法<a class=\"anchor\" id=\"6\"></a>\n","[Back to Table of Contents](#0)"]},{"metadata":{"trusted":true},"cell_type":"code","source":["def binary_focal_loss(gamma=2., alpha=.25):\n","    \"\"\"\n","    Binary form of focal loss.\n","      FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n","      where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n","    References:\n","        https://arxiv.org/pdf/1708.02002.pdf\n","    Usage:\n","     model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n","    \"\"\"\n","    def binary_focal_loss_fixed(y_true, y_pred):\n","        \"\"\"\n","        :param y_true: A tensor of the same shape as `y_pred`\n","        :param y_pred:  A tensor resulting from a sigmoid\n","        :return: Output tensor.\n","        \"\"\"\n","        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n","        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n","\n","        epsilon = K.epsilon()\n","        # clip to prevent NaN's and Inf's\n","        pt_1 = K.clip(pt_1, epsilon, 1. - epsilon)\n","        pt_0 = K.clip(pt_0, epsilon, 1. - epsilon)\n","\n","        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) \\\n","               -K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n","\n","    return binary_focal_loss_fixed\n","\n","\n","def categorical_focal_loss(gamma=2., alpha=.25):\n","    \"\"\"\n","    Softmax version of focal loss.\n","           m\n","      FL = ∑  -alpha * (1 - p_o,c)^gamma * y_o,c * log(p_o,c)\n","          c=1\n","      where m = number of classes, c = class and o = observation\n","    Parameters:\n","      alpha -- the same as weighing factor in balanced cross entropy\n","      gamma -- focusing parameter for modulating factor (1-p)\n","    Default value:\n","      gamma -- 2.0 as mentioned in the paper\n","      alpha -- 0.25 as mentioned in the paper\n","    References:\n","        Official paper: https://arxiv.org/pdf/1708.02002.pdf\n","        https://www.tensorflow.org/api_docs/python/tf/keras/backend/categorical_crossentropy\n","    Usage:\n","     model.compile(loss=[categorical_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n","    \"\"\"\n","    def categorical_focal_loss_fixed(y_true, y_pred):\n","        \"\"\"\n","        :param y_true: A tensor of the same shape as `y_pred`\n","        :param y_pred: A tensor resulting from a softmax\n","        :return: Output tensor.\n","        \"\"\"\n","\n","        # Scale predictions so that the class probas of each sample sum to 1\n","        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n","\n","        # Clip the prediction value to prevent NaN's and Inf's\n","        epsilon = K.epsilon()\n","        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n","\n","        # Calculate Cross Entropy\n","        cross_entropy = -y_true * K.log(y_pred)\n","\n","        # Calculate Focal Loss\n","        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n","\n","        # Sum the losses in mini_batch\n","        return K.sum(loss, axis=1)\n","\n","    return categorical_focal_loss_fixed"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def build_optimizers():\n","    if BASE_OPTIMIZERS == None:\n","        print(\"Custiom OPTIMIZERS\")\n","    else:\n","        RETURN_OPTIMIZERS = BASE_OPTIMIZERS\n","    return RETURN_OPTIMIZERS\n","\n","optimizer = build_optimizers()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def build_metrics():\n","    if BASE_METRICS == None:\n","        print(\"Custiom METRICS\")\n","    else:\n","        RETURN_METRICS = BASE_METRICS\n","    return RETURN_METRICS\n","\n","metrics = build_metrics()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def build_losses():\n","    if BASE_LOSSES == None:\n","        if CLASSES == 2:\n","            RETURN_LOSSES = binary_focal_loss(gamma = LOSSES_GAMMA, alpha = LOSSES_ALPHA)\n","        else:\n","            RETURN_LOSSES = categorical_focal_loss(gamma = LOSSES_GAMMA, alpha = LOSSES_ALPHA)\n","        print(\"Custiom LOSSES\")\n","    else:\n","        RETURN_LOSSES = BASE_LOSSES\n","    return RETURN_LOSSES\n","\n","loss = build_losses()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def build_model(dim = 256, fold = 0):\n","    if LOAD_MODEL:\n","        print(\"Reading the pre-trained model... \")\n","        model = keras.models.load_model(LOAD_MODEL_PATH)\n","        print(\"Reading done. \")\n","    else:\n","        if USE_BASE_MODEL:\n","            if USE_EFFICIENTNET_MODEL:\n","                base_model = BASE_MODEL[EFF_NET[fold]](input_shape=(dim,dim,3), include_top=INCLUDE_TOP, weights=WEIGHTS)\n","                for layer in base_model.layers:\n","                    layer.trainable = BASE_MODEL_TRAINABLE\n","                inputs = base_model.inputs[0]\n","                outputs = base_model.outputs[0]\n","                x = layers.AveragePooling2D(name=\"averagepooling2d_head\")(outputs)\n","                x = layers.Flatten(name=\"flatten_head\")(x)\n","                x = layers.Dense(64, activation=\"relu\", name=\"dense_head\")(x)\n","                x = layers.Dropout(DROPOUT, name=\"dropout_head\")(x)\n","            else:\n","                base_model = BASE_MODEL(input_shape =(dim, dim, 3), include_top=INCLUDE_TOP, weights=WEIGHTS)\n","                for layer in base_model.layers:\n","                    layer.trainable = BASE_MODEL_TRAINABLE\n","                inputs = base_model.inputs[0]\n","                outputs = base_model.outputs[0]\n","                x = layers.GlobalAveragePooling2D(name=\"globalaveragepooling2d_head\")(outputs)\n","                x = layers.Dropout(DROPOUT, name=\"dropout_head\")(x)\n","        else:\n","            print(\"Custiom Model\")\n","        outputs = layers.Dense(CLASSES, activation=ACTIVATION_FUNCTION, name=\"predictions_head\")(x)    \n","        model = Model(inputs, outputs)\n","        model.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n","\n","        if MODEL_PRINT:\n","            model.summary()\n","        if SAVE_MODEL_DIAGRAM:\n","            plot_model(model, show_shapes= SAVE_MODEL_SHAPE, to_file=SAVE_MODEL_FILENAME)\n","\n","        if LOAD_WEIGHTS :\n","            print(\"Reading the pre-trained weights... \")\n","            model.load_weights(LOAD_WEIGHTS_PATH)\n","            print(\"Reading done. \")\n","    return model"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# 7. 定義回調函數方法<a class=\"anchor\" id=\"7\"></a>\n","[Back to Table of Contents](#0)"]},{"metadata":{"trusted":true},"cell_type":"code","source":["def get_callbacks(checkpointpath):\n","    check_pointer = callbacks.ModelCheckpoint(filepath = checkpointpath, monitor = MONITOR, verbose = VERBOSE, \n","                                              save_best_only = SAVE_BEST_ONLY)\n","\n","    # Interrupt the training when the validation loss is not decreasing\n","    early_stopping = callbacks.EarlyStopping(monitor = MONITOR, verbose = VERBOSE, patience = PATIENCE_ELS)\n","\n","    # Stream each epoch results into a .csv file\n","    csv_logger = callbacks.CSVLogger(CSV_SAVE_PATH, separator = ',', append = APPEND)\n","\n","    # LEARNING RATE SCHEDULER\n","    def get_lr_callback():\n","        def lrfn(epoch):\n","            if epoch < LEARNING_RATE_RAMPUP_EPOCHS:\n","                lr = (LEARNING_RATE_MAX - LEARNING_RATE_START) / LEARNING_RATE_RAMPUP_EPOCHS * epoch + LEARNING_RATE_START\n","\n","            elif epoch < LEARNING_RATE_RAMPUP_EPOCHS + LEARNING_RATE_SUSTAIN_EPOCHS:\n","                lr = LEARNING_RATE_MAX\n","\n","            else:\n","                lr = (LEARNING_RATE_MAX - LEARNING_RATE_MIN) * LEARNING_RATE_EXP_DECAY**(epoch - LEARNING_RATE_RAMPUP_EPOCHS - LEARNING_RATE_SUSTAIN_EPOCHS) + LEARNING_RATE_MIN\n","\n","            return lr\n","\n","        lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=VERBOSE)\n","        return lr_callback\n","\n","    lr_scheduler = get_lr_callback()\n","\n","    # Reduce learning rate when a metric has stopped improving\n","    reduce_lr = callbacks.ReduceLROnPlateau(monitor = MONITOR, verbose = VERBOSE, factor = FACTOR, patience = PATIENCE_RLR, \n","                                  min_lr = LEARNING_RATE_MIN_RLR)\n","\n","    tensor_board = callbacks.TensorBoard(log_dir = TENSORBOARD_LOGS_PATH, update_freq = UPDATE_FREQ, write_graph = WRITE_GRAPH, \n","                               profile_batch = PROFILE_BATCH)\n","\n","    callbacks_list = []\n","    if CALLBACKS_CHECK_POINTER:\n","        callbacks_list.append(check_pointer)\n","    if CALLBACKS_EARLY_STOPPING:\n","        callbacks_list.append(early_stopping)\n","    if CALLBACKS_CSV_LOGGER:\n","        callbacks_list.append(csv_logger)\n","    if CALLBACKS_LR_SCHEDULER:\n","        callbacks_list.append(lr_scheduler)\n","    if CALLBACKS_REDUCE_LR:\n","        callbacks_list.append(reduce_lr)\n","    if CALLBACKS_TENSOR_BOARD:\n","        callbacks_list.append(tensor_board)\n","    \n","    return callbacks_list"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# 8. 製作資料集＆資料擴增&訓練模型<a class=\"anchor\" id=\"8\"></a>\n","[Back to Table of Contents](#0)"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# 宣告為訓練後預測用\n","all_labels = []; all_pred = []"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def display_training_curves(history, fold):\n","    plt.figure(figsize=(TRAINING_CURVES_FIGSIZE_W,TRAINING_CURVES_FIGSIZE_H))\n","    plt.plot(np.arange(EPOCHS[fold]),history.history[PLOT_METRICS],'-o',label='TRAIN '+PLOT_METRICS.upper(),color='#ff7f0e')\n","    plt.plot(np.arange(EPOCHS[fold]),history.history['val_'+PLOT_METRICS],'-o',label='VALIDATION '+PLOT_METRICS.upper(),color='#1f77b4')\n","    x = np.argmax( history.history['val_'+PLOT_METRICS] ); y = np.max( history.history['val_'+PLOT_METRICS] )\n","    xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n","    plt.scatter(x,y,s=TRAINING_CURVES_SCATTER_SCALAR,color='#1f77b4')\n","    plt.text(x-TRAINING_CURVES_SCATTER_METRICS_TEXT_XSCALAR*xdist,y-TRAINING_CURVES_SCATTER_METRICS_TEXT_YSCALAR*ydist,'max '+PLOT_METRICS+'\\n%.4f'%y,size=TRAINING_CURVES_SCATTER_TEXTSIZE)\n","    plt.ylabel(PLOT_METRICS.upper(),size=TRAINING_CURVES_YLABEL_FONTSIZE); plt.xlabel('EPOCH',size=TRAINING_CURVES_XLABEL_FONTSIZE)\n","    plt.grid(alpha=TRAINING_CURVES_GRID_ALPHA)\n","    plt.legend(loc=2)\n","    plt2 = plt.gca().twinx()\n","    plt2.plot(np.arange(EPOCHS[fold]),history.history['loss'],'-o',label='TRAIN LOSS',color='#2ca02c')\n","    plt2.plot(np.arange(EPOCHS[fold]),history.history['val_loss'],'-o',label='VALIDATION LOSS',color='#d62728')\n","    x = np.argmin( history.history['val_loss'] ); y = np.min( history.history['val_loss'] )\n","    ydist = plt.ylim()[1] - plt.ylim()[0]\n","    plt.scatter(x,y,s=TRAINING_CURVES_SCATTER_SCALAR,color='#d62728')\n","    plt.text(x-TRAINING_CURVES_SCATTER_LOSS_TEXT_XSCALAR*xdist,y+TRAINING_CURVES_SCATTER_LOSS_TEXT_YSCALAR*ydist,'min loss\\n%.4f'%y,size=TRAINING_CURVES_SCATTER_TEXTSIZE)\n","    plt.ylabel('LOSS',size=TRAINING_CURVES_YLABEL_FONTSIZE)\n","    if FOLD != 1:\n","        plt.title('FOLD %i - IMAGE SIZE %i, %s'%\n","                  (fold+1, IMAGE_SIZE[fold], MODEL_NAME.upper()), size=TRAINING_CURVES_TITLE_FONTSIZE)\n","    else:\n","        plt.title(' IMAGE SIZE %i, %s'%\n","                  (IMAGE_SIZE[fold], MODEL_NAME.upper()), size=TRAINING_CURVES_TITLE_FONTSIZE)\n","    plt.grid(alpha=TRAINING_CURVES_GRID_ALPHA)\n","    plt.legend(loc=3)\n","    plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def train_process(fold, train_index, val_index):\n","    print('FOLD %i - IMAGE SIZE %i WITH %s AND BATCH_SIZE %i'%\n","          (fold+1,IMAGE_SIZE[fold],MODEL_NAME.upper(),BATCH_SIZE[fold]*REPLICAS))\n","        \n","    # CREATE TRAIN AND VALIDATION SUBSETS\n","    files_train = tf.io.gfile.glob([GCS_PATH[fold] + '/train%.2i*.tfrec'%x for x in train_index])\n","    np.random.shuffle(files_train)\n","    files_valid = tf.io.gfile.glob([GCS_PATH[fold] + '/train%.2i*.tfrec'%x for x in val_index])\n","        \n","    training_dataset = get_dataset(files_train, augment=True, shuffle=True, repeat=True, batch_size=BATCH_SIZE[fold], dim=IMAGE_SIZE[fold])\n","    validation_dataset = get_dataset(files_valid, augment=False,shuffle=False, repeat=False, batch_size=BATCH_SIZE[fold], dim=IMAGE_SIZE[fold])\n","        \n","    NUM_TRAIN_IMAGES = count_data_items(files_train)\n","    NUM_VALID_IMAGES = count_data_items(files_valid)\n","    NUM_TEST_IMAGES = count_data_items(files_test)\n","    print('TRAIN FILES COUNT : '+str(NUM_TRAIN_IMAGES))\n","    print('VALID FILES COUNT : '+str(NUM_VALID_IMAGES))\n","    print('TEST FILES COUNT : '+str(NUM_TEST_IMAGES))\n","        \n","    # (Int)聲明一個紀元完成並開始下一個紀元之前的總步數(一批樣品)\n","    STEPS_PER_EPOCH = tf.math.ceil(NUM_TRAIN_IMAGES/BATCH_SIZE[fold]/REPLICAS)\n","    # (Int)在每個時期結束時執行驗證時，在停止之前要繪製的步驟總數(樣本批次)\n","    VALIDATION_STEPS = tf.math.ceil(NUM_VALID_IMAGES/BATCH_SIZE[fold]/REPLICAS)\n","    print(\"Number of training and validation steps: {} and {}\".format(STEPS_PER_EPOCH,VALIDATION_STEPS))\n","     \n","    # BUILD MODEL\n","    K.clear_session()\n","    with strategy.scope():\n","        model = build_model(dim = IMAGE_SIZE[fold], fold = fold)\n","     \n","    # (String)訓練模型FOLD>1的儲存路徑\n","    SAVE_MODEL_PATH = PROJECT_PATH+r'/models/'+MODEL_NAME+'_fold_%i.h5'%(fold+1)\n","     \n","    print('Training...')\n","    history = model.fit(\n","        training_dataset, \n","        steps_per_epoch = STEPS_PER_EPOCH, \n","        epochs = EPOCHS[fold], \n","        callbacks = get_callbacks(checkpointpath = SAVE_MODEL_PATH), \n","        validation_data = validation_dataset, \n","        validation_steps = VALIDATION_STEPS,\n","        verbose = VERBOSE, \n","        initial_epoch = INITIAL_EPOCH)\n","    print('Training done!')\n","    \n","    if CALLBACKS_CHECK_POINTER:\n","        model.load_weights(TRAIN_MODEL_PATH)\n","    else:\n","        model.save(TRAIN_MODEL_PATH)\n","        \n","    display_training_curves(history, fold)\n","    \n","    images_ds = validation_dataset.map(lambda image, label: image)\n","    labels_ds = validation_dataset.map(lambda image, label: label).unbatch()\n","    all_labels.append( next(iter(labels_ds.batch(NUM_VALID_IMAGES))).numpy() ) # get everything as one batch\n","    all_pred.append(np.argmax(model.predict(images_ds), axis = -1))\n","    \n","    del files_train, files_valid\n","    del model\n","    del training_dataset, validation_dataset, history\n","    del images_ds, labels_ds\n","    K.clear_session()\n","    gc.collect()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["%%time\n","for fold,(train_index,val_index) in enumerate(SKF.split(np.arange(files_train_length))): \n","    train_process(fold = fold, train_index = train_index, val_index = val_index)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# 9. 混淆矩陣<a class=\"anchor\" id=\"9\"></a>\n","[Back to Table of Contents](#0)"]},{"metadata":{"trusted":true},"cell_type":"code","source":["cm_correct_labels = np.concatenate(all_labels)\n","cm_predictions = np.concatenate(all_pred)\n","print(\"Correct   labels: \", cm_correct_labels.shape, cm_correct_labels)\n","print(\"Predicted labels: \", cm_predictions.shape, cm_predictions)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["'''混淆矩陣包含四個要素:TP(True Positive)正確預測成功的正樣本, TN(True Negative)正確預測成功的負樣本, \n","FP(False Positive)錯誤預測成正樣本，實際上為負樣本, FN(False Negative)錯誤預測成負樣本(或者說沒能預測出來的正樣本)'''\n","cm = tf.math.confusion_matrix(cm_correct_labels, cm_predictions)\n","cm = cm/cm.numpy().sum(axis=1)[:, tf.newaxis]\n","\n","f,ax = plt.subplots(figsize = (CONFUSION_MATRIX_FIGSIZE_W, CONFUSION_MATRIX_FIGSIZE_H))\n","sns.heatmap(cm, annot = True, ax = ax, annot_kws={\"size\": CONFUSION_MATRIX_HEATMAP_FONTSIZE})\n","plt.title(\"CONFUSION MATRIX\", fontsize=CONFUSION_MATRIX_TITLE_FONTSIZE)\n","plt.xlabel(\"PREDICTED\", fontsize=CONFUSION_MATRIX_XLABEL_FONTSIZE)\n","plt.ylabel(\"TRUE\", fontsize=CONFUSION_MATRIX_YLABEL_FONTSIZE)\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["'''\n","Accuracy = (TP+TN)/(TP+FP+TN+FN)\n","Precision(準確率) = TP/(TP+FP)\n","Recall(召回率) = TP/(TP+FN)\n","F1-score(Recall與Precision的調和平均數) = 2 * Precision * Recall / (Precision + Recall)\n","'''\n","accuracy = accuracy_score(cm_correct_labels, cm_predictions)\n","precision = precision_score(cm_correct_labels, cm_predictions, labels = range(CLASSES), average = AVERAGE)\n","recall = recall_score(cm_correct_labels, cm_predictions, labels = range(CLASSES), average = AVERAGE)\n","score = f1_score( cm_correct_labels, cm_predictions, labels = range(CLASSES), average = AVERAGE)\n","print('Accuracy: {:.3f}, Precision: {:.3f}, Recall: {:.3f}, F1 score: {:.3f}'.format(accuracy, precision, recall, score))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Classification report on training Data\n","print(classification_report(cm_correct_labels, cm_predictions))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# 10. 待辦事項<a class=\"anchor\" id=\"10\"></a>\n","[Back to Table of Contents](#0)"]},{"metadata":{},"cell_type":"markdown","source":["[Go to Top](#0)"]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}