{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Object_Detection_YOLOv5 (Training)\n1. 需有前處理的CSV和標籤集跟圖檔集。\n1. 修改完設定檔後，執行前需修改[訓練模型](#5.4)指令。","metadata":{}},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# Table of Contents\n\n1. [套件安裝與載入](#1)\n1. [環境檢測與設定](#2)\n1. [開發參數設定](#3)\n1. [資料處理](#4)\n    -  [載入CSV檔](#4.1)\n    -  [檢查CSV檔缺失值](#4.2)\n1. [製作資料＆訓練模型](#5)\n    -  [製作資料集與標籤集](#5.1)\n    -  [Get Class Name](#5.2)\n    -  [製作訓練檔案路徑](#5.3)\n    -  [訓練模型](#5.4)\n    -  [Class Distribution](#5.5)\n    -  [Batch ImageBatch Image](#5.6)\n    -  [GT Vs PredGT Vs Pred](#5.7)\n    -  [(Loss, Map) Vs Epoch(Loss, Map) Vs Epoch](#5.8)\n    -  [Confusion Matrix](#5.9)\n1. [待辦事項](#6)","metadata":{}},{"cell_type":"markdown","source":"# 1. 套件安裝與載入<a class=\"anchor\" id=\"1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"# 資料處理套件\nimport os\nimport gc\nimport yaml\nimport time\nimport shutil\nimport datetime\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split, GroupKFold\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 設定顯示中文字體\nfrom matplotlib.font_manager import FontProperties\nplt.rcParams['font.sans-serif'] = ['Microsoft JhengHei'] # 用來正常顯示中文標籤\nplt.rcParams['font.family'] = 'AR PL UMing CN'\nplt.rcParams['axes.unicode_minus'] = False # 用來正常顯示負號","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pytorch深度學習模組套件\nimport torch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. 環境檢測與設定<a class=\"anchor\" id=\"2\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nDEVICE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 查看pytorch版本\nprint(torch.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''執行環境參數設定'''\n\n# (Boolean)是否為本機\nLOCAL = False\n\n# (Boolean)是否為 Colab\nCOLAB = False\n\n\n'''檔案路徑參數設定'''\n\n# (String)Root路徑\nif LOCAL:\n    PATH = r'../'\nelif COLAB:\n    PATH = r'/content/drive/My Drive/Colab Notebooks/'\nelse:\n    PATH = r'../input/'\n    OUTPUT_PATH = r'/kaggle/working/'\n    \n# (String)資料根路徑\nDATA_ROOT_PATH = PATH+r'vinbigdata-256-image-dataset/' \n\n# (String)標籤根路徑\nLABEL_ROOT_PATH = PATH+r'labeldataset/' \n\n# (String)CSV根路徑\nCSV_ROOT_PATH = PATH+r'trainyolo/' \n\n# (String)訓練資料路徑\nTRAIN_DATA_PATH = DATA_ROOT_PATH+r'vinbigdata/train/'\n\n# (String)訓練標籤路徑\nLABEL_DATA_PATH = LABEL_ROOT_PATH+r'labels/'\n\n# (String)訓練CSV路徑\nTRAIN_CSV_PATH = CSV_ROOT_PATH+r'train_yolo.csv'\n\n# (String)專案名稱\nPROJECT_NAME = 'vinbigdata-chest-xray-abnormalities-detection'\n\n# (Boolean)是否要匯入Library\nIMPORT_PYTORCH_LIBRARY = False\n\n# (String)Library的路徑\nPYTORCH_LIBRARY_PATH = PATH + \"PyTorch_Library/\"\n\n# (String)專案檔案儲存路徑\nif LOCAL or COLAB:\n    OUTPUT_PATH = PATH\nPROJECT_PATH = OUTPUT_PATH+PROJECT_NAME+'/'+PROJECT_NAME+' '+datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n\n# (String)權重名稱(使用哪個權重)\nWEIGHTS_NAME = 'efficientnet_b0'\n\n# (String)模型名稱(使用哪個模型)\nMODEL_NAME = 'efficientnet_b0'\n\n# (String)讀取預訓練權重的儲存路徑\nLOAD_WEIGHTS_PATH = PROJECT_PATH+r'/models/pretrain_weights/'+WEIGHTS_NAME+'.pth'\n\n# (String)讀取預訓練模型的儲存路徑\nLOAD_MODEL_PATH = PROJECT_PATH+r'/models/pretrain_models/'+MODEL_NAME+'.pth'\n\n# (Boolean)是否建立訓練模型儲存的時間戳資料夾\nMODEL_TIME_FOLDER = False\n# (String)訓練模型的儲存路徑\nif MODEL_TIME_FOLDER:\n    TRAIN_MODEL_PATH = PROJECT_PATH+r'/models/'+MODEL_NAME+'.pth'\nelse:\n    TRAIN_MODEL_PATH = MODEL_NAME+'.pth'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DEVICE != torch.device(\"cpu\"):\n    !nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not LOCAL and COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')\n\nif MODEL_TIME_FOLDER:\n    if not os.path.isdir(PROJECT_PATH+r'/models/'):\n        os.makedirs(PROJECT_PATH+r'/models/')\n    \nif IMPORT_PYTORCH_LIBRARY:\n    sys.path.append(PYTORCH_LIBRARY_PATH + \"Custom_Loss.py\")\n    sys.path.append(PYTORCH_LIBRARY_PATH + \"Custom_Model.py\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. 開發參數設定<a class=\"anchor\" id=\"3\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"'''客製參數設定'''\n\n\n'''資料參數設定'''\n\n# (Int)有CSV檔該參數才有用，1則為不做交叉驗證\nFOLD = 5\n\n# (String)圖片副檔名\nIMAGE_NAME_EXTENSION = '.png'\n\n# (String)CSV圖片檔名欄位\nIMAGE_NAME = 'image_id'\n\n# (String)CSV標籤欄位\nLABEL_NAME = 'class_name'\n\n# (String)CSV標籤ID欄位\nLABEL_ID = 'class_id'\n\n# (Boolean)是否有空物件框的csv資料\nEMPTY_BOUNDING_BOX = True\n\nif EMPTY_BOUNDING_BOX:\n    # (Int)CSV空物件框標籤ID\n    EMPTY_BOUNDING_BOX_LABEL_ID = 14\n    \n# (Int)不同的種子會產生不同的Random或分層K-FOLD分裂, 42則是預設固定種子\nSEED = 42\n\nif FOLD == 1:\n    # (Float)驗證集佔訓練集的比率，FOLD>1則不啟用\n    DATA_SPLIT = 0.2\nelse:\n    # (String)切分訓練集跟驗證集方式 GroupKFold\n    KF = GroupKFold(n_splits = FOLD)\n\n\n''''圖表參數設定'''\n\n# (Float)全部SNS圖表的字形縮放\nALL_SNS_FONT_SCALE = 1.0\n\n# (Int)CSV缺失值圖表寬度\nCSV_COUNTPLOT_FIGSIZE_W = 10\n\n# (Int)CSV缺失值圖表高度\nCSV_COUNTPLOT_FIGSIZE_H = 10\n\n# (Int)CSV缺失值圖表標題字型大小\nCSV_COUNTPLOT_TITLE_FONTSIZE = 20\n\n# (Int)CSV缺失值圖表X軸標題字型大小\nCSV_COUNTPLOT_XLABEL_FONTSIZE = 15\n\n# (Int)CSV缺失值圖表Y軸標題字型大小\nCSV_COUNTPLOT_YLABEL_FONTSIZE = 15\n\n# (Int)Class Distribution圖表寬度\nCLASS_DISTRIBUTION_FIGSIZE_W = 20\n\n# (Int)Class Distribution圖表高度\nCLASS_DISTRIBUTION_FIGSIZE_H = 20\n\n# (Int)Batch Image圖表寬度\nBATCH_IMAGE_FIGSIZE_W = 15\n\n# (Int)Batch Image圖表高度\nBATCH_IMAGE_FIGSIZE_H = 15\n\n# (Int)Batch Image顯示次數\nCOUNTS = 3\n\n# (Int)GT Vs Pred圖表figsize倍率\nFIGSIZE_RATE = 5\n\n# (Boolean)GT Vs Pred圖表是否自動調整子圖間距\nCONSTRAINED_LAYOUT = True\n\n# (Int)GT Vs Pred圖表標題字體大小\nFONTSIZE = 12\n\n# (Int)(Loss, Map) Vs Epoch圖表寬度\nLOSS_MAP_EPOCH_FIGSIZE_W = 30\n\n# (Int)(Loss, Map) Vs Epoch圖表高度\nLOSS_MAP_EPOCH_FIGSIZE_H = 15\n\n# (Int)Confusion Matrix圖表寬度\nCONFUSION_MATRIX_FIGSIZE_W = 30\n\n# (Int)Confusion Matrix圖表高度\nCONFUSION_MATRIX_FIGSIZE_H = 15","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 設置sns圖表縮放係數\nsns.set(font_scale = ALL_SNS_FONT_SCALE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. 資料處理<a class=\"anchor\" id=\"4\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"markdown","source":"## 4.1 載入CSV檔 <a class=\"anchor\" id=\"4.1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"print('Reading data...')\n\n# 讀取訓練資料集CSV檔\ntrain_csv = pd.read_csv(TRAIN_CSV_PATH,encoding=\"utf8\")\nif EMPTY_BOUNDING_BOX:\n    train_csv = train_csv[train_csv.class_id != EMPTY_BOUNDING_BOX_LABEL_ID].reset_index(drop = True)\n\nprint('Reading data completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 顯示訓練資料集CSV檔\ntrain_csv.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of train_data :\", train_csv.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 檢查CSV檔缺失值 <a class=\"anchor\" id=\"4.2\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"# 缺失值比率\ntotal = train_csv.isnull().sum().sort_values(ascending = False)\npercent = (train_csv.isnull().sum()/train_csv.isnull().count()*100).sort_values(ascending = False)\nmissing_train_csv  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_train_csv.head(missing_train_csv.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv[LABEL_NAME].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax = plt.subplots(figsize=(CSV_COUNTPLOT_FIGSIZE_W, CSV_COUNTPLOT_FIGSIZE_H))\nsns.countplot(train_csv[LABEL_NAME], hue = train_csv[LABEL_NAME],ax = ax)\nplt.title(\"LABEL COUNT\", fontsize=CSV_COUNTPLOT_TITLE_FONTSIZE)\nplt.xlabel(LABEL_NAME.upper(), fontsize=CSV_COUNTPLOT_XLABEL_FONTSIZE)\nplt.ylabel(\"COUNT\", fontsize=CSV_COUNTPLOT_YLABEL_FONTSIZE)\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. 製作資料＆訓練模型 <a class=\"anchor\" id=\"5\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"markdown","source":"## 5.1 製作資料集與標籤集 <a class=\"anchor\" id=\"5.1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"os.makedirs(OUTPUT_PATH+'train/labels/', exist_ok = True)\nos.makedirs(OUTPUT_PATH+'train/images/', exist_ok = True)\nfiles = []\nfiles = train_csv['image_path'].unique()\nfor file in tqdm(files):\n    shutil.copy(file, OUTPUT_PATH+'train/images/')\n    filename = file.split('/')[-1].split('.')[0]\n    shutil.copy(os.path.join(LABEL_DATA_PATH, filename+'.txt'), OUTPUT_PATH+'train/labels/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 Get Class Name <a class=\"anchor\" id=\"5.2\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"class_ids, class_names = list(zip(*set(zip(train_csv[LABEL_ID], train_csv[LABEL_NAME]))))\nclasses = list(np.array(class_names)[np.argsort(class_ids)])\nclasses = list(map(lambda x: str(x), classes))\nclasses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.3 製作訓練檔案路徑 <a class=\"anchor\" id=\"5.3\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"def txt_process(fold, kf): \n    train_files = []\n    val_files = []\n    val_files += list(train_csv[train_csv.Folds == fold].image_path.unique())\n    train_files += list(train_csv[train_csv.Folds != fold].image_path.unique())\n    print(len(train_files), len(val_files))\n    \n    os.makedirs(OUTPUT_PATH+'train/'+str(fold)+'/', exist_ok = True)\n\n    with open(os.path.join(OUTPUT_PATH, 'train/'+str(fold)+'/train.txt'), 'w') as f:\n        for path in train_files:\n            filename = path.split('/')[-1].split('.')[0]\n            f.write(OUTPUT_PATH+'train/images/'+filename+IMAGE_NAME_EXTENSION+'\\n')\n\n    with open(os.path.join(OUTPUT_PATH, 'train/'+str(fold)+'/val.txt'), 'w') as f:\n        for path in val_files:\n            filename = path.split('/')[-1].split('.')[0]\n            f.write(OUTPUT_PATH+'train/images/'+filename+IMAGE_NAME_EXTENSION+'\\n')\n\n    data = dict(\n        train =  os.path.join(OUTPUT_PATH, 'train/'+str(fold)+'/train.txt') ,\n        val   =  os.path.join(OUTPUT_PATH, 'train/'+str(fold)+'/val.txt' ),\n        nc    = len(classes),\n        names = classes\n        )\n\n    with open(os.path.join(OUTPUT_PATH, 'train/'+str(fold)+'/train.yaml'), 'w') as outfile:\n        yaml.dump(data, outfile, default_flow_style=False)\n\n    f = open(os.path.join(OUTPUT_PATH, 'train/'+str(fold)+'/train.yaml'), 'r')\n    print('\\nyaml:')\n    print(f.read())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def txt_main():\n    try:\n        if FOLD > 1:\n            train_csv['Folds'] = -1\n            for fold, (train_index, valid_index) in enumerate(KF.split(train_csv, groups = train_csv[IMAGE_NAME].tolist())):\n                train_csv.loc[valid_index, 'Folds'] = fold\n                txt_process(fold = fold, kf = True)\n        else:\n            txt_process(fold = 0, kf = False)\n    except Exception as exception:\n        print(exception)\n        raise","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    txt_main()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.4 訓練模型 <a class=\"anchor\" id=\"5.4\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"%cd train\n!git clone https://github.com/ultralytics/yolov5  # clone repo\n%cd yolov5\n%pip install -qr requirements.txt  # install dependencies","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!WANDB_MODE=\"dryrun\" python train.py --img 256 --batch 32 --epochs 3 --data /kaggle/working/train/0/train.yaml --weights yolov5x.pt --cache","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.5 Class Distribution <a class=\"anchor\" id=\"5.5\"></a>\n[Back to Table of Contents](#0)","metadata":{"papermill":{"duration":4.919442,"end_time":"2021-01-01T15:22:26.398681","exception":false,"start_time":"2021-01-01T15:22:21.479239","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.figure(figsize = (CLASS_DISTRIBUTION_FIGSIZE_W,CLASS_DISTRIBUTION_FIGSIZE_H))\nplt.axis('off')\nplt.imshow(plt.imread('runs/train/exp/labels_correlogram.jpg'));","metadata":{"papermill":{"duration":6.511035,"end_time":"2021-01-01T15:22:37.753063","exception":false,"start_time":"2021-01-01T15:22:31.242028","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (CLASS_DISTRIBUTION_FIGSIZE_W,CLASS_DISTRIBUTION_FIGSIZE_H))\nplt.axis('off')\nplt.imshow(plt.imread('runs/train/exp/labels.jpg'));","metadata":{"papermill":{"duration":5.977042,"end_time":"2021-01-01T15:22:48.614609","exception":false,"start_time":"2021-01-01T15:22:42.637567","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.6 Batch ImageBatch Image <a class=\"anchor\" id=\"5.6\"></a>\n[Back to Table of Contents](#0)","metadata":{"papermill":{"duration":5.378338,"end_time":"2021-01-01T15:22:59.482837","exception":false,"start_time":"2021-01-01T15:22:54.104499","status":"completed"},"tags":[]}},{"cell_type":"code","source":"for i in range(COUNTS):\n    plt.figure(figsize = (BATCH_IMAGE_FIGSIZE_W, BATCH_IMAGE_FIGSIZE_H))\n    plt.imshow(plt.imread('runs/train/exp/train_batch'+str(i)+'.jpg'))","metadata":{"papermill":{"duration":7.317416,"end_time":"2021-01-01T15:23:11.777544","exception":false,"start_time":"2021-01-01T15:23:04.460128","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.7 GT Vs PredGT Vs Pred <a class=\"anchor\" id=\"5.7\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(COUNTS, 2, figsize = (2*FIGSIZE_RATE,COUNTS*FIGSIZE_RATE), constrained_layout = CONSTRAINED_LAYOUT)\nfor row in range(COUNTS):\n    ax[row][0].imshow(plt.imread(f'runs/train/exp/test_batch{row}_labels.jpg'))\n    ax[row][0].set_xticks([])\n    ax[row][0].set_yticks([])\n    ax[row][0].set_title(f'runs/train/exp/test_batch{row}_labels.jpg', fontsize = FONTSIZE)\n    \n    ax[row][1].imshow(plt.imread(f'runs/train/exp/test_batch{row}_pred.jpg'))\n    ax[row][1].set_xticks([])\n    ax[row][1].set_yticks([])\n    ax[row][1].set_title(f'runs/train/exp/test_batch{row}_pred.jpg', fontsize = FONTSIZE)","metadata":{"papermill":{"duration":6.453975,"end_time":"2021-01-01T15:23:23.514717","exception":false,"start_time":"2021-01-01T15:23:17.060742","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.8 (Loss, Map) Vs Epoch <a class=\"anchor\" id=\"5.8\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(LOSS_MAP_EPOCH_FIGSIZE_W,LOSS_MAP_EPOCH_FIGSIZE_H))\nplt.axis('off')\nplt.imshow(plt.imread('runs/train/exp/results.png'));","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.9 Confusion Matrix <a class=\"anchor\" id=\"5.9\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(CONFUSION_MATRIX_FIGSIZE_W,CONFUSION_MATRIX_FIGSIZE_H))\nplt.axis('off')\nplt.imshow(plt.imread('runs/train/exp/confusion_matrix.png'));","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. 待辦事項<a class=\"anchor\" id=\"6\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"markdown","source":"[Go to Top](#0)","metadata":{}}]}