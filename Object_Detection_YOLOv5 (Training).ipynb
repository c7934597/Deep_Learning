{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Object_Detection_YOLOv5 (Training)\n1. 需要先有前處理的CSV。\n1. 需要先有前處理的圖檔資料集。\n1. 需要先有前處理的標籤資料集。","metadata":{}},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# Table of Contents\n\n1. [套件安裝與載入](#1)\n1. [環境檢測與設定](#2)\n1. [開發參數設定](#3)\n1. [資料處理](#4)\n    -  [載入CSV檔](#4.1)\n    -  [檢查CSV檔缺失值](#4.2)\n1. [定義模型方法](#5)\n1. [定義回調函數方法](#6)\n1. [製作資料集＆資料擴增&回調函數&訓練模型](#7)\n1. [混淆矩陣 & Quadratic Weighted Kappa](#8)\n1. [待辦事項](#9)","metadata":{}},{"cell_type":"markdown","source":"# 1. 套件安裝與載入<a class=\"anchor\" id=\"1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"# # YOLOv5\n# !git clone https://github.com/ultralytics/yolov5  # clone repo\n# %cd yolov5\n# %pip install -qr requirements.txt  # install dependencies","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 資料處理套件\nimport os\nimport gc\nimport time\nimport shutil\nimport datetime\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split, GroupKFold\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 設定顯示中文字體\nfrom matplotlib.font_manager import FontProperties\nplt.rcParams['font.sans-serif'] = ['Microsoft JhengHei'] # 用來正常顯示中文標籤\nplt.rcParams['font.family'] = 'AR PL UMing CN'\nplt.rcParams['axes.unicode_minus'] = False # 用來正常顯示負號","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pytorch深度學習模組套件\nimport torch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. 環境檢測與設定<a class=\"anchor\" id=\"2\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nDEVICE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 查看pytorch版本\nprint(torch.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''執行環境參數設定'''\n\n# (Boolean)是否為本機\nLOCAL = False\n\n# (Boolean)是否為 Colab\nCOLAB = False\n\n\n'''檔案路徑參數設定'''\n\n# (String)Root路徑\nif LOCAL:\n    PATH = r'../'\nelif COLAB:\n    PATH = r'/content/drive/My Drive/Colab Notebooks/'\nelse:\n    PATH = r'../input/'\n    OUTPUT_PATH = r'/kaggle/working/'\n    \n# (String)資料根路徑\nDATA_ROOT_PATH = PATH+r'vinbigdata-256-image-dataset/' \n\n# (String)CSV根路徑\nCSV_ROOT_PATH = PATH+r'trainyolo/' \n\n# (String)訓練資料路徑\nTRAIN_DATA_PATH = DATA_ROOT_PATH+r'vinbigdata/train/'\n\n# (String)訓練CSV路徑\nTRAIN_CSV_PATH = CSV_ROOT_PATH+r'train_yolo.csv'\n\n# (String)專案名稱\nPROJECT_NAME = 'vinbigdata-chest-xray-abnormalities-detection'\n\n# (Boolean)是否要匯入Library\nIMPORT_PYTORCH_LIBRARY = False\n\n# (String)Library的路徑\nPYTORCH_LIBRARY_PATH = PATH + \"PyTorch_Library/\"\n\n# (String)專案檔案儲存路徑\nif LOCAL or COLAB:\n    OUTPUT_PATH = PATH\nPROJECT_PATH = OUTPUT_PATH+PROJECT_NAME+'/'+PROJECT_NAME+' '+datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n\n# (String)權重名稱(使用哪個權重)\nWEIGHTS_NAME = 'efficientnet_b0'\n\n# (String)模型名稱(使用哪個模型)\nMODEL_NAME = 'efficientnet_b0'\n\n# (String)讀取預訓練權重的儲存路徑\nLOAD_WEIGHTS_PATH = PROJECT_PATH+r'/models/pretrain_weights/'+WEIGHTS_NAME+'.pth'\n\n# (String)讀取預訓練模型的儲存路徑\nLOAD_MODEL_PATH = PROJECT_PATH+r'/models/pretrain_models/'+MODEL_NAME+'.pth'\n\n# (String)訓練模型的儲存路徑\nTRAIN_MODEL_PATH = PROJECT_PATH+r'/models/'+MODEL_NAME+'.pth'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DEVICE != torch.device(\"cpu\"):\n    !nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not LOCAL and COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    \nif not os.path.isdir(PROJECT_PATH+r'/models/'):\n    os.makedirs(PROJECT_PATH+r'/models/')\n    \nif IMPORT_PYTORCH_LIBRARY:\n    sys.path.append(PYTORCH_LIBRARY_PATH + \"Custom_Loss.py\")\n    sys.path.append(PYTORCH_LIBRARY_PATH + \"Custom_Model.py\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. 開發參數設定<a class=\"anchor\" id=\"3\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"'''客製參數設定'''\n\n\n'''資料參數設定'''\n\n# (Int)有CSV檔該參數才有用，1則為不做交叉驗證\nFOLD = 5\n\n# (String)圖片副檔名\nIMAGE_NAME_EXTENSION = '.png'\n\n# (String)CSV圖片檔名欄位\nIMAGE_NAME = 'image_id'\n\n# (String)CSV標籤欄位\nLABEL_NAME = 'class_name'\n\n# (String)CSV標籤ID欄位\nLABEL_ID = 'class_id'\n\n# (Boolean)是否有空物件框的csv資料\nEMPTY_BOUNDING_BOX = True\n\nif EMPTY_BOUNDING_BOX:\n    # (Int)CSV空物件框標籤ID\n    EMPTY_BOUNDING_BOX_LABEL_ID = 14\n    \n# (Int)不同的種子會產生不同的Random或分層K-FOLD分裂, 42則是預設固定種子\nSEED = 42\n\nif FOLD == 1:\n    # (Float)驗證集佔訓練集的比率，FOLD>1則不啟用\n    DATA_SPLIT = 0.2\nelse:\n    # (String)切分訓練集跟驗證集方式 GroupKFold\n    KF = GroupKFold(n_splits = FOLD)\n\n\n''''圖表參數設定'''\n\n# (Float)全部SNS圖表的字形縮放\nALL_SNS_FONT_SCALE = 1.0\n\n# (Int)CSV缺失值圖表寬度\nCSV_COUNTPLOT_FIGSIZE_W = 10\n\n# (Int)CSV缺失值圖表高度\nCSV_COUNTPLOT_FIGSIZE_H = 10\n\n# (Int)CSV缺失值圖表標題字型大小\nCSV_COUNTPLOT_TITLE_FONTSIZE = 20\n\n# (Int)CSV缺失值圖表X軸標題字型大小\nCSV_COUNTPLOT_XLABEL_FONTSIZE = 15\n\n# (Int)CSV缺失值圖表Y軸標題字型大小\nCSV_COUNTPLOT_YLABEL_FONTSIZE = 15","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 設置sns圖表縮放係數\nsns.set(font_scale = ALL_SNS_FONT_SCALE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. 資料處理<a class=\"anchor\" id=\"4\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"markdown","source":"## 4.1 載入CSV檔 <a class=\"anchor\" id=\"4.1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"print('Reading data...')\n\n# 讀取訓練資料集CSV檔\ntrain_csv = pd.read_csv(TRAIN_CSV_PATH,encoding=\"utf8\")\nif EMPTY_BOUNDING_BOX:\n    train_csv = train_csv[train_csv.class_id != EMPTY_BOUNDING_BOX_LABEL_ID].reset_index(drop = True)\n\nprint('Reading data completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 顯示訓練資料集CSV檔\ntrain_csv.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of train_data :\", train_csv.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 檢查CSV檔缺失值 <a class=\"anchor\" id=\"4.2\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"# 缺失值比率\ntotal = train_csv.isnull().sum().sort_values(ascending = False)\npercent = (train_csv.isnull().sum()/train_csv.isnull().count()*100).sort_values(ascending = False)\nmissing_train_csv  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_train_csv.head(missing_train_csv.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv[LABEL_NAME].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax = plt.subplots(figsize=(CSV_COUNTPLOT_FIGSIZE_W, CSV_COUNTPLOT_FIGSIZE_H))\nsns.countplot(train_csv[LABEL_NAME], hue = train_csv[LABEL_NAME],ax = ax)\nplt.title(\"LABEL COUNT\", fontsize=CSV_COUNTPLOT_TITLE_FONTSIZE)\nplt.xlabel(LABEL_NAME.upper(), fontsize=CSV_COUNTPLOT_XLABEL_FONTSIZE)\nplt.ylabel(\"COUNT\", fontsize=CSV_COUNTPLOT_YLABEL_FONTSIZE)\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n    try:\n        print('Training start')\n        since = time.time()\n        if FOLD > 1:\n            train_csv['Folds'] = -1\n            for fold, (train_index, valid_index) in enumerate(KF.split(train_csv, groups = train_csv[train_csv.columns[0]].values)):\n                train_csv.loc[valid_index, 'Folds'] = fold\n#                 train_process(fold = fold, kf = True)\n#         else:\n#             train_process(fold = 0, kf = False)\n        time_elapsed = time.time() - since\n        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    except Exception as exception:\n        print(exception)\n        raise","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    main()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_files = []\n# val_files = []\n# val_files += list(train_csv[train_csv.Folds == 0].image_path.unique())\n# train_files += list(train_csv[train_csv.Folds != 0].image_path.unique())\n# print(len(train_files), len(val_files))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.makedirs('/kaggle/working/vinbigdata/labels/train', exist_ok = True)\n# os.makedirs('/kaggle/working/vinbigdata/labels/val', exist_ok = True)\n# os.makedirs('/kaggle/working/vinbigdata/images/train', exist_ok = True)\n# os.makedirs('/kaggle/working/vinbigdata/images/val', exist_ok = True)\n# label_dir = '/kaggle/input/vinbigdata-yolo-labels-dataset/labels'\n# for file in tqdm(train_files):\n#     shutil.copy(file, '/kaggle/working/vinbigdata/images/train')\n#     filename = file.split('/')[-1].split('.')[0]\n#     shutil.copy(os.path.join(label_dir, filename+'.txt'), '/kaggle/working/vinbigdata/labels/train')\n    \n# for file in tqdm(val_files):\n#     shutil.copy(file, '/kaggle/working/vinbigdata/images/val')\n#     filename = file.split('/')[-1].split('.')[0]\n#     shutil.copy(os.path.join(label_dir, filename+'.txt'), '/kaggle/working/vinbigdata/labels/val')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# features = ['x_min', 'y_min', 'x_max', 'y_max', 'x_mid', 'y_mid', 'w', 'h', 'area']\n# X = train_df[features]\n# y = train_df['class_id']\n# X.shape, y.shape","metadata":{"papermill":{"duration":0.040387,"end_time":"2021-01-01T09:45:02.923416","exception":false,"start_time":"2021-01-01T09:45:02.883029","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class_ids, class_names = list(zip(*set(zip(train_df.class_id, train_df.class_name))))\n# classes = list(np.array(class_names)[np.argsort(class_ids)])\n# classes = list(map(lambda x: str(x), classes))\n# classes","metadata":{"papermill":{"duration":0.050418,"end_time":"2021-01-01T09:45:03.002944","exception":false,"start_time":"2021-01-01T09:45:02.952526","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Copying Files","metadata":{"papermill":{"duration":0.083752,"end_time":"2021-01-01T09:47:56.584924","exception":false,"start_time":"2021-01-01T09:47:56.501172","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# os.makedirs('/kaggle/working/vinbigdata/labels/train', exist_ok = True)\n# os.makedirs('/kaggle/working/vinbigdata/labels/val', exist_ok = True)\n# os.makedirs('/kaggle/working/vinbigdata/images/train', exist_ok = True)\n# os.makedirs('/kaggle/working/vinbigdata/images/val', exist_ok = True)\n# label_dir = '/kaggle/input/vinbigdata-yolo-labels-dataset/labels'\n# for file in tqdm(train_files):\n#     shutil.copy(file, '/kaggle/working/vinbigdata/images/train')\n#     filename = file.split('/')[-1].split('.')[0]\n#     shutil.copy(os.path.join(label_dir, filename+'.txt'), '/kaggle/working/vinbigdata/labels/train')\n    \n# for file in tqdm(val_files):\n#     shutil.copy(file, '/kaggle/working/vinbigdata/images/val')\n#     filename = file.split('/')[-1].split('.')[0]\n#     shutil.copy(os.path.join(label_dir, filename+'.txt'), '/kaggle/working/vinbigdata/labels/val')","metadata":{"papermill":{"duration":124.654777,"end_time":"2021-01-01T09:50:01.331041","exception":false,"start_time":"2021-01-01T09:47:56.676264","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get Class Name","metadata":{"papermill":{"duration":0.068822,"end_time":"2021-01-01T09:50:01.458337","exception":false,"start_time":"2021-01-01T09:50:01.389515","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# class_ids, class_names = list(zip(*set(zip(train_df.class_id, train_df.class_name))))\n# classes = list(np.array(class_names)[np.argsort(class_ids)])\n# classes = list(map(lambda x: str(x), classes))\n# classes","metadata":{"papermill":{"duration":0.082234,"end_time":"2021-01-01T09:50:01.601574","exception":false,"start_time":"2021-01-01T09:50:01.51934","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# [YOLOv5](https://github.com/ultralytics/yolov5)\n![](https://user-images.githubusercontent.com/26833433/98699617-a1595a00-2377-11eb-8145-fc674eb9b1a7.jpg)\n![](https://user-images.githubusercontent.com/26833433/90187293-6773ba00-dd6e-11ea-8f90-cd94afc0427f.png)","metadata":{"papermill":{"duration":0.056257,"end_time":"2021-01-01T09:50:01.716608","exception":false,"start_time":"2021-01-01T09:50:01.660351","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# YOLOv5 Stuff","metadata":{"papermill":{"duration":0.055699,"end_time":"2021-01-01T09:50:01.82747","exception":false,"start_time":"2021-01-01T09:50:01.771771","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# from os import listdir\n# from os.path import isfile, join\n# import yaml\n\n# cwd = '/kaggle/working/'\n\n# with open(join( cwd , 'train.txt'), 'w') as f:\n#     for path in glob('/kaggle/working/vinbigdata/images/train/*'):\n#         f.write(path+'\\n')\n            \n# with open(join( cwd , 'val.txt'), 'w') as f:\n#     for path in glob('/kaggle/working/vinbigdata/images/val/*'):\n#         f.write(path+'\\n')\n\n# data = dict(\n#     train =  join( cwd , 'train.txt') ,\n#     val   =  join( cwd , 'val.txt' ),\n#     nc    = 14,\n#     names = classes\n#     )\n\n# with open(join( cwd , 'vinbigdata.yaml'), 'w') as outfile:\n#     yaml.dump(data, outfile, default_flow_style=False)\n\n# f = open(join( cwd , 'vinbigdata.yaml'), 'r')\n# print('\\nyaml:')\n# print(f.read())","metadata":{"papermill":{"duration":0.113001,"end_time":"2021-01-01T09:50:01.996448","exception":false,"start_time":"2021-01-01T09:50:01.883447","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # https://www.kaggle.com/ultralytics/yolov5\n# # !git clone https://github.com/ultralytics/yolov5  # clone repo\n# # %cd yolov5\n# shutil.copytree('/kaggle/input/yolov5-official-v31-dataset/yolov5', '/kaggle/working/yolov5')\n# os.chdir('/kaggle/working/yolov5')\n# # %pip install -qr requirements.txt # install dependencies\n\n# import torch\n# from IPython.display import Image, clear_output  # to display images\n\n# clear_output()\n# print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","papermill":{"duration":6.702428,"end_time":"2021-01-01T09:50:08.784153","exception":false,"start_time":"2021-01-01T09:50:02.081725","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images/\n# Image(filename='runs/detect/exp/zidane.jpg', width=600)","metadata":{"papermill":{"duration":10.410768,"end_time":"2021-01-01T09:50:19.303402","exception":false,"start_time":"2021-01-01T09:50:08.892634","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pretrained Checkpoints:\n\n| Model | AP<sup>val</sup> | AP<sup>test</sup> | AP<sub>50</sub> | Speed<sub>GPU</sub> | FPS<sub>GPU</sub> || params | FLOPS |\n|---------- |------ |------ |------ | -------- | ------| ------ |------  |  :------: |\n| [YOLOv5s](https://github.com/ultralytics/yolov5/releases/tag/v3.0)    | 37.0     | 37.0     | 56.2     | **2.4ms** | **416** || 7.5M   | 13.2B\n| [YOLOv5m](https://github.com/ultralytics/yolov5/releases/tag/v3.0)    | 44.3     | 44.3     | 63.2     | 3.4ms     | 294     || 21.8M  | 39.4B\n| [YOLOv5l](https://github.com/ultralytics/yolov5/releases/tag/v3.0)    | 47.7     | 47.7     | 66.5     | 4.4ms     | 227     || 47.8M  | 88.1B\n| [YOLOv5x](https://github.com/ultralytics/yolov5/releases/tag/v3.0)    | **49.2** | **49.2** | **67.7** | 6.9ms     | 145     || 89.0M  | 166.4B\n| | | | | | || |\n| [YOLOv5x](https://github.com/ultralytics/yolov5/releases/tag/v3.0) + TTA|**50.8**| **50.8** | **68.9** | 25.5ms    | 39      || 89.0M  | 354.3B\n| | | | | | || |\n| [YOLOv3-SPP](https://github.com/ultralytics/yolov5/releases/tag/v3.0) | 45.6     | 45.5     | 65.2     | 4.5ms     | 222     || 63.0M  | 118.0B","metadata":{"papermill":{"duration":0.064911,"end_time":"2021-01-01T09:50:19.435746","exception":false,"start_time":"2021-01-01T09:50:19.370835","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Selecting Models\nIn this notebok I'm using `v5s`. To select your prefered model just replace `--cfg models/yolov5s.yaml --weights yolov5s.pt` with the following command:\n* `v5s` : `--cfg models/yolov5s.yaml --weights yolov5s.pt`\n* `v5m` : `--cfg models/yolov5m.yaml --weights yolov5m.pt`\n* `v5l` : `--cfg models/yolov5l.yaml --weights yolov5l.pt`\n* `v5x` : `--cfg models/yolov5x.yaml --weights yolov5x.pt`","metadata":{"papermill":{"duration":0.064016,"end_time":"2021-01-01T09:50:19.564859","exception":false,"start_time":"2021-01-01T09:50:19.500843","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Train","metadata":{"papermill":{"duration":0.064553,"end_time":"2021-01-01T09:50:19.6938","exception":false,"start_time":"2021-01-01T09:50:19.629247","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# # !WANDB_MODE=\"dryrun\" python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --nosave --cache \n# !WANDB_MODE=\"dryrun\" python train.py --img 640 --batch 16 --epochs 30 --data /kaggle/working/vinbigdata.yaml --weights yolov5x.pt --cache","metadata":{"papermill":{"duration":19916.498298,"end_time":"2021-01-01T15:22:16.289734","exception":false,"start_time":"2021-01-01T09:50:19.791436","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Class Distribution","metadata":{"papermill":{"duration":4.919442,"end_time":"2021-01-01T15:22:26.398681","exception":false,"start_time":"2021-01-01T15:22:21.479239","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# plt.figure(figsize = (20,20))\n# plt.axis('off')\n# plt.imshow(plt.imread('runs/train/exp/labels_correlogram.jpg'));","metadata":{"papermill":{"duration":6.511035,"end_time":"2021-01-01T15:22:37.753063","exception":false,"start_time":"2021-01-01T15:22:31.242028","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.figure(figsize = (20,20))\n# plt.axis('off')\n# plt.imshow(plt.imread('runs/train/exp/labels.jpg'));","metadata":{"papermill":{"duration":5.977042,"end_time":"2021-01-01T15:22:48.614609","exception":false,"start_time":"2021-01-01T15:22:42.637567","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Batch Image","metadata":{"papermill":{"duration":5.378338,"end_time":"2021-01-01T15:22:59.482837","exception":false,"start_time":"2021-01-01T15:22:54.104499","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# plt.figure(figsize = (15, 15))\n# plt.imshow(plt.imread('runs/train/exp/train_batch0.jpg'))\n\n# plt.figure(figsize = (15, 15))\n# plt.imshow(plt.imread('runs/train/exp/train_batch1.jpg'))\n\n# plt.figure(figsize = (15, 15))\n# plt.imshow(plt.imread('runs/train/exp/train_batch2.jpg'))","metadata":{"papermill":{"duration":7.317416,"end_time":"2021-01-01T15:23:11.777544","exception":false,"start_time":"2021-01-01T15:23:04.460128","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GT Vs Pred","metadata":{}},{"cell_type":"code","source":"# fig, ax = plt.subplots(3, 2, figsize = (2*5,3*5), constrained_layout = True)\n# for row in range(3):\n#     ax[row][0].imshow(plt.imread(f'runs/train/exp/test_batch{row}_labels.jpg'))\n#     ax[row][0].set_xticks([])\n#     ax[row][0].set_yticks([])\n#     ax[row][0].set_title(f'runs/train/exp/test_batch{row}_labels.jpg', fontsize = 12)\n    \n#     ax[row][1].imshow(plt.imread(f'runs/train/exp/test_batch{row}_pred.jpg'))\n#     ax[row][1].set_xticks([])\n#     ax[row][1].set_yticks([])\n#     ax[row][1].set_title(f'runs/train/exp/test_batch{row}_pred.jpg', fontsize = 12)","metadata":{"papermill":{"duration":6.453975,"end_time":"2021-01-01T15:23:23.514717","exception":false,"start_time":"2021-01-01T15:23:17.060742","status":"completed"},"tags":[],"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (Loss, Map) Vs Epoch","metadata":{}},{"cell_type":"code","source":"# plt.figure(figsize=(30,15))\n# plt.axis('off')\n# plt.imshow(plt.imread('runs/train/exp/results.png'));","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confusion Matrix","metadata":{}},{"cell_type":"code","source":"# plt.figure(figsize=(30,15))\n# plt.axis('off')\n# plt.imshow(plt.imread('runs/train/exp/confusion_matrix.png'));","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{"papermill":{"duration":4.941983,"end_time":"2021-01-01T15:23:33.765831","exception":false,"start_time":"2021-01-01T15:23:28.823848","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Inference Plot","metadata":{"papermill":{"duration":5.225725,"end_time":"2021-01-01T15:24:00.706026","exception":false,"start_time":"2021-01-01T15:23:55.480301","status":"completed"},"tags":[]}}]}