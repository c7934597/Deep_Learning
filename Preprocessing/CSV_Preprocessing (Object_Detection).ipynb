{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CSV_Preprocessing (Object_Detection)\n需有處理後圖片元數據CSV，並且會產出處理過CSV跟標籤資料集","metadata":{}},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# Table of Contents\n\n1. [套件安裝與載入](#1)\n1. [環境檢測與設定](#2)\n1. [資料處理參數設定](#3)\n1. [資料處理](#4)\n    -  [載入CSV檔](#4.1)\n    -  [檢查CSV檔缺失值](#4.2)\n    -  [使用元數據提取圖片寬度和高度欄位](#4.3)\n    -  [使用處理後CSV來產生標籤資料集](#4.4)","metadata":{}},{"cell_type":"markdown","source":"# 1. 套件安裝與載入<a class=\"anchor\" id=\"1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"# 資料處理套件\nimport os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom tqdm import tqdm\nfrom sklearn import preprocessing","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. 環境檢測與設定<a class=\"anchor\" id=\"2\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"'''執行環境參數設定'''\n\n# (Boolean)是否為本機\nLOCAL = False\n\n# (Boolean)是否為 Colab\nCOLAB = False\n\n\n'''檔案路徑參數設定'''\n\n# (String)Root路徑\nif LOCAL:\n    PATH = r'../'\nelif COLAB:\n    PATH = r'/content/drive/My Drive/Colab Notebooks/'\nelse:\n    PATH = r'../input/'\n    OUTPUT_PATH = r'/kaggle/working/'\n    \n# (String)資料根路徑\nDATA_ROOT_PATH = PATH+r'vinbigdata-chest-xray-abnormalities-detection/'\n\n# (String)meta資料根路徑\nMETA_DATA_ROOT_PATH = PATH+r'vinbigdata-process-and-resize-to-png-256x256/'\n\n# (String)CSV圖檔路徑的根路徑\nCSV_IMAGE_ROOT_PATH = PATH+r'vinbigdata-256-image-dataset/vinbigdata/'\n\n# (String)訓練資料路徑\nTRAIN_DATA_PATH = CSV_IMAGE_ROOT_PATH+r'train/'\n\n# (String)訓練CSV路徑，如為None則不讀CSV檔\nTRAIN_CSV_PATH = DATA_ROOT_PATH+r'train.csv'\n\n# (String)META_CSV路徑，如為None則不讀META_CSV檔\nTRAIN_META_CSV_PATH = META_DATA_ROOT_PATH+r'train_meta.csv'\n\n# (String)CSV處理後的儲存檔名\nTRAIN_CSV_SAVE_FILENAME = 'train_yolo.csv'\n\n# (String)標籤資料夾的路徑\nLABEL_FOLDER_PATH = '/kaggle/working/labels/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not LOCAL and COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. 資料處理參數設定<a class=\"anchor\" id=\"3\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"'''客製參數設定'''\n\n\n'''資料參數設定'''\n\n# (String)圖片副檔名\nIMAGE_NAME_EXTENSION = '.png'\n\n# (String)CSV圖片檔名欄位\nIMAGE_NAME = 'image_id'\n\n# (String)CSV標籤欄位\nLABEL_NAME = 'class_name'\n\n# (String)CSV標籤ID欄位\nLABEL_ID = 'class_id'\n\n# (Boolean)是否標籤欄位要LabelEncoder\nLABEL_ENCODER = False\n\n# (Boolean)是否為元數據CSV的前處理\nMETA_CSV_PREPROCESSING = False\n\nif META_CSV_PREPROCESSING:\n    # (Int)圖片W尺寸\n    IMAGE_SIZE_W = 256\n\n    # (Int)圖片H尺寸\n    IMAGE_SIZE_H = 256\n    \n# (Boolean)是否為使用處理後CSV來產生標籤資料集\nUSE_CSV_GET_LABEL = True\n\nif USE_CSV_GET_LABEL:\n    # (Boolean)是否有空物件框的csv資料\n    EMPTY_BOUNDING_BOX = True\n\n    if EMPTY_BOUNDING_BOX:\n        # (Int)CSV空物件框標籤ID\n        EMPTY_BOUNDING_BOX_LABEL_ID = 14\n    \n# (Int)指定列印進度條的位置（從0開始）\nTQDM_POSITION = 0\n\n# (Boolean)保留迭代結束時進度條的所有痕跡。如果是None，只會在position是0時離開\nTQDM_LEAVE = True\n\n\n''''圖表參數設定'''\n\n# (Float)全部SNS圖表的字形縮放\nALL_SNS_FONT_SCALE = 1.0\n\n# (Int)CSV缺失值圖表寬度\nCSV_COUNTPLOT_FIGSIZE_W = 10\n\n# (Int)CSV缺失值圖表高度\nCSV_COUNTPLOT_FIGSIZE_H = 10\n\n# (Int)CSV缺失值圖表標題字型大小\nCSV_COUNTPLOT_TITLE_FONTSIZE = 20\n\n# (Int)CSV缺失值圖表X軸標題字型大小\nCSV_COUNTPLOT_XLABEL_FONTSIZE = 15\n\n# (Int)CSV缺失值圖表Y軸標題字型大小\nCSV_COUNTPLOT_YLABEL_FONTSIZE = 15","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 設置sns圖表縮放係數\nsns.set(font_scale = ALL_SNS_FONT_SCALE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. 資料處理<a class=\"anchor\" id=\"4\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"markdown","source":"## 4.1 載入CSV檔 <a class=\"anchor\" id=\"4.1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"print('Reading data...')\n\n# 讀取訓練資料集CSV檔\ntrain_csv = pd.read_csv(TRAIN_CSV_PATH,encoding=\"utf8\")\ntrain_csv['image_path'] = TRAIN_DATA_PATH + train_csv[IMAGE_NAME] + IMAGE_NAME_EXTENSION\n\nprint('Reading data completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 顯示訓練資料集CSV檔\ntrain_csv.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of train_data :\", train_csv.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 檢查CSV檔缺失值 <a class=\"anchor\" id=\"4.2\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"# 缺失值比率\ntotal = train_csv.isnull().sum().sort_values(ascending = False)\npercent = (train_csv.isnull().sum()/train_csv.isnull().count()*100).sort_values(ascending = False)\nmissing_train_csv  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_train_csv.head(missing_train_csv.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv[LABEL_NAME].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax = plt.subplots(figsize=(CSV_COUNTPLOT_FIGSIZE_W, CSV_COUNTPLOT_FIGSIZE_H))\nsns.countplot(train_csv[LABEL_NAME], hue = train_csv[LABEL_NAME],ax = ax)\nplt.title(\"LABEL COUNT\", fontsize=CSV_COUNTPLOT_TITLE_FONTSIZE)\nplt.xlabel(LABEL_NAME.upper(), fontsize=CSV_COUNTPLOT_XLABEL_FONTSIZE)\nplt.ylabel(\"COUNT\", fontsize=CSV_COUNTPLOT_YLABEL_FONTSIZE)\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if LABEL_ENCODER:\n    le = preprocessing.LabelEncoder()\n    le.fit(train_csv[LABEL_NAME])\n    print(le.classes_)\n    labels = le.transform(train_csv[LABEL_NAME])\n    train_csv[LABEL_ID] = labels\n    print(train_csv.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3 使用元數據提取圖片寬度和高度欄位 <a class=\"anchor\" id=\"4.3\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"if not META_CSV_PREPROCESSING:\n    print('Reading data...')\n\n    # 讀取訓練資料集CSV檔\n    train_meta_csv = pd.read_csv(TRAIN_META_CSV_PATH,encoding=\"utf8\")\n\n    print('Reading data completed')\n    \n    print(train_meta_csv.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not META_CSV_PREPROCESSING:\n    pbar = tqdm(train_meta_csv.iterrows(), total=train_meta_csv.shape[0], \n                position = TQDM_POSITION, leave = TQDM_LEAVE)\n    for index, row in pbar:\n        list_index = list(train_csv[train_csv[IMAGE_NAME] == row[IMAGE_NAME]].index)\n        for index in list_index:\n            train_csv.loc[index,'meta_image_width'] = row['dim1']\n            train_csv.loc[index,'meta_image_height'] = row['dim0']\n    print(train_csv.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not META_CSV_PREPROCESSING:\n    train_csv['x_min'] = train_csv.apply(lambda row: (row.x_min)/row.meta_image_width, axis =1)\n    train_csv['y_min'] = train_csv.apply(lambda row: (row.y_min)/row.meta_image_height, axis =1)\n\n    train_csv['x_max'] = train_csv.apply(lambda row: (row.x_max)/row.meta_image_width, axis =1)\n    train_csv['y_max'] = train_csv.apply(lambda row: (row.y_max)/row.meta_image_height, axis =1)\nelse:\n    train_csv['x_min'] = train_csv.apply(lambda row: (row.x_min)/IMAGE_SIZE_W, axis =1)\n    train_csv['y_min'] = train_csv.apply(lambda row: (row.y_min)/IMAGE_SIZE_H, axis =1)\n\n    train_csv['x_max'] = train_csv.apply(lambda row: (row.x_max)/IMAGE_SIZE_W, axis =1)\n    train_csv['y_max'] = train_csv.apply(lambda row: (row.y_max)/IMAGE_SIZE_H, axis =1)\n\ntrain_csv['x_mid'] = train_csv.apply(lambda row: (row.x_max+row.x_min)/2, axis =1)\ntrain_csv['y_mid'] = train_csv.apply(lambda row: (row.y_max+row.y_min)/2, axis =1)\n\ntrain_csv['width'] = train_csv.apply(lambda row: (row.x_max-row.x_min), axis =1)\ntrain_csv['height'] = train_csv.apply(lambda row: (row.y_max-row.y_min), axis =1)\n\ntrain_csv['area'] = train_csv['width']*train_csv['height']\n    \ntrain_csv.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv.to_csv(TRAIN_CSV_SAVE_FILENAME, index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.4 使用處理後CSV來產生標籤資料集 <a class=\"anchor\" id=\"4.4\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"def segregate_data(df):\n    filenames = []\n    for filename in df[IMAGE_NAME]:\n        filenames.append(filename)\n    filenames = set(filenames)\n    \n    pbar = tqdm(filenames, total = len(filenames), \n                position = TQDM_POSITION, leave = TQDM_LEAVE)\n    for filename in pbar:\n        yolo_list = []\n        \n        for _,row in df[df[IMAGE_NAME] == filename].iterrows():\n            yolo_list.append([row[LABEL_ID], row.x_mid, row.y_mid, row.width, row.height])\n\n        yolo_list = np.array(yolo_list)\n        txt_filename = os.path.join(LABEL_FOLDER_PATH, filename+\".txt\")\n        \n        # Save .txt files to the corresponding folders\n        np.savetxt(txt_filename, yolo_list, fmt=[\"%d\", \"%f\", \"%f\", \"%f\", \"%f\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if USE_CSV_GET_LABEL:\n    os.mkdir(LABEL_FOLDER_PATH)\n    if EMPTY_BOUNDING_BOX:\n        train_csv = train_csv[train_csv[LABEL_ID] != EMPTY_BOUNDING_BOX_LABEL_ID].reset_index(drop = True)\n    segregate_data(train_csv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[Go to Top](#0)","metadata":{}}]}