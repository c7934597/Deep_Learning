{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecord_Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"0\"></a>\n",
    "# Table of Contents\n",
    "\n",
    "1. [套件安裝與載入](#1)\n",
    "1. [環境檢測與設定](#2)\n",
    "1. [資料處理參數設定](#3)\n",
    "1. [資料處理](#4)\n",
    "    -  [載入CSV檔](#4.1)\n",
    "    -  [檢查CSV檔缺失值](#4.2)\n",
    "1. [圖片轉成 TFRECORD](#5)\n",
    "    -  [Data Preprocessing](#5.1)\n",
    "    -  [Definite TFRecord](#5.2)\n",
    "    -  [Label Encode Data](#5.3)\n",
    "    -  [Write TFRecord](#5.4)\n",
    "    -  [Verify TFRecord](#5.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 套件安裝與載入<a class=\"anchor\" id=\"1\"></a>\n",
    "[Back to Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料處理套件\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow深度學習模組套件\n",
    "import tensorflow as tf, re, math\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 環境檢測與設定<a class=\"anchor\" id=\"2\"></a>\n",
    "[Back to Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看tensorflow版本\n",
    "print(tf.__version__)\n",
    "\n",
    "# 查看圖像通道位置\n",
    "print(K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''執行環境參數設定'''\n",
    "\n",
    "# (Boolean)是否為本機\n",
    "LOCAL = True\n",
    "\n",
    "# (Boolean)是否為 Colab\n",
    "COLAB = False\n",
    "\n",
    "\n",
    "'''檔案路徑參數設定'''\n",
    "\n",
    "# (String)Root路徑\n",
    "if LOCAL:\n",
    "    PATH = r'../'\n",
    "elif COLAB:\n",
    "    PATH = r'/content/drive/My Drive/Colab Notebooks/'\n",
    "else:\n",
    "    PATH = r'../input/'\n",
    "    \n",
    "# (String)資料根路徑\n",
    "DATA_ROOT_PATH = PATH+r'datasets/AI_CUP_2020_AIMango_Grade_Classification/' \n",
    "\n",
    "# (String)訓練資料路徑\n",
    "TRAIN_DATA_PATH = DATA_ROOT_PATH+r'Train_Cropped'\n",
    "\n",
    "# (String)訓練CSV路徑，如為None則不讀CSV檔\n",
    "TRAIN_CSV_PATH = DATA_ROOT_PATH+r'train_cropped.csv'\n",
    "\n",
    "# (String)測試資料路徑\n",
    "TEST_DATA_PATH = DATA_ROOT_PATH+r'Test'\n",
    "\n",
    "# (String)測試CSV路徑，如為None則不讀CSV檔\n",
    "TEST_CSV_PATH = DATA_ROOT_PATH+r'test_Final_example.csv'\n",
    "\n",
    "# (String)建立裁切時需要的訓練集資料夾名稱\n",
    "TRAIN_TFRECORD_PATH = DATA_ROOT_PATH+r'Train_TFRecord'\n",
    "\n",
    "# (String)建立裁切時需要的測試集資料夾名稱\n",
    "TEST_TFRECORD_PATH = DATA_ROOT_PATH+r'Test_TFRecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOCAL and COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(TRAIN_CSV_PATH) and os.path.isfile(TEST_CSV_PATH):\n",
    "    LOAD_CSV = True\n",
    "else:\n",
    "    LOAD_CSV = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立TFRECORD圖片時需要的資料夾\n",
    "if not os.path.isdir(TRAIN_TFRECORD_PATH):\n",
    "    os.mkdir(TRAIN_TFRECORD_PATH)\n",
    "\n",
    "if not os.path.isdir(TEST_TFRECORD_PATH):\n",
    "    os.mkdir(TEST_TFRECORD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 資料處理參數設定<a class=\"anchor\" id=\"3\"></a>\n",
    "5.2 Definite TFRecord & 5.3 Label Encode Data & 5.5 Verify TFRecord 有需要再去調整\n",
    "\n",
    "[Back to Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''客製參數設定'''\n",
    "\n",
    "\n",
    "'''資料參數設定'''\n",
    "\n",
    "# (Int)圖片尺寸\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "# (Int)每批訓練的尺寸\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 是否要轉成TFRECORD\n",
    "CONVERT_TFRECORD = True\n",
    "\n",
    "# 是否要轉換圖像RGB2BGR\n",
    "CONVERT_RGB2BGR = False\n",
    "\n",
    "# 是否驗證顯示TFRECORD\n",
    "VERIFY_TFRECORD = False\n",
    "\n",
    "# (String)圖片副檔名\n",
    "IMAGE_NAME_EXTENSION = '.jpg'\n",
    "\n",
    "# (Boolean)CSV圖片檔名欄位是否包含副檔名\n",
    "IMAGE_NAME_HAVE_EXTENSION = True\n",
    "\n",
    "# (Int)不包含副檔名的圖片檔名長度，因為CSV檔名欄位有副檔名時需要移除\n",
    "IMAGE_NAME_LENGTH = 5\n",
    "\n",
    "# (String list)CSV訓練集須移除的多餘欄位\n",
    "TRAIN_REMOVE_NAME = [\"pos_x\", \"pos_y\",\"width\",\"height\"]\n",
    "\n",
    "# (String list)CSV測試集須移除的多餘欄位\n",
    "TEST_REMOVE_NAME = []\n",
    "\n",
    "# (String)CSV圖片檔名欄位(不包含路徑)\n",
    "IMAGE_NAME = 'image_id'\n",
    "\n",
    "# (String)CSV訓練集標籤欄位\n",
    "TRAIN_LABEL_NAME = 'grade'\n",
    "\n",
    "# (String)CSV測試集標籤欄位\n",
    "TEST_LABEL_NAME = 'label'\n",
    "\n",
    "# (String)TFRecord圖片檔名欄位(不包含路徑)\n",
    "TFRECORD_IMAGE_NAME = 'image_name'\n",
    "\n",
    "# (String)TFRecord標籤欄位\n",
    "TFRECORD_LABEL_NAME = 'label'\n",
    "\n",
    "# (String List)TFRecord要編碼化的欄位\n",
    "LABEL_ENCODE_NAME = [TFRECORD_LABEL_NAME]\n",
    "\n",
    "# 設定TFRECORD總層數，為了計算tfrsize有多大\n",
    "TFRECORD = 20\n",
    "\n",
    "# 設定訓練集images數量，為了計算tfrsize有多大\n",
    "TRAIN_IMG = 52000\n",
    "\n",
    "# 設定測試集images數量，為了計算tfrsize有多大\n",
    "TEST_IMG = 13000\n",
    "\n",
    "# (String List)分類項目\n",
    "CLASSES_LIST = ['A','B','C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 資料處理<a class=\"anchor\" id=\"4\"></a>\n",
    "[Back to Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 載入CSV檔 <a class=\"anchor\" id=\"4.1\"></a>\n",
    "[Back to Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_CSV:\n",
    "    print('Reading data...')\n",
    "\n",
    "    # 讀取訓練資料集CSV檔\n",
    "    train_csv = pd.read_csv(TRAIN_CSV_PATH,encoding=\"utf8\")\n",
    "\n",
    "    # 讀取測試資料集CSV檔\n",
    "    test_csv = pd.read_csv(TEST_CSV_PATH,encoding=\"utf8\")\n",
    "\n",
    "    print('Reading data completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_CSV:\n",
    "    # 顯示訓練資料集CSV檔\n",
    "    print(train_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_CSV:\n",
    "    print(\"Shape of train_data :\", train_csv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_CSV:\n",
    "    # 顯示測試資料集CSV檔\n",
    "    print(test_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_CSV:\n",
    "    print(\"Shape of test_data :\", test_csv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 檢查CSV檔缺失值 <a class=\"anchor\" id=\"4.2\"></a>\n",
    "[Back to Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_CSV:\n",
    "    total = train_csv.isnull().sum().sort_values(ascending = False)\n",
    "    percent = (train_csv.isnull().sum()/train_csv.isnull().count()*100).sort_values(ascending = False)\n",
    "    missing_train_csv  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    print(missing_train_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_CSV:\n",
    "    print(train_csv[TRAIN_LABEL_NAME].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 圖片轉成 TFRecord<a class=\"anchor\" id=\"5\"></a>\n",
    "https://www.kaggle.com/cdeotte/how-to-create-TFRECORDS\n",
    "\n",
    "[Back to Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Data Preprocessing<a class=\"anchor\" id=\"5.1\"></a>\n",
    "[Back to Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONVERT_TFRECORD and LOAD_CSV:\n",
    "    # TRAIN_CROPPED_PATH to images\n",
    "    train_imgs = os.listdir(TRAIN_DATA_PATH);\n",
    "    print('There are %i train images'%(len(train_imgs)))\n",
    "\n",
    "    # TEST_CROPPED_PATH to images\n",
    "    test_imgs = os.listdir(TEST_DATA_PATH);\n",
    "    print('There are %i test images'%(len(test_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONVERT_TFRECORD and LOAD_CSV:\n",
    "    train_csv = train_csv.drop(columns=TRAIN_REMOVE_NAME)\n",
    "    # CSV檔名欄位包括副檔名時，需要移除副檔名\n",
    "    if IMAGE_NAME_HAVE_EXTENSION:\n",
    "        train_csv[IMAGE_NAME] = train_csv[IMAGE_NAME].str.slice(stop = IMAGE_NAME_LENGTH)\n",
    "    train_csv.rename({IMAGE_NAME:TFRECORD_IMAGE_NAME,TRAIN_LABEL_NAME:TFRECORD_LABEL_NAME},axis=1,inplace=True)\n",
    "    print(train_csv.shape)\n",
    "    print(train_csv.head())\n",
    "    \n",
    "if CONVERT_TFRECORD and LOAD_CSV:\n",
    "    test_csv = test_csv.drop(columns=TEST_REMOVE_NAME)\n",
    "    if IMAGE_NAME_HAVE_EXTENSION:\n",
    "        test_csv[IMAGE_NAME] = test_csv[IMAGE_NAME].str.slice(stop = IMAGE_NAME_LENGTH)\n",
    "    test_csv.rename({IMAGE_NAME:TFRECORD_IMAGE_NAME,TEST_LABEL_NAME:TFRECORD_LABEL_NAME},axis=1,inplace=True)\n",
    "    print(test_csv.shape)\n",
    "    print(test_csv.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Definite TFRecord<a class=\"anchor\" id=\"5.2\"></a>\n",
    "[Back to Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONVERT_TFRECORD:\n",
    "    def _bytes_feature(value):\n",
    "        \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "        if isinstance(value, type(tf.constant(0))):\n",
    "            value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    def _int64_feature(value):\n",
    "        \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "    \n",
    "    def _float_feature(value):\n",
    "        \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONVERT_TFRECORD:\n",
    "    def train_serialize_example(feature0, feature1, feature2):\n",
    "        \"\"\"\n",
    "        Creates a tf.Example message ready to be written to a file.\n",
    "        \"\"\"\n",
    "        # Create a dictionary mapping the feature name to the tf.Example-compatible\n",
    "        # data type.\n",
    "        feature = {\n",
    "            'image': _bytes_feature(feature0),\n",
    "            TFRECORD_IMAGE_NAME: _bytes_feature(feature1),\n",
    "            TFRECORD_LABEL_NAME: _int64_feature(feature2)\n",
    "        }\n",
    "        # Create a Features message using tf.train.Example.\n",
    "        example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        return example_proto.SerializeToString()\n",
    "    \n",
    "    def test_serialize_example(feature0, feature1):\n",
    "        \"\"\"\n",
    "        Creates a tf.Example message ready to be written to a file.\n",
    "        \"\"\"\n",
    "        # Create a dictionary mapping the feature name to the tf.Example-compatible\n",
    "        # data type.\n",
    "        feature = {\n",
    "            'image': _bytes_feature(feature0),\n",
    "            TFRECORD_IMAGE_NAME: _bytes_feature(feature1),\n",
    "        }\n",
    "        # Create a Features message using tf.train.Example.\n",
    "        example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Label Encode Data<a class=\"anchor\" id=\"5.3\"></a>\n",
    "[Back to Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONVERT_TFRECORD and LOAD_CSV:\n",
    "    # LABEL ENCODE ALL STRINGS\n",
    "    cats = LABEL_ENCODE_NAME \n",
    "    for c in cats:\n",
    "        train_csv[c],mp = train_csv[c].factorize()\n",
    "        print(train_csv[c])\n",
    "        print(\"=========\")\n",
    "        print(mp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Write TFRecord<a class=\"anchor\" id=\"5.4\"></a>\n",
    "[Back to Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONVERT_TFRECORD:\n",
    "    # 通過TFRECORD跟images數量，計算tfrsize有多大\n",
    "    TRAIN_TFRSIZE = math.ceil(TRAIN_IMG / TFRECORD)\n",
    "    TEST_TFRSIZE = math.ceil(TEST_IMG / TFRECORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONVERT_TFRECORD and LOAD_CSV:\n",
    "    train_ct = len(train_imgs)//TRAIN_TFRSIZE + int(len(train_imgs)%TRAIN_TFRSIZE!=0)    \n",
    "    for j in range(train_ct):\n",
    "        print('Writing Train TFRECORDS %i of %i...'%(j,train_ct))\n",
    "        train_ct2 = min(TRAIN_TFRSIZE,len(train_imgs)-j*TRAIN_TFRSIZE)\n",
    "        with tf.io.TFRecordWriter(TRAIN_TFRECORD_PATH+'/train%.2i-%i.tfrec'%(j,train_ct2)) as writer:\n",
    "            for k in range(train_ct2):\n",
    "                img = cv2.imread(TRAIN_DATA_PATH+'/'+train_imgs[TRAIN_TFRSIZE*j+k])\n",
    "                if CONVERT_RGB2BGR:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # Fix incorrect colors\n",
    "                img = cv2.imencode(IMAGE_NAME_EXTENSION, img, (cv2.IMWRITE_JPEG_QUALITY, 100))[1].tostring()\n",
    "                name = train_imgs[TRAIN_TFRSIZE*j+k].split('.')[0]\n",
    "                row = train_csv.loc[train_csv[TFRECORD_IMAGE_NAME] == name]\n",
    "                example = train_serialize_example(img, str.encode(name), row.label.values[0])\n",
    "                writer.write(example)\n",
    "                if k%100==0: \n",
    "                    print(k,', ',end='')\n",
    "\n",
    "    test_ct = len(test_imgs)//TEST_TFRSIZE + int(len(test_imgs)%TEST_TFRSIZE!=0)    \n",
    "    for j in range(test_ct):\n",
    "        print('Writing Test TFRECORDS %i of %i...'%(j,test_ct))\n",
    "        test_ct2 = min(TEST_TFRSIZE,len(test_imgs)-j*TEST_TFRSIZE)\n",
    "        with tf.io.TFRecordWriter(TEST_TFRECORD_PATH+'/test%.2i-%i.tfrec'%(j,test_ct2)) as writer:\n",
    "            for k in range(test_ct2):\n",
    "                img = cv2.imread(TEST_DATA_PATH+'/'+test_imgs[TEST_TFRSIZE*j+k])\n",
    "                if CONVERT_RGB2BGR:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # Fix incorrect colors\n",
    "                img = cv2.imencode(IMAGE_NAME_EXTENSION, img, (cv2.IMWRITE_JPEG_QUALITY, 100))[1].tostring()\n",
    "                name = test_imgs[TEST_TFRSIZE*j+k].split('.')[0]\n",
    "                row = test_csv.loc[test_csv[TFRECORD_IMAGE_NAME] == name]\n",
    "                example = test_serialize_example(img, str.encode(name))\n",
    "                writer.write(example)\n",
    "                if k%100==0: \n",
    "                    print(k,', ',end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONVERT_TFRECORD:\n",
    "    # 查看資料夾檔案\n",
    "    print(sorted(os.listdir(TRAIN_TFRECORD_PATH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONVERT_TFRECORD:\n",
    "    # 查看資料夾檔案\n",
    "    print(sorted(os.listdir(TEST_TFRECORD_PATH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Verify TFRecord<a class=\"anchor\" id=\"5.5\"></a>\n",
    "[Back to Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=15, linewidth=80)\n",
    "\n",
    "def batch_to_numpy_images_and_labels(data):\n",
    "    images, labels = data\n",
    "    numpy_images = images.numpy()\n",
    "    numpy_labels = labels.numpy()\n",
    "    #if numpy_labels.dtype == object: # binary string in this case, these are image ID strings\n",
    "    #    numpy_labels = [None for _ in enumerate(numpy_images)]\n",
    "    # If no labels, only image IDs, return None for labels (this is the case for test data)\n",
    "    return numpy_images, numpy_labels\n",
    "\n",
    "def title_from_label_and_target(label, correct_label):\n",
    "    if correct_label is None:\n",
    "        return CLASSES_LIST[label], True\n",
    "    correct = (label == correct_label)\n",
    "    return \"{} [{}{}{}]\".format(CLASSES_LIST[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n",
    "                                CLASSES_LIST[correct_label] if not correct else ''), correct\n",
    "\n",
    "def display_one(image, title, subplot, red=False, titlesize=16):\n",
    "    plt.subplot(*subplot)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "    if len(title) > 0:\n",
    "        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n",
    "    return (subplot[0], subplot[1], subplot[2]+1)\n",
    "    \n",
    "def display_batch_of_images(databatch, predictions=None):\n",
    "    \"\"\"This will work with:\n",
    "    display_batch_of_images(images)\n",
    "    display_batch_of_images(images, predictions)\n",
    "    display_batch_of_images((images, labels))\n",
    "    display_batch_of_images((images, labels), predictions)\n",
    "    \"\"\"\n",
    "    # data\n",
    "    images, labels = batch_to_numpy_images_and_labels(databatch)\n",
    "    if labels is None:\n",
    "        labels = [None for _ in enumerate(images)]\n",
    "        \n",
    "    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n",
    "    rows = int(math.sqrt(len(images)))\n",
    "    cols = len(images)//rows\n",
    "        \n",
    "    # size and spacing\n",
    "    FIGSIZE = 13.0\n",
    "    SPACING = 0.1\n",
    "    subplot=(rows,cols,1)\n",
    "    if rows < cols:\n",
    "        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n",
    "    else:\n",
    "        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n",
    "    \n",
    "    # display\n",
    "    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n",
    "        title = label\n",
    "        correct = True\n",
    "        if predictions is not None:\n",
    "            title, correct = title_from_label_and_target(predictions[i], label)\n",
    "        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n",
    "        subplot = display_one(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n",
    "    \n",
    "    #layout\n",
    "    plt.tight_layout()\n",
    "    if label is None and predictions is None:\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    else:\n",
    "        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    image = tf.reshape(image, [IMAGE_SIZE, IMAGE_SIZE, 3]) # explicit size needed for TPU\n",
    "    return image\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        TFRECORD_IMAGE_NAME: tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    label = example[TFRECORD_IMAGE_NAME]\n",
    "    return image, label # returns a dataset of (image, label) pairs\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
    "\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(read_labeled_tfrecord)\n",
    "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
    "    return dataset\n",
    "\n",
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n",
    "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE VARIABLES\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "TRAINING_FILENAMES = tf.io.gfile.glob(TRAIN_TFRECORD_PATH+'/train*.tfrec')\n",
    "print('There are %i train images'%count_data_items(TRAINING_FILENAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VERIFY_TFRECORD:\n",
    "    # DISPLAY TRAIN IMAGES\n",
    "    training_dataset = get_training_dataset()\n",
    "    training_dataset = training_dataset.unbatch().batch(20)\n",
    "    train_batch = iter(training_dataset)\n",
    "\n",
    "    display_batch_of_images(next(train_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}