{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Semantic_Segmentation_Pytorch (Training)\n","https://zhuanlan.zhihu.com/p/159173338"],"metadata":{}},{"cell_type":"markdown","source":["<a class=\"anchor\" id=\"0\"></a>\n","# Table of Contents\n","\n","1. [套件安裝與載入](#1)\n","1. [環境檢測與設定](#2)\n","1. [開發參數設定](#3)\n","1. [資料處理](#4)\n","    -  [載入CSV檔](#4.1)\n","1. [定義模型方法](#5)\n","1. [定義回調函數方法](#6)\n","1. [製作資料集＆資料擴增&回調函數&訓練模型](#7)\n","1. [待辦事項](#8)"],"metadata":{}},{"cell_type":"markdown","source":["# 1. 套件安裝與載入<a class=\"anchor\" id=\"1\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}},{"cell_type":"code","source":["!pip3 install git+https://github.com/qubvel/segmentation_models.pytorch"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 資料處理套件\n","import os\n","import gc\n","import cv2\n","import sys\n","import time\n","import copy\n","import random\n","import datetime\n","import numpy as np\n","import pandas as pd\n","import albumentations as A\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import segmentation_models_pytorch as smp\n","\n","from tqdm import tqdm\n","from albumentations.pytorch.transforms import ToTensorV2\n","from sklearn.model_selection import train_test_split, GroupKFold\n","from sklearn.metrics import roc_auc_score\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 設定顯示中文字體\n","from matplotlib.font_manager import FontProperties\n","plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei'] # 用來正常顯示中文標籤\n","plt.rcParams['font.family'] = 'AR PL UMing CN'\n","plt.rcParams['axes.unicode_minus'] = False # 用來正常顯示負號"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pytorch深度學習模組套件\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as data\n","import torch.nn.functional as F\n","import torchvision\n","\n","from torch.optim import lr_scheduler\n","from torch.cuda.amp import autocast, GradScaler\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from torchvision import models"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. 環境檢測與設定<a class=\"anchor\" id=\"2\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}},{"cell_type":"code","source":["DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","DEVICE"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''執行環境參數設定'''\n","\n","# (Boolean)是否為本機\n","LOCAL = False\n","\n","# (Boolean)是否為 Colab\n","COLAB = False\n","\n","\n","'''檔案路徑參數設定'''\n","\n","# (String)Root路徑\n","if LOCAL:\n","    PATH = r'../'\n","elif COLAB:\n","    PATH = r'/content/drive/My Drive/Colab Notebooks/'\n","else:\n","    PATH = r'../input/'\n","    OUTPUT_PATH = r'/kaggle/working/'\n","    \n","# (String)資料根路徑\n","DATA_ROOT_PATH = PATH+r'hubmap-256x256/' \n","\n","# (String)訓練資料路徑\n","TRAIN_DATA_PATH = DATA_ROOT_PATH+r'train/'\n","\n","# (String)訓練資料Mask路徑\n","TRAIN_DATA_MASK_PATH = DATA_ROOT_PATH+r'masks/'\n","\n","# (String)訓練CSV路徑，如為None則不讀CSV檔\n","TRAIN_CSV_PATH = DATA_ROOT_PATH+r'train.csv'\n","\n","# (String)專案名稱\n","PROJECT_NAME = 'hubmap-kidney-segmentation'\n","\n","# (Boolean)是否要匯入Library\n","IMPORT_PYTORCH_LIBRARY = False\n","\n","# (String)Library的路徑\n","PYTORCH_LIBRARY_PATH = PATH + \"PyTorch_Library/\"\n","\n","# (String)專案檔案儲存路徑\n","if LOCAL or COLAB:\n","    OUTPUT_PATH = PATH\n","PROJECT_PATH = OUTPUT_PATH+PROJECT_NAME+'/'+PROJECT_NAME+' '+datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n","\n","# (String)權重名稱(使用哪個權重)\n","WEIGHTS_NAME = 'efficientnet_b0'\n","\n","# (String)模型名稱(使用哪個模型)\n","MODEL_NAME = 'efficientnet_b0'\n","\n","# (String)讀取預訓練權重的儲存路徑\n","LOAD_WEIGHTS_PATH = PROJECT_PATH+r'/models/pretrain_weights/'+WEIGHTS_NAME+'.pth'\n","\n","# (String)讀取預訓練模型的儲存路徑\n","LOAD_MODEL_PATH = PROJECT_PATH+r'/models/pretrain_models/'+MODEL_NAME+'.pth'\n","\n","# (Boolean)是否建立訓練模型儲存的時間戳資料夾\n","MODEL_TIME_FOLDER = False\n","# (String)訓練模型的儲存路徑\n","if MODEL_TIME_FOLDER:\n","    TRAIN_MODEL_PATH = PROJECT_PATH+r'/models/'+MODEL_NAME+'.pth'\n","else:\n","    TRAIN_MODEL_PATH = MODEL_NAME+'.pth'"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if DEVICE != torch.device(\"cpu\"):\n","    !nvidia-smi"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if not LOCAL and COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","if MODEL_TIME_FOLDER:   \n","    if not os.path.isdir(PROJECT_PATH+r'/models/'):\n","        os.makedirs(PROJECT_PATH+r'/models/')\n","    \n","if IMPORT_PYTORCH_LIBRARY:\n","    sys.path.append(PYTORCH_LIBRARY_PATH + \"Custom_Loss.py\")\n","    sys.path.append(PYTORCH_LIBRARY_PATH + \"Custom_Model.py\")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. 開發參數設定<a class=\"anchor\" id=\"3\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}},{"cell_type":"code","source":["'''客製參數設定'''\n","\n","\n","'''資料參數設定'''\n","\n","# (Int)分類數量\n","CLASSES = 1\n","\n","# (Int)有CSV檔該參數才有用，1則為不做交叉驗證\n","FOLD = 2\n","    \n","# (Int)圖片尺寸\n","IMAGE_SIZE = [256]*FOLD\n","\n","# (String)圖片副檔名\n","IMAGE_NAME_EXTENSION = '.png'\n","\n","# (String)CSV圖片檔名欄位\n","IMAGE_NAME = 'id'\n","\n","# (Boolean)CSV圖片檔名欄位是否包含副檔名\n","IMAGE_NAME_HAVE_EXTENSION = True\n","\n","#  (Boolean)圖像轉為RGB\n","COLOR_CONVERT_RGB = True\n","\n","# (Int)不同的種子會產生不同的Random或分層K-FOLD分裂, 42則是預設固定種子\n","SEED = 42\n","\n","if FOLD == 1:\n","    # (Float)驗證集佔訓練集的比率，FOLD>1則不啟用\n","    DATA_SPLIT = 0.2\n","else:\n","    # (String)切分訓練集跟驗證集方式 GroupKFold\n","    KF = GroupKFold(n_splits = FOLD)\n","\n","# (Boolean)是否資料轉Tensor時啟動鎖頁內存(GPU內存)，而不鎖頁內存就是會使用到硬碟虛擬內存\n","PIN_MEMORY = False\n","\n","# (Int)要用於數據加載的子進程數。0表示將在主進程中加載數據。（默認值：0）\n","NUM_WORKERS = 0\n","\n","# (Boolean)批次處理在大小不合適的情況下，是否刪除最後一個不完整的批次\n","DROP_LAST = False\n","    \n","# (Boolean)如為True每次返回的卷積算法將是確定的，即默認算法\n","CUDNN_DETERMINISTIC = True\n","\n","# (Boolean)PyTorch 中對模型裡的卷積層進行預先的優化，也就是在每一個卷積層中測試 cuDNN 提供的所有卷積實現算法，\n","# 然後選擇最快的那個。這樣在模型啟動的時候，只要額外多花一點點預處理時間，就可以較大幅度地減少訓練時間\n","CUDNN_BENCHMARK = True\n","\n","\n","'''資料擴增參數設定\n","\n","資料擴增教學\n","https://zhuanlan.zhihu.com/p/107399127\n","\n","資料擴增Doc\n","https://vfdev-5-albumentations.readthedocs.io/en/docs_pytorch_fix/api/augmentations.html\n","'''\n","\n","# (Float)訓練集資料擴增的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_TRAIN_TRANSFORMS = 1.0\n","\n","# (Float)驗證集資料擴增的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_VAL_TRANSFORMS = 1.0\n","\n","# 以下資料擴增為訓練集使用=============================================\n","\n","# (Float)模糊的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_BLUR = 0\n","\n","# (Int)模糊的上限\n","BLUR_LIMIT = 3\n","\n","# (Float)水平翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_HORIZONTALFLIP = 0\n","\n","# (Float)垂直翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_VERTICALFLIP = 0\n","\n","# (Float)水平和垂直翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_FLIP = 0\n","\n","# (Float)隨機旋轉90度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_RANDOMROTATE90 = 0\n","\n","# (Float)平移縮放旋轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_SHIFTSCALEROTATE = 0\n","\n","# (Float)平移縮放旋轉的平移上限\n","SHIFTSCALEROTATE_SHIFT_LIMIT = 0.0625\n","\n","# (Float)平移縮放旋轉的縮放上限\n","SHIFTSCALEROTATE_SCALE_LIMIT = 0.1\n","\n","# (Float)平移縮放旋轉的旋轉上限\n","SHIFTSCALEROTATE_ROTATE_LIMIT = 45\n","\n","# (Float)彈性變換的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_ELATICTRANSFORM = 0\n","\n","# (Float)彈性變換的alpha高斯過濾參數\n","ELATICTRANSFORM_ALPHA = 1\n","\n","# (Float)彈性變換的sigma高斯過濾參數\n","ELATICTRANSFORM_SIGMA = 50\n","\n","# (Float)彈性變換的alpha_affine，範圍為（-alpha_affine，alpha_affine）\n","ELATICTRANSFORM_ALPHA_AFFINE = 50\n","\n","# (Float)網格失真的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_GRIDDISTORTION = 0\n","\n","# (Int)網格失真的每一條邊上網格單元數量\n","GRIDDISTORTION_NUM_STEPS = 5\n","\n","# (Float)隨機亮度對比度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_RANDOMBRIGHTNESSCONTRAST_CONTRAST = 0\n","\n","# (Float)隨機亮度的上限\n","RANDOMBRIGHTNESSCONTRAST_BRIGHTNESS_LIMIT = 0.2\n","\n","# (Float)隨機對比度的上限\n","RANDOMBRIGHTNESSCONTRAST_CONTRAST_LIMIT = 0.2\n","\n","# (Float)隨機色調飽和度的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_HUESATURATIONVALUE = 0\n","\n","# (Float)隨機色調飽和度的色調上限\n","HUESATURATIONVALUE_HUE_SHIFT_LIMIT = 20\n","\n","# (Float)隨機色調飽和度的飽和度上限\n","HUESATURATIONVALUE_SAT_SHIFT_LIMIT = 30\n","\n","# (Float)隨機色調飽和度的值上限\n","HUESATURATIONVALUE_VAL_SHIFT_LIMIT = 20\n","\n","# (Float)對比度受限自適應直方圖均衡的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_CLAHE = 0\n","\n","# (Float)對比度受限自適應直方圖均衡的對比度上限\n","CLAHE_CLIP_LIMIT = 4.0\n","\n","# (Float)隨機在圖像上生成黑色矩形的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_COARSEDROPOUT = 0\n","\n","# (Int)隨機在圖像上生成黑色矩形的數量\n","COARSEDROPOUT_NUM_HOLES = 8\n","\n","# (Int)隨機在圖像上生成黑色矩形的最大高度\n","COARSEDROPOUT_MAX_H_SIZE = 8\n","\n","# (Int)隨機在圖像上生成黑色矩形的最大寬度\n","COARSEDROPOUT_MAX_W_SIZE = 8\n","\n","# (Float)隨機縮放剪裁的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_RANDOMRESIZEDCROP = 0\n","\n","# (Float Tuple)隨機縮放剪裁之前的圖像比例縮放\n","RANDOMRESIZEDCROP_SCALE = (0.08, 1.0)\n","\n","# (Int)隨機縮放剪裁之前的圖像高度\n","RANDOMRESIZEDCROP_HEIGHT = IMAGE_SIZE[0]\n","\n","# (Int)隨機縮放剪裁之前的圖像寬度\n","RANDOMRESIZEDCROP_WIDTH = IMAGE_SIZE[0]\n","\n","# 以上資料擴增為訓練集使用=============================================\n","\n","# 以下資料擴增為訓練集和驗證集共用======================================\n","\n","# (Float)縮放的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_RESIZE = 1.0\n","\n","# (Int)縮放後的圖片高度\n","RESIZE_HEIGHT = IMAGE_SIZE[0]\n","\n","# (Int)縮放後的圖片寬度\n","RESIZE_WIDTH = IMAGE_SIZE[0]\n","\n","# (Float)正規化的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","P_NORMALIZE = 1.0\n","\n","# (List)正規化的平均值([0,1]的參考平均值:[0.485, 0.456, 0.406], [-1,1]的參考平均值:[0.5, 0.5, 0.5])\n","NORMALIZE_MEAN = [0.485, 0.456, 0.406]\n","\n","# (List)正規化的標準差([0,1]的參考標準差[0.229, 0.224, 0.225], [-1,1]的參考標準差[0.5, 0.5, 0.5])\n","NORMALIZE_STD = [0.229, 0.224, 0.225]\n","\n","# (Float)正規化的PIXEL最大值(參考PIXEL最大值255.0)\n","NORMALIZE_MAX_PIXEL_VALUE = 255.0\n","\n","# (Float)歸一化的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\n","# ToTensorV2()將[0, 255]的PIL.Image或[H, W, C]的numpy.ndarray數據，\n","# 轉換為形狀[C, H, W]的torch.FloadTensor，並歸一化。\n","P_TOTENSORV2 = 1.0\n","\n","# 以上資料擴增為訓練集和驗證集共用======================================\n","\n","\n","''''模型參數設定'''\n","\n","# (Boolean)是否依照設定路徑，載入完整客製(模型+權重)\n","LOAD_MODEL = False\n","\n","# (Boolean)使用客制模型，None則使用基本模型\n","CUSTOM_MODEL = None\n","\n","# (Boolean)是否依照設定路徑，已有客製模型，僅載入權重\n","LOAD_WEIGHTS = False\n","\n","if CUSTOM_MODEL is None and not LOAD_MODEL:\n","    # https://github.com/qubvel/segmentation_models.pytorch\n","    # (Boolean)使用基礎smp模型，如為False則使用基礎Pytorch模型\n","    USE_BASE_SMP_MODEL = True\n","    \n","    if USE_BASE_SMP_MODEL:\n","        # (Model)建立基礎SMP模型\n","        BASE_MODEL = smp.Unet\n","        \n","        # (String)建立基礎SMP模型編碼器\n","        BASE_MODEL_ENCODER = \"efficientnet-b0\"\n","        \n","        # (String)SMP編碼器預訓練權重為 imagenet\n","        ENCODER_WEIGHTS = \"imagenet\"\n","        \n","        # (Int)模型輸入通道（1個用於灰度圖像，3個用於RGB等）\n","        IN_CHANNELS = 3\n","        \n","        # (String)SMP最終卷積後應用的激活函數 None\n","        SMP_MODEL_ACTIVATION = None\n","    else:\n","        # (Model)建立Pytorch模型\n","        BASE_MODEL = models.segmentation.fcn_resnet50\n","        \n","        # (Boolean)是否使用Pytorch模型權重\n","        LOAD_BASE_WEIGHTS = True\n","        \n","        # (String)Pytorch模型主分類器\n","        BASE_MODEL_CLASSIFIER = nn.Conv2d(512, CLASSES, kernel_size = 1, stride = 1)\n","        \n","        # (String)Pytorch模型輔助分類器\n","        BASE_MODEL_AUX_CLASSIFIER = nn.Conv2d(256, CLASSES, kernel_size = 1, stride = 1)\n","\n","# (Boolean)是否印出完整模型\n","MODEL_PRINT = False\n","\n","\n","''''回調函數參數設定\n","\n","學習率遞減\n","https://zhuanlan.zhihu.com/p/69411064\n","\n","回調函數Doc\n","https://pytorch.org/docs/stable/optim.html\n","\n","'''\n","\n","# (Boolean)回調函數 ModelCheckpoint 是否啟用\n","CALLBACKS_CHECK_POINTER = True\n","\n","# (Boolean)回調函數 EarlyStopping 是否啟用\n","CALLBACKS_EARLY_STOPPING = True\n","\n","# (Boolean)回調函數 StepLR 是否啟用\n","CALLBACKS_STEPLR = True\n","\n","# (Boolean)回調函數 ReduceLROnPlateau 是否啟用\n","CALLBACKS_REDUCELRONPLATEAU = False\n","\n","# (Boolean)回調函數 CosineAnnealingWarmRestarts 是否啟用\n","CALLBACKS_COSINEANNEALINGWARMRESTAERS = False\n","\n","# (Boolean)回調函數 TensorBoard 是否啟用(訓練epoch step指標計算有啟用才有用)\n","CALLBACKS_TENSOR_BOARD = False\n","\n","# (String)回調函數監控數值 val_dice_coeff/val_loss\n","MONITOR = 'val_dice_coeff'\n","\n","# (Boolean)回調函數 ModelCheckpoint 是否只儲存最佳 False\n","SAVE_BEST_ONLY = True\n","\n","# (Boolean)回調函數 ModelCheckpoint 是否只儲存權重 True\n","SAVE_WEIGHTS_ONLY = True\n","\n","# (Int)回調函數 EarlyStopping 沒有改善的時期數，之後訓練將停止 10\n","PATIENCE_ELS = 5\n","\n","# (Int)學習率衰減的時間段，意思每過多少epoch會衰減\n","STEP_SIZE = 5\n","\n","# (Float)學習率衰減的乘數 0.1\n","GAMMA = 0.1\n","\n","# (String)最小，最大之一 在最小模式下，當監視的數量停止減少時，lr將減小； 在最大模式下，當監視的數量停止增加時，它將減少。 min\n","MODE = \"min\"\n","\n","# (Float)學習率降低的因數。new_lr = lr *因子 0.1\n","FACTOR = 0.1\n","\n","# (Int)沒有改善的時期數，此後學習率將降低。例如，如果 耐心= 2，那麼我們將忽略前兩個時期而沒有任何改善，\n","# 並且如果損失仍然沒有改善，則只會在第三個時期之後降低LR。 10\n","PATIENCE = 10 \n","\n","# (Float)用於測量新的最佳閾值，僅關注重大變化。 1e-4\n","THRESHOLD = 1e-4 \n","\n","# (String)rel，abs之一。在rel模式下，“ max”模式下的dynamic_threshold = best *（1 +閾值），在min模式下，\n","# dynamic_threshold = best *（1-threshold）。在絕對模式下，dynamic_threshold =最佳+ 最大模式下的閾值或最佳-最小模式下的閾值。 rel\n","THRESHOLD_MODE = \"rel\"\n","\n","# (Int)減少lr後恢復正常運行之前要等待的時期數。 0 \n","COOLDOWN = 0\n","\n","# (Float/List)標量或標量列表。所有參數組或每個組的學習率的下限。 0 \n","MIN_LR = 0\n","\n","# (Float)應用於lr的最小衰減。如果新舊lr之間的差異小於eps，則忽略該更新。 1e-8\n","SCHEDULER_EPS = 1e-8\n","\n","# (Int)第一次重啟的迭代次數。\n","T_0 = 15\n","\n","# (Int)重新啟動後，因素增加。 1 \n","T_MULT = 1\n","\n","# (Int)最低學習率。 0\n","ETA_MIN = 0\n","\n","# (Boolean)每次更新，學習率回調函式都會向輸出印出一條消息。 False\n","SCHEDULER_VERBOSE = False\n","\n","# (Boolean)訓練集每批就更新學習率回調函式，否則每時代就更新。 False\n","SCHEDULER_BATCH_UPDATE = False\n","\n","# (Boolean)驗證集學習率回調函式是否啟用。 False\n","VAL_ENABLE_SCHEDULER = False\n","\n","# (Boolean)驗證集通過計算LOSS就更新學習率回調函式，否則不計算就更新。 False\n","SCHEDULER_LOSS_UPDATE = False\n","\n","# (String)TensorBoard儲存檔案的註解\n","TENSOR_BOARD_COMMENT = PROJECT_NAME\n","\n","\n","''''編譯參數設定\n","\n","編譯參數Doc\n","https://pytorch.org/docs/stable/optim.html\n","\n","'''\n","\n","# (String)優化器指定(SGD/Adam/Adamax/RMSprop/Adagrad)\n","OPTIMIZERS_TYPE = \"Adam\"\n","\n","# (Float)優化器學習率 1e-3/1e-1\n","LEARNING_RATE = 1e-3\n","\n","# (Float)學習速率衰減 0\n","LR_DECAY = 0\n","\n","# (Float)優化器權重衰減 5e-5/5e-4\n","WEIGHT_DECAY = 5e-5\n","\n","# (Float)加速優化器在相關方向上前進，並抑制震盪 0.9\n","MOMENTUM = None\n","\n","# (Tuple Float)用於計算梯度及其平方的移動平均值的係數 (0.9, 0.999)\n","BETAS = (0.9, 0.999)\n","\n","# (Float)分母中添加的項，以提高數值穩定性 1e-8\n","EPS = 1e-8\n","\n","# (Float)平滑常數 0.99\n","ALPHA = 0.99\n","\n","# (Boolean)計算居中RMSProp，則通過估計其方差來對梯度進行歸一化 True\n","CENTERED = True\n","\n","# (Float)阻尼動量 0\n","DAMPENING = 0\n","\n","# (Boolean)啟用Nesterov動量 False\n","NESTEROV = False\n","\n","# (Boolean)客制損失函數\n","CUSTOM_LOSSES = nn.BCEWithLogitsLoss(reduction = \"mean\")\n","\n","# (String )評價指標的圖表顯示 dice_coeff\n","PLOT_METRICS = 'dice_coeff'\n","\n","# (Boolean)是否印出完整編譯器\n","OPTIMIZER_PRINT = False\n","\n","\n","''''訓練參數設定'''\n","\n","# (Boolean)是否啟用混合精度訓練\n","AMP_SCALE_TRAIN = False\n","\n","# (Int List)每批訓練的尺寸\n","BATCH_SIZE = [32]*FOLD\n","\n","# (Int)訓練做幾次時代\n","EPOCHS = [1]*FOLD\n","\n","# (Int)指定列印進度條的位置（從0開始）\n","TQDM_POSITION = 0\n","\n","# (Boolean)保留迭代結束時進度條的所有痕跡。如果是None，只會在position是0時離開\n","TQDM_LEAVE = True\n","\n","# https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2021/02/19/gradient-accumulation.html\n","# (Int)假設您要在一批中使用32張圖像，但是一旦超出8張，硬件就會崩潰\n","# 在這種情況下，您可以使用8張圖像的批次並每4批次更新一次權重，因此設置 4\n","ACCUM_ITER = 1\n","\n","# (Boolean)是否計算每個Epoch Step指標，會造成CPU使用率變高\n","CALCULATE_EPOCH_STEP = False\n","\n","\n","''''圖表參數設定'''\n","\n","# (Int)訓練歷程圖表寬度\n","TRAINING_CURVES_FIGSIZE_W = 20\n","\n","# (Int)訓練歷程圖表高度\n","TRAINING_CURVES_FIGSIZE_H = 10\n","\n","# (Int)訓練歷程圖表SCATTER的標記點大小 \n","TRAINING_CURVES_SCATTER_SCALAR = 200\n","\n","# (Float)訓練歷程圖表SCATTER的指標文字離標記點X距離係數\n","TRAINING_CURVES_SCATTER_METRICS_TEXT_XSCALAR = 0.03\n","\n","# (Float)訓練歷程圖表SCATTER的指標文字標記點Y距離係數\n","TRAINING_CURVES_SCATTER_METRICS_TEXT_YSCALAR = 0.13\n","\n","# (Float)訓練歷程圖表SCATTER的損失文字標記點X距離係數\n","TRAINING_CURVES_SCATTER_LOSS_TEXT_XSCALAR = 0.03\n","\n","# (Float)訓練歷程圖表SCATTER的損失文字標記點Y距離係數\n","TRAINING_CURVES_SCATTER_LOSS_TEXT_YSCALAR = 0.05\n","\n","# (Int)訓練歷程圖表SCATTER的文字大小\n","TRAINING_CURVES_SCATTER_TEXTSIZE = 15\n","\n","# (Int)訓練歷程圖表X軸標題字型大小\n","TRAINING_CURVES_XLABEL_FONTSIZE = 15\n","\n","# (Int)訓練歷程圖表Y軸標題字型大小\n","TRAINING_CURVES_YLABEL_FONTSIZE = 15\n","\n","# (Int)訓練歷程圖表標題字型大小\n","TRAINING_CURVES_TITLE_FONTSIZE = 20\n","\n","# (Float)訓練歷程圖表格線粗度\n","TRAINING_CURVES_GRID_ALPHA = 0"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = CUDNN_DETERMINISTIC\n","    torch.backends.cudnn.benchmark = CUDNN_BENCHMARK\n","\n","seed_everything(SEED)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. 資料處理<a class=\"anchor\" id=\"4\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}},{"cell_type":"markdown","source":["## 4.1 載入CSV檔 <a class=\"anchor\" id=\"4.1\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}},{"cell_type":"code","source":["print('Reading data...')\n","\n","# 讀取訓練資料集CSV檔\n","if os.path.isfile(TRAIN_CSV_PATH):\n","    train_csv = pd.read_csv(TRAIN_CSV_PATH,encoding=\"utf8\")\n","else:\n","    train_data_directory_list = os.listdir(TRAIN_DATA_PATH)\n","    train_data_mask_directory_list = os.listdir(TRAIN_DATA_MASK_PATH)\n","    train_csv = pd.DataFrame(train_data_directory_list, columns=[IMAGE_NAME])\n","    train_mask_csv = pd.DataFrame(train_data_mask_directory_list, columns=[IMAGE_NAME])\n","    del train_data_directory_list, train_data_mask_directory_list\n","    gc.collect()\n","\n","print('Reading data completed')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 顯示訓練資料集CSV檔\n","train_csv.head()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Shape of train_data :\", train_csv.shape)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 顯示訓練資料集CSV檔\n","train_mask_csv.head()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Shape of train_data :\", train_mask_csv.shape)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5. 定義模型方法<a class=\"anchor\" id=\"5\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}},{"cell_type":"code","source":["def build_optimizers(model):\n","    if OPTIMIZERS_TYPE == \"SGD\":\n","        RETURN_OPTIMIZERS = optim.SGD(model.parameters(), \n","                                      lr = LEARNING_RATE, momentum = MOMENTUM, \n","                                      dampening = DAMPENING, weight_decay = WEIGHT_DECAY, \n","                                      nesterov = NESTEROV)\n","    elif OPTIMIZERS_TYPE == \"Adam\":\n","        RETURN_OPTIMIZERS = optim.Adam(model.parameters(), \n","                                       lr = LEARNING_RATE, betas = BETAS, eps = EPS, \n","                                       weight_decay = WEIGHT_DECAY)\n","    elif OPTIMIZERS_TYPE == \"Adamax\":\n","        RETURN_OPTIMIZERS = optim.Adamax(model.parameters(), \n","                                         lr = LEARNING_RATE, betas = BETAS, eps = EPS, \n","                                         weight_decay = WEIGHT_DECAY)\n","    elif OPTIMIZERS_TYPE == \"RMSprop\":\n","        RETURN_OPTIMIZERS = optim.RMSprop(model.parameters(), \n","                                          lr = LEARNING_RATE, alpha = ALPHA, eps = EPS, \n","                                          weight_decay = WEIGHT_DECAY, momentum = MOMENTUM, \n","                                          centered = CENTERED)\n","    elif OPTIMIZERS_TYPE == \"Adagrad\":\n","        RETURN_OPTIMIZERS = optim.Adagrad(model.parameters(), \n","                                          lr = LEARNING_RATE, lr_decay = LR_DECAY, \n","                                          weight_decay = WEIGHT_DECAY)\n","    return RETURN_OPTIMIZERS"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DiceBCELoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True,  smoothing=1):\n","        super(DiceBCELoss, self).__init__()\n","        self.weight = weight\n","        self.size_average = size_average\n","        self.smoothing = smoothing\n","\n","    def forward(self, inputs, targets):\n","        \n","        #comment out if your model contains a sigmoid or equivalent activation layer\n","        inputs = F.sigmoid(inputs)       \n","        \n","        #flatten label and prediction tensors\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","        \n","        intersection = (inputs * targets).sum()                            \n","        dice_loss = 1 - (2.*intersection +  self.smoothing)/(inputs.sum() + targets.sum() +  self.smoothing)  \n","        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n","        Dice_BCE = BCE + dice_loss\n","        \n","        return Dice_BCE"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_losses():\n","#     return CUSTOM_LOSSES.to(DEVICE)\n","    return DiceBCELoss().to(DEVICE)\n","\n","def get_dice_coeff(pred, targs):\n","    '''\n","    Calculates the dice coeff of a single or batch of predicted mask and true masks.\n","    \n","    Args:\n","        pred : Batch of Predicted masks (b, w, h) or single predicted mask (w, h)\n","        targs : Batch of true masks (b, w, h) or single true mask (w, h)\n","  \n","    Returns: Dice coeff over a batch or over a single pair.\n","    '''\n","    \n","    pred = (pred>0).float()\n","    return 2.0 * (pred*targs).sum() / ((pred+targs).sum() + 1.0)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class build_model(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        if USE_BASE_SMP_MODEL:\n","            self.model = BASE_MODEL(encoder_name = BASE_MODEL_ENCODER, \n","                                    encoder_weights = ENCODER_WEIGHTS, \n","                                    in_channels = IN_CHANNELS, \n","                                    classes = CLASSES, \n","                                    activation = SMP_MODEL_ACTIVATION)\n","        else:\n","            self.model = BASE_MODEL(pretrained = LOAD_BASE_WEIGHTS)\n","            self.model.classifier[4] = BASE_MODEL_CLASSIFIER\n","            self.model.aux_classifier[4] = BASE_MODEL_AUX_CLASSIFIER\n","            \n","    def forward(self, x):\n","        x = self.model(x)\n","        return x"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 6. 定義回調函數方法 <a class=\"anchor\" id=\"6\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}},{"cell_type":"code","source":["def get_callbacks(optimizer):\n","    if CALLBACKS_STEPLR:\n","        # 等間隔調整學習率，調整倍數為gamma倍，調整間隔為step_size。間隔單位是step。需要注意的是，step通常是指epoch，不要弄成iteration了。\n","        callbacks_scheduler = lr_scheduler.StepLR(optimizer, step_size = STEP_SIZE, gamma = GAMMA)\n","    elif CALLBACKS_REDUCELRONPLATEAU:\n","        # 當某指標不再變化（下降或升高），調整學習率，這是非常實用的學習率調整策略。例如，當驗證集的loss不再下降時，進行學習率調整；\n","        # 或者監測驗證集的accuracy，當accuracy不再上升時，則調整學習率。\n","        callbacks_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,  mode = MODE, factor = FACTOR, patience = PATIENCE, \n","                                                   threshold = THRESHOLD, threshold_mode = THRESHOLD_MODE, cooldown = COOLDOWN, \n","                                                   min_lr = MIN_LR, eps = SCHEDULER_EPS, verbose = SCHEDULER_VERBOSE)\n","    elif CALLBACKS_COSINEANNEALINGWARMRESTAERS:\n","        # 使用餘弦退火時間表設置每個參數組的學習率\n","        callbacks_scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = T_0, T_mult = T_MULT, eta_min = ETA_MIN, \n","                                                             verbose = SCHEDULER_VERBOSE)\n","    else:\n","        callbacks_scheduler = None \n","    return callbacks_scheduler"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 7. 製作資料集＆資料擴增&訓練模型 <a class=\"anchor\" id=\"7\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}},{"cell_type":"code","source":["class MyDataset(Dataset):\n","    def __init__(self, df, transforms = None):\n","        super().__init__()\n","        self.df = df\n","        self.transforms = transforms\n","        \n","    def __len__(self):\n","        return self.df.shape[0]\n","\n","    def __getitem__(self, index: int):\n","        image_name = self.df[index]\n","        \n","        if IMAGE_NAME_HAVE_EXTENSION:\n","            image_path = TRAIN_DATA_PATH + image_name\n","        else:\n","            image_path = TRAIN_DATA_PATH + image_name + IMAGE_NAME_EXTENSION\n","        mask_path = TRAIN_DATA_MASK_PATH + image_name\n","\n","        image = cv2.imread(image_path)\n","        if COLOR_CONVERT_RGB:\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n","        \n","        if self.transforms is not None:\n","            sample = self.transforms(image = image, mask = mask)\n","            image, mask = sample['image'], sample['mask']\n","\n","        return image, mask"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 確定是否將應用此增強。機率為 p = 1.0 意味著我們總是從上面應用轉換。\n","# p = 0 將意味著將忽略轉換塊。\n","# 0 < p < 1.0 等於每個擴增都具有以一定概率應用的選項。\n","# OneOf 隨機選取一種增強擴增\n","\n","def get_train_transforms():\n","    return A.Compose([\n","        A.Blur(blur_limit = BLUR_LIMIT, \n","               p = P_BLUR), # 模糊\n","        A.HorizontalFlip(p = P_HORIZONTALFLIP), # 水平翻轉\n","        A.VerticalFlip(p = P_VERTICALFLIP), # 垂直翻轉\n","        A.Flip(p = P_FLIP), # 水平和垂直翻轉\n","        A.Resize(height = RESIZE_HEIGHT, \n","                 width = RESIZE_WIDTH, \n","                 p = P_RESIZE), # 縮放\n","        A.RandomResizedCrop(height = RANDOMRESIZEDCROP_HEIGHT, \n","                            width = RANDOMRESIZEDCROP_WIDTH, \n","                            scale = RANDOMRESIZEDCROP_SCALE, \n","                            p = P_RANDOMRESIZEDCROP), #隨機縮放剪裁\n","        A.RandomRotate90(p = P_RANDOMROTATE90), # 隨機旋轉90度\n","        A.ShiftScaleRotate(shift_limit = SHIFTSCALEROTATE_SHIFT_LIMIT, \n","                           scale_limit = SHIFTSCALEROTATE_SCALE_LIMIT, \n","                           rotate_limit = SHIFTSCALEROTATE_ROTATE_LIMIT, \n","                           p = P_SHIFTSCALEROTATE), # 平移縮放旋轉\n","        A.ElasticTransform(alpha = ELATICTRANSFORM_ALPHA, \n","                           sigma = ELATICTRANSFORM_SIGMA, \n","                           alpha_affine = ELATICTRANSFORM_ALPHA_AFFINE, \n","                           p = P_ELATICTRANSFORM), # 彈性變換\n","        A.GridDistortion(num_steps = GRIDDISTORTION_NUM_STEPS, \n","                         p = P_GRIDDISTORTION), # 網格失真\n","        A.RandomBrightnessContrast(brightness_limit = RANDOMBRIGHTNESSCONTRAST_BRIGHTNESS_LIMIT, \n","                                   contrast_limit = RANDOMBRIGHTNESSCONTRAST_CONTRAST_LIMIT, \n","                                   p = P_RANDOMBRIGHTNESSCONTRAST_CONTRAST), # 隨機亮度對比度\n","        A.HueSaturationValue(hue_shift_limit = HUESATURATIONVALUE_HUE_SHIFT_LIMIT, \n","                             sat_shift_limit = HUESATURATIONVALUE_SAT_SHIFT_LIMIT, \n","                             val_shift_limit = HUESATURATIONVALUE_VAL_SHIFT_LIMIT, \n","                             p = P_HUESATURATIONVALUE), # 隨機色調飽和度值\n","        A.CLAHE(clip_limit = CLAHE_CLIP_LIMIT, \n","                p = P_CLAHE), # 將對比度受限的自適應直方圖均衡化應用於輸入圖像\n","        A.Cutout(num_holes = COARSEDROPOUT_NUM_HOLES, \n","                        max_h_size = COARSEDROPOUT_MAX_H_SIZE, \n","                        max_w_size = COARSEDROPOUT_MAX_W_SIZE, \n","                        p = P_COARSEDROPOUT), # 隨機在圖像上生成黑色矩形\n","        A.Normalize(\n","             mean = NORMALIZE_MEAN, \n","             std = NORMALIZE_STD, \n","            max_pixel_value = NORMALIZE_MAX_PIXEL_VALUE, \n","            p = P_NORMALIZE), # 正規化。\n","        ToTensorV2(p = P_TOTENSORV2) # 歸一化\n","    ], p = P_TRAIN_TRANSFORMS)\n","\n","def get_val_transforms():\n","    return A.Compose([\n","        A.Resize(height = RESIZE_HEIGHT, \n","                 width = RESIZE_WIDTH, \n","                 p = P_RESIZE), # 縮放\n","        A.Normalize(\n","             mean = NORMALIZE_MEAN,\n","             std = NORMALIZE_STD, \n","            max_pixel_value = NORMALIZE_MAX_PIXEL_VALUE, \n","            p = P_NORMALIZE), # 正規化。\n","        ToTensorV2(p = P_TOTENSORV2) # 歸一化\n","    ], p = P_VAL_TRANSFORMS)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_dataloader(fold, df):\n","    \n","    if FOLD >1:\n","        train_data = df.loc[~df.Folds.isin([fold]), IMAGE_NAME].values\n","        validation_data = df.loc[df.Folds.isin([fold]), IMAGE_NAME].values\n","    else:\n","        X_train, X_val = train_test_split(train_csv[IMAGE_NAME], test_size = DATA_SPLIT, random_state = SEED)\n","        train_data = pd.DataFrame(X_train)\n","        train_data.columns = [IMAGE_NAME]\n","\n","        validation_data = pd.DataFrame(X_val)\n","        validation_data.columns = [IMAGE_NAME]\n","        \n","    train_dataset = MyDataset(train_data, transforms = get_train_transforms())\n","    val_dataset = MyDataset(validation_data, transforms = get_val_transforms())\n","    \n","    # 紀錄訓練集跟驗證集大小\n","    train_dataset_size = len(train_dataset)\n","    val_dataset_size = len(val_dataset)\n","    \n","    #for metrics\n","    dataset_sizes = { 'train': train_dataset_size, 'val': val_dataset_size}\n","    print(dataset_sizes)\n","    \n","    train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE[fold], pin_memory = PIN_MEMORY, \n","                                               shuffle = True, num_workers = NUM_WORKERS, drop_last = DROP_LAST)\n","    \n","    val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE[fold], pin_memory = PIN_MEMORY, \n","                                               shuffle = False, num_workers = NUM_WORKERS)\n","    \n","    del train_data, validation_data, train_dataset, val_dataset, dataset_sizes\n","    if FOLD <=1:\n","        del X_train, X_val\n","    gc.collect()\n","    \n","    return train_loader, val_loader, train_dataset_size, val_dataset_size"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def display_training_curves(fold, kf, train_metrics, val_metrics):\n","    plt.figure(figsize=(TRAINING_CURVES_FIGSIZE_W,TRAINING_CURVES_FIGSIZE_H))\n","    plt.plot(np.arange(EPOCHS[fold]),train_metrics[PLOT_METRICS],'-o',label='TRAIN '+PLOT_METRICS.upper(),color='#ff7f0e')\n","    plt.plot(np.arange(EPOCHS[fold]),val_metrics[PLOT_METRICS],'-o',label='VALIDATION '+PLOT_METRICS.upper(),color='#1f77b4')\n","    x = np.argmax( val_metrics[PLOT_METRICS] ); y = np.max( val_metrics[PLOT_METRICS] )\n","    xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n","    plt.scatter(x,y,s=TRAINING_CURVES_SCATTER_SCALAR,color='#1f77b4')\n","    plt.text(x-TRAINING_CURVES_SCATTER_METRICS_TEXT_XSCALAR*xdist,y-TRAINING_CURVES_SCATTER_METRICS_TEXT_YSCALAR*ydist,'max '+PLOT_METRICS+'\\n%.4f'%y,size=TRAINING_CURVES_SCATTER_TEXTSIZE)\n","    plt.ylabel(PLOT_METRICS.upper(),size=TRAINING_CURVES_YLABEL_FONTSIZE); plt.xlabel('EPOCH',size=TRAINING_CURVES_XLABEL_FONTSIZE)\n","    plt.grid(alpha=TRAINING_CURVES_GRID_ALPHA)\n","    plt.legend(loc=2)\n","    plt2 = plt.gca().twinx()\n","    plt2.plot(np.arange(EPOCHS[fold]),train_metrics['loss'],'-o',label='TRAIN LOSS',color='#2ca02c')\n","    plt2.plot(np.arange(EPOCHS[fold]),val_metrics['loss'],'-o',label='VALIDATION LOSS',color='#d62728')\n","    x = np.argmin( val_metrics['loss'] ); y = np.min( val_metrics['loss'] )\n","    ydist = plt.ylim()[1] - plt.ylim()[0]\n","    plt.scatter(x,y,s=TRAINING_CURVES_SCATTER_SCALAR,color='#d62728')\n","    plt.text(x-TRAINING_CURVES_SCATTER_LOSS_TEXT_XSCALAR*xdist,y+TRAINING_CURVES_SCATTER_LOSS_TEXT_YSCALAR*ydist,'min loss\\n%.4f'%y,size=TRAINING_CURVES_SCATTER_TEXTSIZE)\n","    plt.ylabel('LOSS',size=TRAINING_CURVES_YLABEL_FONTSIZE)\n","    if kf:\n","        plt.title('FOLD %i - IMAGE SIZE %i, %s'%\n","                  (fold+1, IMAGE_SIZE[fold], MODEL_NAME.upper()), size=TRAINING_CURVES_TITLE_FONTSIZE)\n","    else:\n","        plt.title(' IMAGE SIZE %i, %s'%\n","                  (IMAGE_SIZE[fold], MODEL_NAME.upper()), size=TRAINING_CURVES_TITLE_FONTSIZE)\n","    plt.grid(alpha=TRAINING_CURVES_GRID_ALPHA)\n","    plt.legend(loc=3)\n","    plt.show()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_one_epoch(fold, epoch, model, scaler, train_loss, optimizer, train_loader, train_dataset_size, \n","                    train_metrics, writer = None, scheduler = None, scheduler_batch_update = False):\n","    # 設定模型為訓練模式\n","    model.train()\n","    \n","    # 計算迭代目前的step\n","    epoch_step = 0\n","\n","    # 計算當下loss\n","    running_loss = 0.0\n","    \n","    # 計算每迭代loss\n","    epoch_loss = 0.0\n","    \n","    # 計算每迭代dice_coeff\n","    epoch_dice_coeff = 0.0\n","    \n","    # 加總每批骰子係數\n","    dice_coeff = []\n","\n","    # 遍歷enumaretad批處理\n","    pbar = tqdm(enumerate(train_loader), total=len(train_loader), \n","                position = TQDM_POSITION, leave = TQDM_LEAVE)\n","    for batch_idx, (inputs, labels) in pbar:\n","        # 提取輸入和標籤\n","        inputs = inputs.to(DEVICE).float()\n","        labels = labels.to(DEVICE).float()\n","        \n","        if AMP_SCALE_TRAIN:\n","            # 前向過程(model + loss)開啟 autocast\n","            with autocast():\n","                if USE_BASE_SMP_MODEL:\n","                    outputs = model(inputs)\n","                else:\n","                    outputs = model(inputs)['out']\n","                loss = train_loss(outputs, labels)  \n","        else:\n","            if USE_BASE_SMP_MODEL:\n","                outputs = model(inputs)\n","            else:\n","                outputs = model(inputs)['out']\n","            loss = train_loss(outputs, labels)\n","            \n","        # 歸一化損失以說明批次累積\n","        loss = loss / ACCUM_ITER \n","            \n","        if AMP_SCALE_TRAIN:\n","            # Scales loss. 為了梯度放大\n","            # 反向傳播在autocast上下文之外\n","            scaler.scale(loss).backward()\n","        else:\n","            loss.backward()\n","\n","        # 權重更新\n","        if ((batch_idx + 1) %  ACCUM_ITER == 0) or ((batch_idx + 1) == len(train_loader)):\n","\n","            if AMP_SCALE_TRAIN:\n","                # scaler.step() 首先把梯度的值unscale回來.\n","                # 如果梯度的值不是 infs 或者 NaNs, 那麼調用optimizer.step()來更新權重,\n","                # 否則，忽略step調用，從而保證權重不更新（不被破壞）\n","                scaler.step(optimizer)\n","\n","                # 準備著，看是否要增大scaler\n","                scaler.update()\n","            else:\n","                optimizer.step()\n","            \n","            # 零參數梯度\n","            optimizer.zero_grad()\n","            \n","            if scheduler is not None and scheduler_batch_update:\n","                scheduler.step()\n","            \n","        if CALCULATE_EPOCH_STEP:\n","            # step / epoch statistics\n","            epoch_step += 1\n","            \n","            if PLOT_METRICS == \"dice_coeff\":\n","                epoch_step_dice_coeff = get_dice_coeff(torch.squeeze(outputs), labels).cpu().numpy()\n","                print(f\"Step {epoch_step} / Epoch {epoch+1} - Train Loss: {loss.item():.4f}, Train Dice_Coeff: {epoch_step_dice_coeff:.4f}\")\n","            \n","            if CALLBACKS_TENSOR_BOARD:\n","                epoch_len = train_dataset_size // train_loader.batch_size\n","                writer.add_scalar(\"Loss/Train\", loss.item(), epoch_len * epoch + epoch_step)\n","                if PLOT_METRICS == \"dice_coeff\":\n","                    writer.add_scalar(\"Dice_Coeff/Train\", epoch_step_dice_coeff, epoch_len * epoch + epoch_step) \n","                    \n","        # epoch statistics\n","        running_loss += loss.item()*inputs.size(0)\n","        dice_coeff += [get_dice_coeff(torch.squeeze(outputs), labels).cpu().numpy()]\n","\n","    epoch_loss = running_loss / train_dataset_size\n","    train_metrics['loss'].append(epoch_loss)\n","    if PLOT_METRICS == \"dice_coeff\":\n","        epoch_dice_coeff = sum(dice_coeff) / len(dice_coeff)\n","        train_metrics[PLOT_METRICS].append(epoch_dice_coeff)\n","        print(f\"Epoch {epoch+1}/{EPOCHS[fold]} - Train Average Loss: {epoch_loss:.4f}, Train Average Dice_Coeff: {epoch_dice_coeff:.4f}\")\n","       \n","    if scheduler is not None and not scheduler_batch_update:\n","        scheduler.step()\n","        \n","    del model, epoch_step, running_loss, epoch_loss, epoch_dice_coeff\n","    del dice_coeff\n","    gc.collect()\n","        \n","def valid_one_epoch(fold, epoch, model, val_loss, val_loader, val_dataset_size, val_metrics, monitor_metrics, save_model_path, \n","                    writer = None, scheduler = None, scheduler_loss_update = False):\n","    # 設定模型為評估模式\n","    model.eval()\n","    \n","    # 計算迭代目前的step\n","    epoch_step = 0\n","\n","    # 計算每批loss\n","    running_loss = 0.0\n","    \n","    # 計算每迭代loss\n","    epoch_loss = 0.0\n","    \n","    # 計算每迭代dice_coeff\n","    epoch_dice_coeff = 0.0\n","    \n","    # 計算提早停止次數\n","    early_stopping = 0\n","    \n","    # 加總每批骰子係數\n","    dice_coeff = []\n","    \n","    # 遍歷enumaretad批處理\n","    pbar = tqdm(enumerate(val_loader), total=len(val_loader), \n","                position = TQDM_POSITION, leave = TQDM_LEAVE)\n","    for batch_idx, (inputs, labels) in pbar:\n","        # 提取輸入和標籤\n","        inputs = inputs.to(DEVICE).float()\n","        labels = labels.to(DEVICE).float() \n","        if USE_BASE_SMP_MODEL:\n","            outputs = model(inputs)\n","        else:\n","            outputs = model(inputs)['out']\n","        loss = val_loss(outputs, labels)\n","        \n","        if CALCULATE_EPOCH_STEP:\n","            # step / epoch statistics\n","            epoch_step += 1\n","  \n","            if PLOT_METRICS == \"dice_coeff\":\n","                epoch_step_dice_coeff = get_dice_coeff(torch.squeeze(outputs), labels).cpu().numpy()\n","                print(f\"Step {epoch_step} / Epoch {epoch+1} - Val Loss: {loss.item():.4f}, Val Accuracy: {epoch_step_dice_coeff:.4f}\")\n","            \n","            if CALLBACKS_TENSOR_BOARD:\n","                epoch_len = val_dataset_size // val_loader.batch_size\n","                writer.add_scalar(\"Loss/Val\", loss.item(), epoch_len * epoch + epoch_step)\n","                if PLOT_METRICS == \"dice_coeff\":\n","                    writer.add_scalar(\"Dice_Coeff/Val\", epoch_step_dice_coeff, epoch_len * epoch + epoch_step)\n","            \n","        # epoch statistics\n","        running_loss += loss.item()*inputs.size(0)\n","        dice_coeff += [get_dice_coeff(torch.squeeze(outputs), labels).cpu().numpy()]\n","        \n","    epoch_loss = running_loss / val_dataset_size\n","    val_metrics['loss'].append(epoch_loss)\n","    if PLOT_METRICS == \"dice_coeff\":\n","        epoch_dice_coeff = sum(dice_coeff) / len(dice_coeff)\n","        val_metrics[PLOT_METRICS].append(epoch_dice_coeff)\n","        print(f\"Epoch {epoch+1}/{EPOCHS[fold]} - Val Average Loss: {epoch_loss:.4f}, Val Average Dice_Coeff: {epoch_dice_coeff:.4f}\")    \n","        \n","    if CALLBACKS_CHECK_POINTER:\n","        save_model = False\n","        if SAVE_BEST_ONLY:\n","            if (epoch_loss < monitor_metrics or monitor_metrics == 0) and MONITOR == \"val_loss\":\n","                monitor_metrics = epoch_loss\n","                save_model = True\n","            elif epoch_dice_coeff > monitor_metrics and MONITOR == \"val_dice_coeff\" and PLOT_METRICS == \"dice_coeff\":\n","                monitor_metrics = epoch_dice_coeff\n","                save_model = True \n","            else:\n","                early_stopping += 1\n","        else:\n","            if MONITOR == \"val_loss\":\n","                if monitor_metrics is not 0:\n","                    if epoch_loss >= monitor_metrics:\n","                        early_stopping += 1\n","                monitor_metrics = epoch_loss\n","            elif MONITOR == \"val_dice_coeff\":\n","                if monitor_metrics is not 0:\n","                    if epoch_dice_coeff <= monitor_metrics:\n","                        early_stopping += 1\n","                monitor_metrics = epoch_dice_coeff\n","            save_model = True\n","            \n","        if SAVE_WEIGHTS_ONLY and save_model:\n","            torch.save(model.state_dict(), save_model_path)\n","            print('Save weights')\n","        elif not SAVE_WEIGHTS_ONLY and save_model:\n","            torch.save(model, save_model_path)\n","            print('Save model')\n","\n","    if scheduler is not None and VAL_ENABLE_SCHEDULER:\n","        if scheduler_loss_update:\n","            scheduler.step(epoch_loss)\n","        else:\n","            scheduler.step()\n","            \n","    del model, epoch_step, running_loss, epoch_loss, epoch_dice_coeff\n","    del dice_coeff\n","    gc.collect()\n","            \n","    return early_stopping"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_process(fold, kf):\n","    if kf:\n","        print('Fold %i - image size %i with %s and batch size %i'%(fold+1,IMAGE_SIZE[fold],MODEL_NAME.upper(),BATCH_SIZE[fold]))\n","    else:\n","        print('Image size %i with %s and batch_size %i'%(IMAGE_SIZE[fold],MODEL_NAME.upper(),BATCH_SIZE[fold]))\n","        \n","    if kf:\n","        # (String)訓練模型FOLD>1的儲存路徑\n","        SAVE_MODEL_PATH = PROJECT_PATH+r'/models/'+MODEL_NAME+'_fold_%i.pt'%(fold+1)\n","    else:\n","        SAVE_MODEL_PATH = TRAIN_MODEL_PATH\n","    \n","    train_loader, val_loader, train_dataset_size, val_dataset_size = prepare_dataloader(fold, train_csv)\n","    \n","    if LOAD_MODEL:\n","        # 載入預訓練模型\n","        model = torch.load(LOAD_MODEL_PATH)\n","    elif CUSTOM_MODEL is not None:\n","        # ==== INIT CUSTIOM MODEL\n","        model = CUSTOM_MODEL\n","        if LOAD_WEIGHTS:\n","            # 載入預訓練權重\n","            model.load_state_dict(LOAD_WEIGHTS_PATH)\n","    else:\n","        # 創建model\n","        model = build_model()\n","\n","    model.to(DEVICE)\n","    optimizer = build_optimizers(model)\n","    \n","    # 在訓練最開始之前實例化一個GradScaler對象\n","    scaler = GradScaler()\n","    \n","    if CALLBACKS_TENSOR_BOARD:\n","        # 在訓練最開始之前實例化一個SummaryWriter對象\n","        writer = SummaryWriter(comment=TENSOR_BOARD_COMMENT)\n","    else:\n","        writer = None\n","    \n","    scheduler = get_callbacks(optimizer) # 回調函式\n","\n","    train_loss = build_losses() # train loss\n","    val_loss = build_losses() # val loss\n","\n","    if MODEL_PRINT:\n","        # Print model's state_dict\n","        print(\"Model's state_dict:\")\n","        for param_tensor in model.state_dict():\n","            print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n","\n","    if OPTIMIZER_PRINT:\n","        # Print optimizer's state_dict\n","        print(\"Optimizer's state_dict:\")\n","        for var_name in optimizer.state_dict():\n","            print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n","            \n","    # 紀錄最好指標\n","    monitor_metrics = 0.0\n","    \n","    #save the losses and metrics for further visualization\n","    train_metrics = {PLOT_METRICS:[], 'loss':[]}\n","    val_metrics = {PLOT_METRICS:[], 'loss':[]}\n","               \n","    for epoch in range(EPOCHS[fold]):\n","        train_one_epoch(fold, epoch, model, scaler, train_loss, optimizer, train_loader, train_dataset_size, \n","                        train_metrics, writer, scheduler = scheduler, scheduler_batch_update = SCHEDULER_BATCH_UPDATE)\n","\n","        with torch.no_grad():\n","            early_stopping = valid_one_epoch(fold, epoch, model, val_loss, val_loader, val_dataset_size, \n","                                             val_metrics, monitor_metrics, SAVE_MODEL_PATH, writer, \n","                                             scheduler = scheduler, scheduler_loss_update = SCHEDULER_LOSS_UPDATE)\n","        \n","        if CALLBACKS_EARLY_STOPPING:\n","            if early_stopping >= PATIENCE_ELS:\n","                break\n","            \n","    display_training_curves(fold, kf, train_metrics, val_metrics)\n","    \n","    if not CALLBACKS_CHECK_POINTER:\n","        if SAVE_WEIGHTS_ONLY:\n","            torch.save(model.state_dict(), SAVE_MODEL_PATH)\n","            print('Save weights')\n","        else:\n","            torch.save(model, SAVE_MODEL_PATH)\n","            print('Save model')\n","    \n","    if CALLBACKS_TENSOR_BOARD:\n","        writer.flush()\n","        writer.close()\n","        \n","    torch.cuda.empty_cache()\n","    \n","    del model, optimizer, train_loader, val_loader, scaler, scheduler, train_loss, val_loss\n","    del train_dataset_size, val_dataset_size, monitor_metrics, early_stopping\n","    gc.collect()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main():\n","    try:\n","        print('Training start')\n","        since = time.time()\n","        if FOLD > 1:\n","            train_csv['Folds'] = 0\n","            for fold, (train_index, valid_index) in enumerate(KF.split(train_csv, groups = train_csv[train_csv.columns[0]].values)):\n","                train_csv.loc[valid_index, 'Folds'] = fold\n","                train_process(fold = fold, kf = True)\n","        else:\n","            train_process(fold = 0, kf = False)\n","        time_elapsed = time.time() - since\n","        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    except Exception as exception:\n","        print(exception)\n","        raise"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    main()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 8. 待辦事項<a class=\"anchor\" id=\"8\"></a>\n","[Back to Table of Contents](#0)"],"metadata":{}}]}